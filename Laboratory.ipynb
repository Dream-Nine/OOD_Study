{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a27e974-4760-438a-8283-d96bb45fe66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72f2204-ea31-4cc4-8112-98acd1b5192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "TF_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((125.3/255, 123.0/255, 113.9/255), (63.0/255, 62.1/255.0, 66.7/255.0)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/mydir/data', train=True, download=True, transform=TF_cifar10)\n",
    "trainloaderIn = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "testset = torchvision.datasets.CIFAR10(root='/home/mydir/data', train=False, download=True, transform=TF_cifar10)\n",
    "testloaderIn = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffde8f2b-7284-487b-be7b-6d30b503c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When calling the pre-trained model, you maybe need the module in where pre-trained model's class is\n",
    "# sys.path.insert(1, './odin/code')\n",
    "\n",
    "path2model = './odin/models/'\n",
    "dense10_cifar = torch.load(path2model+'densenet10.pth')\n",
    "dense10_svhn = torch.load(path2model+'densenet10_svhn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc17b0c-263c-44ed-aedc-79fbbf35a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ae4fdd-4d3b-4d05-ad31-1faf8960ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c1bd0-59dc-4624-91c2-943aa79e54ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LittleLab: Let's reverse-engineer the paper `A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebb7bc8-5175-434e-9d81-e4f4a61dcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# about non-deeplearning\n",
    "\n",
    "# importing sys\n",
    "import sys\n",
    "# adding other folder to the system path\n",
    "sys.path.insert(1, './Mahal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f57c73-f70f-41bb-9918-f63d55335c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# about deeplearning\n",
    "import data_loader\n",
    "import calculate_log as callog\n",
    "import lib_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b3b43e7-ffa8-48e3-8a57-5cb7607a0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder `models` includes the modules `densenet.py` and `resnet.py`, \n",
    "# so there must be the file `__init__py` in folder if you want to import the folder\n",
    "import models \n",
    "model = torch.load('./models/densenet_cifar10_Mahal.pth')\n",
    "num_classes = 10\n",
    "train_loader = trainloaderIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2a2fb67-e478-4e8c-a0b1-9ffef8e9a2df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./Mahal/lib_generation.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Accuracy:(100.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed(1001)\n",
    "out_dist_list = ['svhn', 'imagenet_resize', 'lsun_resize']\n",
    "model.cuda()\n",
    "train_loader, test_loader = trainloaderIn, testloaderIn\n",
    "model.eval()\n",
    "# ?? why we use tmp tensor?\n",
    "temp_x = torch.rand(2,3,32,32).cuda()\n",
    "temp_x = Variable(temp_x)\n",
    "temp_list = model.feature_list(temp_x)[1] # last output is in index 0, intermediate ouputs are in index 1 (it is a list)\n",
    "num_output = len(temp_list)\n",
    "feature_list = np.empty(num_output)\n",
    "count = 0\n",
    "for out in temp_list:\n",
    "    feature_list[count] = out.size(1)\n",
    "    count += 1\n",
    "    \n",
    "sample_mean, precision = lib_generation.sample_estimator(model, num_classes, feature_list, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "558fc09b-b99b-461e-8731-2bf95124aefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 108])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mean[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de35fd28-a0e2-411b-8b09-b3042e7a2b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24., 108., 150., 342.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c572e9b-6f7c-4895-ac60-04b9b021efd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4,3,2).view(1,-1).s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c011ccc8-f034-450b-bb80-6e8534f436cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "          [  5.,   6.,   7.,   8.,   9.],\n",
       "          [ 10.,  11.,  12.,  13.,  14.],\n",
       "          [ 15.,  16.,  17.,  18.,  19.]],\n",
       "\n",
       "         [[ 20.,  21.,  22.,  23.,  24.],\n",
       "          [ 25.,  26.,  27.,  28.,  29.],\n",
       "          [ 30.,  31.,  32.,  33.,  34.],\n",
       "          [ 35.,  36.,  37.,  38.,  39.]],\n",
       "\n",
       "         [[ 40.,  41.,  42.,  43.,  44.],\n",
       "          [ 45.,  46.,  47.,  48.,  49.],\n",
       "          [ 50.,  51.,  52.,  53.,  54.],\n",
       "          [ 55.,  56.,  57.,  58.,  59.]]],\n",
       "\n",
       "\n",
       "        [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "          [ 65.,  66.,  67.,  68.,  69.],\n",
       "          [ 70.,  71.,  72.,  73.,  74.],\n",
       "          [ 75.,  76.,  77.,  78.,  79.]],\n",
       "\n",
       "         [[ 80.,  81.,  82.,  83.,  84.],\n",
       "          [ 85.,  86.,  87.,  88.,  89.],\n",
       "          [ 90.,  91.,  92.,  93.,  94.],\n",
       "          [ 95.,  96.,  97.,  98.,  99.]],\n",
       "\n",
       "         [[100., 101., 102., 103., 104.],\n",
       "          [105., 106., 107., 108., 109.],\n",
       "          [110., 111., 112., 113., 114.],\n",
       "          [115., 116., 117., 118., 119.]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor(range(120)).view(2, 3, 4, 5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b96e8bff-7ca2-4f48-b386-e2bd278e288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  7.5000,   8.5000,   9.5000,  10.5000,  11.5000],\n",
       "         [ 27.5000,  28.5000,  29.5000,  30.5000,  31.5000],\n",
       "         [ 47.5000,  48.5000,  49.5000,  50.5000,  51.5000]],\n",
       "\n",
       "        [[ 67.5000,  68.5000,  69.5000,  70.5000,  71.5000],\n",
       "         [ 87.5000,  88.5000,  89.5000,  90.5000,  91.5000],\n",
       "         [107.5000, 108.5000, 109.5000, 110.5000, 111.5000]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "530bbe28-31da-4090-8885-7ccce21324fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "           11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.],\n",
       "         [ 20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,\n",
       "           31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.],\n",
       "         [ 40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,  49.,  50.,\n",
       "           51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.]],\n",
       "\n",
       "        [[ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,\n",
       "           71.,  72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.],\n",
       "         [ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "           91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.],\n",
       "         [100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "          111., 112., 113., 114., 115., 116., 117., 118., 119.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.view(t.size(0), t.size(1), -1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2dfc98c-4fcd-4975-a9da-96712ec618fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.5000, 29.5000, 49.5000]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, 2)[0].view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "598b1490-c085-4cd6-bb42-69b43ec8cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19.],\n",
       "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
       "         34., 35., 36., 37., 38., 39.],\n",
       "        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53.,\n",
       "         54., 55., 56., 57., 58., 59.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3386df50-3016-480b-adc0-2d5c3dca4259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(range(12)).view(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b91cc697-867a-41cf-9b2d-80fc15648374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6., 7.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.Tensor(range(12)).view(3, 4), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0882f7-f924-40da-a13a-9e6906122523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `lib_generation.py`\n",
    "'''\n",
    "real code in the main function\n",
    "\n",
    "This function calculates the class means & precision. \n",
    "We should modify the function to calculate the class precisions.\n",
    "\n",
    "sample_mean, precision = lib_generation.sample_estimator(model, args.num_classes, feature_list, train_loader)\n",
    "'''\n",
    "\n",
    "def sample_estimator(model, num_classes, feature_list, train_loader):\n",
    "    \"\"\"\n",
    "    compute sample mean and precision (inverse of covariance)\n",
    "    return: sample_class_mean: list of class mean\n",
    "             precision: list of precisions\n",
    "    \"\"\"\n",
    "    import sklearn.covariance\n",
    "    \n",
    "    model.eval()\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    \n",
    "    # `correct` is the number of correct inferences in entire inferences\n",
    "    # `total` is ?????\n",
    "    correct, total = 0, 0 \n",
    "    \n",
    "    num_output = len(feature_list)  # num output of model(last & intermediates)\n",
    "    num_sample_per_class = np.empty(num_classes) # zeros of num classes(maybe will contain the class-wise means?)\n",
    "    num_sample_per_class.fill(0)\n",
    "    list_features = []\n",
    "    for i in range(num_output):\n",
    "        temp_list = []\n",
    "        for j in range(num_classes): # temp_list contains zeros as many as the number of classes\n",
    "            temp_list.append(0)\n",
    "        list_features.append(temp_list) # list_features: double-nested list, #model output->#class\n",
    "                                        # if num_output=4 & num_classes=10, then list_features:4x10 list\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        total += data.size(0)\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True) # volatile=True -> only for inference\n",
    "        output, out_features = model.feature_list(data) # output: last output, out_features: intermediate outputs\n",
    "        \n",
    "        # get hidden features\n",
    "        for i in range(num_output):\n",
    "                                                            # size(0): batch_size, size(1): tensor-depth?, -1: flatten\n",
    "            out_features[i] = out_features[i].view(out_features[i].size(0), out_features[i].size(1), -1)\n",
    "            out_features[i] = torch.mean(out_features[i].data, 2) # cal means with preserving the depth?\n",
    "            \n",
    "        # compute the accuracy\n",
    "        pred = output.data.max(1)[1] # dim 1 in mini-batch -> each out for every input, [1] -> index\n",
    "        equal_flag = pred.eq(target.cuda()).cpu() # the flags of correct prediction(1: correct, 0: incorrect)\n",
    "        correct += equal_flag.sum() # the number of correct predictions\n",
    "        \n",
    "        # construct the sample matrix\n",
    "        for i in range(data.size(0)): # batch_size -> consider outputs of each input\n",
    "            label = target[i]  # the correct answer of each input\n",
    "            if num_sample_per_class[label] == 0: # This case is that there is no output yet in the class\n",
    "                out_count = 0\n",
    "                for out in out_features:\n",
    "                    list_features[out_count][label] = out[i].view(1, -1) # n개의 1차원-> 2차원 1xn\n",
    "                    out_count += 1\n",
    "            else:\n",
    "                out_count = 0\n",
    "                for out in out_features:\n",
    "                    list_features[out_count][label] \\\n",
    "                    = torch.cat((list_features[out_count][label], out[i].view(1, -1)), 0)\n",
    "                    out_count += 1                \n",
    "            num_sample_per_class[label] += 1\n",
    "            \n",
    "    sample_class_mean = []\n",
    "    out_count = 0\n",
    "    for num_feature in feature_list:\n",
    "        temp_list = torch.Tensor(num_classes, int(num_feature)).cuda() # temp_list: 10x24, 10x108, 10x150, 10x342\n",
    "        for j in range(num_classes):                                   # j = 0,1,2,...,9 \n",
    "            temp_list[j] = torch.mean(list_features[out_count][j], 0)  \n",
    "        sample_class_mean.append(temp_list)\n",
    "        out_count += 1\n",
    "    # sample_class_mean contains 4 tensors for each intermediate layers which containing class means about output tensor of 1dim \n",
    "    precision = []\n",
    "    for k in range(num_output):\n",
    "        X = 0\n",
    "        for i in range(num_classes):\n",
    "            if i == 0:\n",
    "                # k는 layer번호, i는 클래스 번호\n",
    "                # list_features[k][i]는 2차원 tensor(해당클래스의 데이터 개수 x depth), \n",
    "                # sample_class_mean[k][i]는 1차원 tensor(depth개수) \n",
    "                # => Broadcasting\n",
    "                X = list_features[k][i] - sample_class_mean[k][i]\n",
    "            else:\n",
    "                X = torch.cat((X, list_features[k][i] - sample_class_mean[k][i]), 0)\n",
    "                \n",
    "        # find inverse            \n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        temp_precision = group_lasso.precision_ # pseudo-inverse matrix\n",
    "        temp_precision = torch.from_numpy(temp_precision).float().cuda()\n",
    "        precision.append(temp_precision)\n",
    "        \n",
    "    print('\\n Training Accuracy:({:.2f}%)\\n'.format(100. * correct / total))\n",
    "\n",
    "    return sample_class_mean, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bbf42-a1fd-4fc2-abb4-dd09724fe32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the code from `OOD_Generate_Mahalanobis.py`\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import data_loader\n",
    "import numpy as np\n",
    "import calculate_log as callog\n",
    "import models\n",
    "import os\n",
    "import lib_generation\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch code: Mahalanobis detector')\n",
    "parser.add_argument('--batch_size', type=int, default=200, metavar='N', help='batch size for data loader')\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | cifar100 | svhn')\n",
    "parser.add_argument('--dataroot', default='./data', help='path to dataset')\n",
    "parser.add_argument('--outf', default='./output/', help='folder to output results')\n",
    "parser.add_argument('--num_classes', type=int, default=10, help='the # of classes')\n",
    "parser.add_argument('--net_type', required=True, help='resnet | densenet')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu index')\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "def main():\n",
    "    # set the path to pre-trained model and output\n",
    "    pre_trained_net = './pre_trained/' + args.net_type + '_' + args.dataset + '.pth'\n",
    "    args.outf = args.outf + args.net_type + '_' + args.dataset + '/'\n",
    "    if os.path.isdir(args.outf) == False:\n",
    "        os.mkdir(args.outf)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    # check the in-distribution dataset\n",
    "    if args.dataset == 'cifar100':\n",
    "        args.num_classes = 100\n",
    "    if args.dataset == 'svhn':\n",
    "        out_dist_list = ['cifar10', 'imagenet_resize', 'lsun_resize']\n",
    "    else:\n",
    "        out_dist_list = ['svhn', 'imagenet_resize', 'lsun_resize']\n",
    "        \n",
    "    print('get sample mean and covariance')\n",
    "    sample_mean, precision = lib_generation.sample_estimator(model, args.num_classes, feature_list, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a384b-0ba5-4349-87f5-9f7941392a11",
   "metadata": {},
   "source": [
    "# End LL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1d205-5043-4d49-9ff3-e595b8f4d393",
   "metadata": {},
   "source": [
    "# LittleLab #3. What Are The Mahalobis Distance of Activations like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9db86a4-d79e-49dd-b1ca-6c63b9da440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Hook:\n",
    "    def __init__(self, payers):\n",
    "        self.hook = payers.block3.register_forward_hook(self.hook_fn)\n",
    "    \n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    \n",
    "    def unregister_forward_hook(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72b6dabf-bb76-40bd-bc2f-5d5563628edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"DEVICE : {DEVICE}\")\n",
    "\n",
    "def take_act_from_last_conv(model, data_loader, output_container, activations_container):\n",
    "    model.eval() # using this, the dropouts turn off\n",
    "    activation_hook = Activation_Hook(model)\n",
    "    \n",
    "    with torch.no_grad(): # turn of auto-tracking of gradient\n",
    "        for image, label in data_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            \n",
    "            output = model(image).to('cpu')[0].numpy()\n",
    "            output_container[label.item()].append(output)\n",
    "            activations_container[label.item()].append(activation_hook.features.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e354ce7-fee6-4779-9f9d-c0671ec14e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense10_cifar.cuda()\n",
    "output_container_test = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "activations_container_test = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "take_act_from_last_conv(dense10_cifar, testloaderIn, output_container_test, activations_container_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "35cc3c9a-9d58-4b2e-9244-a8c146cfcdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_container_train = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "activations_container_train = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "take_act_from_last_conv(dense10_cifar, trainloaderIn, output_container_train, activations_container_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "341d54c0-da7a-48dd-9820-ae8f3e7a5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_total_len(container:dict):\n",
    "    total_len = 0\n",
    "    for key in list(container.keys()):\n",
    "        total_len += len(container[key])\n",
    "    return total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1f40c38-d968-41e9-9189-b6bd561eb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(dict_total_len(output_container_test))\n",
    "print(dict_total_len(activations_container_test))\n",
    "print(dict_total_len(output_container_train))\n",
    "print(dict_total_len(activations_container_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2c332b3e-0703-482e-ae89-5299ca26794c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_container_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4419a-02b1-4f85-8cc2-8a36a3ad7eb0",
   "metadata": {},
   "source": [
    "# End of LL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f85a49-9bae-4e1c-a57e-610cbbf2c472",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Is The Features of In-Distribution data at the Last ConvLayer Really Different from of Out-Of-Distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4344d9b3-b79a-4899-add0-74f68e54b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerResult:\n",
    "    def __init__(self, payers):\n",
    "        self.hook = payers.block3.register_forward_hook(self.hook_fn)\n",
    "    \n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.cpu().data.numpy()\n",
    "    \n",
    "    def unregister_forward_hook(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c5c2732d-acf2-48c5-b4bb-e156b3990762",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'Imagenet_resize'\n",
    "testsetImagenet = torchvision.datasets.ImageFolder(\"/home/mydir/data/{}\".format(dataName), transform=transform)\n",
    "testloaderImagenet = torch.utils.data.DataLoader(testsetout, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b98aebe3-ec37-4338-82f3-5bd26325327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'LSUN_resize'\n",
    "testsetLSUN = torchvision.datasets.ImageFolder(\"/home/mydir/data/{}\".format(dataName), transform=transform)\n",
    "testloaderLSUN = torch.utils.data.DataLoader(testsetout, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a0760-e966-447a-99cb-c082c4b19e84",
   "metadata": {},
   "source": [
    "At the last convolutional layer, the number of activations is 21,888 (=342x8x8).\n",
    "1. `dense10_cifar`에 대해 cifar data 10000장의 activations를 모으기\n",
    "2. `dense10_cifar`에 대해 `Imagenet_resize` 10000장의 activations를 모으기\n",
    "3. `dense10_cifar`에 대해 `LSUN_resize` 10000장의 activations를 모으기\n",
    "4. `dense10_cifar`에 대해 `gaussian noize` 10000장의 activations를 모으기\n",
    "5. `dense10_cifar`에 대해 `uniform noize` 10000장의 activations를 모으기\n",
    "6. 위의 1-5단계를 `dense10_svhn`에 대해 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b294cf8a-b428-4e6d-b15c-e964a4034c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"DEVICE : {DEVICE}\")\n",
    "\n",
    "def take_act_from_last_conv(model, val_loader):\n",
    "    model.eval() # using this, the dropouts turn off\n",
    "    activations = None\n",
    "    \n",
    "    with torch.no_grad(): # turn of auto-tracking of gradient\n",
    "        for image, label in val_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            \n",
    "            model(image)\n",
    "            activation = result_of_cifarnet.features.reshape(-1)\n",
    "            \n",
    "            if activations is None:\n",
    "                activations = activation\n",
    "            else:\n",
    "                activations = np.vstack([activations, activation])\n",
    "            \n",
    "            if len(activations) == 10000:\n",
    "                break\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4beb32e-72dc-41f9-8774-1f9b4d1cfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense10_cifar.cuda()\n",
    "result_of_cifarnet = LayerResult(dense10_cifar)\n",
    "in_output_cifar = take_act_from_last_conv(dense10_cifar, testloaderIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a69988c3-cebc-4ec9-b5ea-50b5a9f3a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_output_Imagenet_incifarnet = take_act_from_last_conv(dense10_cifar, testloaderImagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faa5d2-5aea-4f41-856b-374b897b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_output_LSUN_incifarnet = take_act_from_last_conv(dense10_cifar, testloaderLSUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "aa6e0e7f-faec-48ea-a0cf-f0391d6dc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(in_output_cifar)\n",
    "x.to_csv('in_output_cifar.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ca9f2-faa0-4dd1-a565-9e7ad2292c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(out_output_Imagenet_incifarnet)\n",
    "x.to_csv('out_output_Imagenet_incifarnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442621b0-2de8-406b-b0d1-9ba7f229822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(out_output_LSUN_incifarnet)\n",
    "x.to_csv('out_output_LSUN_incifarnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cf359d94-8674-46da-9b89-8df79d838d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cifar = pd.DataFrame(in_output_cifar)\n",
    "cov_cifar = in_cifar.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "692d546e-b99d-4aa6-a411-5fae0c0e2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_cifar = pd.DataFrame(out_output_Imagenet_incifarnet)\n",
    "cov_imagenet = imagenet_cifar.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "dfecfa6b-20f5-4f3c-87b7-0154445a68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSUN_cifar = pd.DataFrame(out_output_LSUN_incifarnet)\n",
    "cov_LSUN = LSUN_cifar.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1495b1c0-aec5-4f47-be71-c8cfe93abcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2721061"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(cov_imagenet - cov_cifar) > 0.01).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7edb578c-5b38-47c1-ae14-890561d80a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(cov_imagenet - cov_LSUN) > 0.001).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "79990a0a-e45f-44cb-83a7-65440c293b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21878</th>\n",
       "      <th>21879</th>\n",
       "      <th>21880</th>\n",
       "      <th>21881</th>\n",
       "      <th>21882</th>\n",
       "      <th>21883</th>\n",
       "      <th>21884</th>\n",
       "      <th>21885</th>\n",
       "      <th>21886</th>\n",
       "      <th>21887</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012458</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21883</th>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21884</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.003834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21886</th>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.004120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.003050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21888 rows × 21888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6      \\\n",
       "0      0.012458  0.007895  0.005120  0.004277  0.004134  0.003969  0.004101   \n",
       "1      0.007895  0.012979  0.008177  0.005209  0.004428  0.004318  0.004200   \n",
       "2      0.005120  0.008177  0.013290  0.008307  0.005550  0.004692  0.004100   \n",
       "3      0.004277  0.005209  0.008307  0.013340  0.008568  0.005386  0.004426   \n",
       "4      0.004134  0.004428  0.005550  0.008568  0.013799  0.008492  0.005069   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21883 -0.000061  0.000095  0.000081 -0.000250 -0.000113  0.000193  0.000317   \n",
       "21884  0.000058  0.000114  0.000078 -0.000225 -0.000149  0.000161  0.000343   \n",
       "21885  0.000113  0.000084  0.000042 -0.000200 -0.000220 -0.000017  0.000150   \n",
       "21886  0.000157  0.000079  0.000096 -0.000012 -0.000104  0.000013  0.000048   \n",
       "21887  0.000116  0.000118  0.000139  0.000067 -0.000011  0.000016  0.000045   \n",
       "\n",
       "          7         8         9      ...     21878     21879     21880  \\\n",
       "0      0.004849  0.006142  0.004094  ... -0.000046 -0.000034 -0.000149   \n",
       "1      0.003932  0.004191  0.004491  ... -0.000084 -0.000028 -0.000155   \n",
       "2      0.003711  0.003415  0.003219  ... -0.000069  0.000011 -0.000092   \n",
       "3      0.003742  0.003092  0.003098  ... -0.000162 -0.000065 -0.000079   \n",
       "4      0.004063  0.003096  0.002817  ... -0.000126 -0.000058 -0.000020   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21883 -0.000022 -0.000273 -0.000335  ...  0.006740  0.003482  0.003034   \n",
       "21884  0.000045 -0.000109 -0.000240  ...  0.008401  0.004019  0.002469   \n",
       "21885  0.000053 -0.000111 -0.000253  ...  0.009347  0.005075  0.002131   \n",
       "21886  0.000096 -0.000051 -0.000199  ...  0.008642  0.005190  0.001662   \n",
       "21887  0.000069  0.000014 -0.000076  ...  0.005028  0.003647  0.000979   \n",
       "\n",
       "          21881     21882     21883     21884     21885     21886     21887  \n",
       "0     -0.000203 -0.000127 -0.000061  0.000058  0.000113  0.000157  0.000116  \n",
       "1     -0.000175 -0.000027  0.000095  0.000114  0.000084  0.000079  0.000118  \n",
       "2     -0.000102  0.000016  0.000081  0.000078  0.000042  0.000096  0.000139  \n",
       "3     -0.000200 -0.000243 -0.000250 -0.000225 -0.000200 -0.000012  0.000067  \n",
       "4     -0.000099 -0.000037 -0.000113 -0.000149 -0.000220 -0.000104 -0.000011  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21883  0.006298  0.009022  0.010408  0.009388  0.007246  0.004487  0.002226  \n",
       "21884  0.004730  0.007490  0.009388  0.010563  0.008847  0.006020  0.002756  \n",
       "21885  0.003827  0.005458  0.007246  0.008847  0.009387  0.007163  0.003834  \n",
       "21886  0.002880  0.003752  0.004487  0.006020  0.007163  0.006949  0.004120  \n",
       "21887  0.001643  0.002038  0.002226  0.002756  0.003834  0.004120  0.003050  \n",
       "\n",
       "[21888 rows x 21888 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "82c4b26e-154f-4a0b-ae57-736b0b07f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense10_svhn.cuda()\n",
    "result_of_svhnnet = LayerResult(dense10_svhn)\n",
    "in_output_svhn = take_act_from_last_conv(dense10_svhn, testloaderSVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e4d82f08-dcd3-4819-bc9e-ba9eac11e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_output_Imagenet_insvhnnet = take_act_from_last_conv(dense10_svhn, testloaderImagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "400377c6-9af4-4f1b-843a-f5d9b02a1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_output_LSUN_insvhnnet = take_act_from_last_conv(dense10_svhn, testloaderLSUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d909193b-4f21-461a-b680-633d86c5f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(in_output_svhn)\n",
    "x.to_csv('in_output_svhn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b6596bd9-1c55-47a0-aa78-a56e5ccf87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(out_output_Imagenet_insvhnnet)\n",
    "x.to_csv('out_output_Imagenet_insvhnnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "22d1a402-b553-4c9a-9dc7-0dbb3eac0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(out_output_LSUN_insvhnnet)\n",
    "x.to_csv('out_output_LSUN_insvhnnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb514964-53ea-4aa8-a3d0-93f8ecb8bb23",
   "metadata": {},
   "source": [
    "## Below plots are some either train data or their activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2366fb7a-f5d7-4cc5-a692-1cea9c54d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXuUlEQVR4nO3de5BV1ZUG8G9Jg6gYG+gWegBp8E3ECGkZUbEwRgNIlc/xUUmGjJTtxEdpjU6CWlFTPqIpH9FydGyFEh9RVFBRMSNjiKDxQQtCI60RsIlNGtoHHSAICqz54xzKhjlr3dun7z0X3N+viqLZq/c5+56+i9v3rLv3FlUFEX377VHqARBRNpjsRIFgshMFgslOFAgmO1EgmOxEgSjrTGcRGQPgbgBdADykqrd637+PiJYbsa9TnL9Lij4A8JUTW5vifNUD+5h9uvf4jn28bnubsbI9OvWj2S19vnqVGWta5f1k9nRi1uuZd317pjgeAGxzYl6Ju4fRvtnpYz2LW6G6TpIikrbOLiJdAPwFwMkAmgHMB3C+qi61+vQT0YuN2GrnXFuM9vI8xpnkEyf2tBOzngKTH7rS7HP4qDFmrMeAI81YxV77m7Hd+9exrWZk6q3XmbGfXf2Mc8wDnZj1H4H9HzRwuhOzEhMANjgx+3GjbFRy+5blzvH+arRfCdVlicnemefNCADLVHWFqn4F4EkAp3XieERURJ1J9n7Y8UWyOW4jol1Q0d8YikgtgFoA2K/YJyMiU2de2VcBGNDu3/3jth2oap2q1qhqzT6dOBkRdU5nkn0+gINFZJCIdANwHoCZhRkWERVa6rvxACAi4wD8DlFVaoqq3ux9f38RvcyINaU4f7kT896fPOrEVqYYh+fAEy83Y8vnPOv0bHVim1KPJ0m/vmebsWNO+YkZO/nM8WZs1LjkQuVBXe1xdLNDrnec2D8fuzA58Kb9cwEOcWLebanuTsz7maV5N231+S+oNifeje/Ue3ZVnQVgVmeOQUTZ2L1LtkSUNyY7USCY7ESBYLITBYLJThSITKdWdQXQN0U/ayKMV+jwHpg3XaHQls+524yd9B9PmrHm5s/N2MeNK8xY7ZnJE29GH21PFunpzBpbu6HcjLWV2fMOGz5Kbv/E+cEM6m6XGzc5P9Etlb3M2KnXD0tsf2mM93nOeU7Mm0Az0In1dmJrjHb7OWBbZ0b4yk4UCCY7USCY7ESBYLITBYLJThSITO/Gi3PC/k4/q88Aox3w15L7oROb5sTSuOr6W8zYEaPsCRcVVYeascpKe+26wyqT270f9CZrhSMAvZzl2FqdcsgHRsmj7EtnHKv/YcbK1raZse6r7Uf3b1XJawDWXzvV7LPm5ovMmD/txluyypvgPdho9+78W0tW2a/ffGUnCgSTnSgQTHaiQDDZiQLBZCcKBJOdKBCdWoOuowaI6BVGLM3qXV65zjteU8pYo9F+uFPX+pdaO9ZjwAFm7LChI8xYfYNdojru6pftExp6j7zEjD3wG3u3m0HDB9kHNX4AZc5SbOVbnF1TvrSmQwFtm+yJPGVGKXLhevtUtb+uN2Mb6ybaHV327j/pNjKzJsnMg2pbwXeEIaLdCJOdKBBMdqJAMNmJAsFkJwoEk50oEJ3d/qkJwHpEO81vUdUa7/v/SUStwkW508+aS+T1aXNiXlmuwolZa9etTtEnV+wIJ+b5jdH+fsrjpVY9NrH51HHJa+QBwKBB9hpub85fYMa6d7dnm114wY8T26/9T7ukuNabbXbw6WZo4+8n2/1gj9/eUsouKQKbjfa3oLqu8Ns/xU5U1c8KcBwiKiL+Gk8UiM4muwJ4RUTeFRHns2JEVGqd/TX+eFVdJSL7A5gtIh+o6tz23xD/J1ALAMlrhhBRFjr1yq6qq+K/WwE8C+D/faBbVetUtUZVa7yFeYiouFInu4jsIyL7bv8awCkAlhRqYERUWKlLbyIyGNGrORC9Hfi9qt7s9TlARH9pxNJs5VTujtDmTLxKtW2Ud7xmJ+YtTzjSiXnlwc+MBzDbnjSGOc7x3uxuz9batmmx03PX8PBzyY9uwmmjMx2HDJluBxvPNgJDnCNaz7pmqG4ubOlNVVcA+F7a/kSULZbeiALBZCcKBJOdKBBMdqJAMNmJApHpXm/b4M/0snglKot3Hu9BeyXANMfzxnGTEzvQiV3oxKqNEps3i26L86A3ldnltbEX/8KMzWtMnpX12pylZp8+w442Y+PHDTdjD910lhnbVby41B7jeEmeIQh4i4dazzq7xspXdqJAMNmJAsFkJwoEk50oEEx2okBkuv1TPxG92Ih5kzss3p1zZ96HG+ub4nzeGnQTWq+xg5XXmSGRNHWBwvu+EzvMma1TOfSixPbfTbHvxv9h0Vwz9iNvTkiBfeXE9jzrPjv4irPO3IbnnKNaWzl5dR77Wayq3P6JKGRMdqJAMNmJAsFkJwoEk50oEEx2okBkWnrrL6KXGTFvwohVDvMmyHjlNa+g4cWsbW+OHmb3OXZByuu73g5Nv+MeM/b047cktk9btsbs09sZhlUUyuVQo5bafdDpZp9F858zY4V+no6+t9WMvXbZIU7Pvzsxe70+/0qucmIdx9IbUeCY7ESBYLITBYLJThQIJjtRIJjsRIHIuQadiEwBMB5Aq6oeEbf1AjANQDWAJgDnqOraXMfaA/bMsTannxXzZspVOcFGq4YG/4I8bbRfsdDuo5++ZQcrj7FjDX+yY42TzdCm5uQSmzd7raLanmE3dPiJZqxuhr1G2ofGNT61aoXZZ5EZAapPucqMNb1yuxmTEcYstfn2NQS80ptXQvO2Lt3TiRW29GbJ55X9YQBjdmqbBOBVVT0YwKvxv4loF5Yz2eP91r/Yqfk0AFPjr6cCOL2wwyKiQkv7nr2PqrbEX68G0KdA4yGiIun0DTqNPsdofpZRRGpFpF5E6tOsGU9EhZE22deISBUAxH+bHzRW1TpVrVHVmjSbPRBRYaRN9pkAJsRfTwDwfGGGQ0TFkk/p7QkAowFUiEgzgOsB3ArgKRGZCGAlgHPyOZnCno1W7vTbZLSf+69Op6lzzFD/E+xy0jXz7EO+4ZzO8qsR481YdU97llTfAXY57MaZ9pZMV1+cvE3Sufc+bPaBDDVDcx+fYsZud0pvlpca7LF7ysrsspac9bjdcf4lRmA/52z9nNhAJ+aV0LzbWtZj+4fTp+NyJruqnm+ETiroSIioqPgJOqJAMNmJAsFkJwoEk50oEEx2okDkvBtfSOKc0PvAjVV6W/xHu8+Rt9rltUed8ppXTLIWZrxsrF2qOXn4j83YQX0PNWPd92ozY3++wN5kbe9BxlicmX6otEMNDe84HW0HGu2fOn3WObHjnXLp8slv5jOknXhPfW+fPevZCNiPGgD2T3HM+U6fjuMrO1EgmOxEgWCyEwWCyU4UCCY7USCY7ESByHSvt8EieqMRK3f6tRnty5w+q53YI07M2yPu5Ork9mHDjzb7fLzAnrk0qMou2d14+0X2QI49y44Z/jh9uhm75+5nzNhnLS+YsTeWFXZWllfyenfdl2bs++f+wT7ky2ONgDezzZuhttKJeTPpvH3gLM+l6MO93oiCx2QnCgSTnSgQTHaiQDDZiQKR6USYPWBPePEGYsW87Z8anNhGJ+Z5qclqTzlhoWmpGXriuNlm7OcX2xNhzpiQvObaPQ/Ya/J98LG9dtqHzenuuH/HaD9x6GCzzy0P22Mcsq9zsqbkLa98Xt0lzfEA4G9OzFu7zrr772WFN/5kfGUnCgSTnSgQTHaiQDDZiQLBZCcKBJOdKBD5bP80BcB4AK2qekTcdgOAC/HNkmLXqOqsnMfK54QJrOkR3kphbSnOsytZ7sSuus9ec+2FWcnbKx093F7D7a1mZ1G+lMaemTwB5b7f3Gz26VVVnvJsfy9wH6+s5U12sbeoAuwyK2Dtb2ytegikKQ/m88r+MIAxCe13qepR8Z+ciU5EpZUz2VV1LoAvMhgLERVRZ96zXyoii0Vkioj0LNiIiKgo0ib7/YgWyT4KQAuAO6xvFJFaEakXkfo076yIqDBSJbuqrlHVraq6DcCDAEY431unqjWqWuPd2iCi4kqV7CJS1e6fZwBYUpjhEFGx5FN6ewLAaAAVItIM4HoAo0XkKAAKoAmAs2DaN7bBLjJ4ZTRrkN46c6/mM6BvoXlNybPUKipXmH3SzvHyTJuRvJHWtBl/NvtMrL3SjI2d+Cv7ZB95bxCtZ08Xp4+3xZPHK715Y7Tmgh7g9On4Ty1nsqvq+QnNkzt8JiIqKX6CjigQTHaiQDDZiQLBZCcKBJOdKBCZbv90gIj+0oh5xQ5rDlKj02dqfkOi3cXhl9uxxsecjlbBySoCA4C3yKY3E83bUsorlVkzEr2ssBbn3ADVLdz+iShkTHaiQDDZiQLBZCcKBJOdKBBMdqJAZLrXm8IuJngz2D4y2p/v3HCok051NtvrOzR5/7IX59glKHceV+Pd+Q0qb2mf+t6qDGljexrtXinPmif6P2YPvrITBYLJThQIJjtRIJjsRIFgshMFItO78R5vWkKWd9379bfvgK5qXpXhSGwTL5hoxnpWJo9/k7PK38ezbjNjlx1sr502ZoYZQj/jrntf5xm3xtt1KTXrcXuTTLy15MpTnCvXMbca7UOdPtb6dG+YPfjKThQIJjtRIJjsRIFgshMFgslOFAgmO1Eg8tn+aQCARwD0QTSXpU5V7xaRXgCmAahGtAXUOaq61jvWVgBtRqwl7yEXQvIkDQA4ZvgQM3byhDGJ7Q/eYW+Q41WT6h57wIyNOKvW6bnRjqxtS2xvbrFLaA397cLn60/d4ozDZhUpu1c4E0JWF2Of38FG++dOH69M5k1o8bZr8h6b9Szx+lhX+CuzRz6v7FsAXKmqQwAcA+ASERkCYBKAV1X1YERbq03K41hEVCI5k11VW1R1Qfz1ekSLuvYDcBq+WcR1KoDTizRGIiqADr1nF5FqAMMAvA2gj6pu/+17NbzfjYmo5PJOdhHpAWA6gCtUdV37mEaLzycuQC8itSJSLyL13mrcRFRceSW7iHRFlOiPq+r2T0SvEZGqOF4FoDWpr6rWqWqNqtZ4tz2IqLhyJruICKL92BtV9c52oZkAJsRfTwBXiSLapeXc/klEjgcwD0ADgG1x8zWI3rc/hajesBJR6e0L71gVIjreiH3g9HvbHaEl7XpgfzUj3zUKlYcNtco7wIZNdvFt5MhjzViPSnuboc/W2zO2Wj5LLte817DC7DNqpF1uXNuy2Iw9+7Ids4uDWbMfm827/XSIE/PeqHZJ0c+bmWf1qYfqusTtn3LW2VX1dQCJnQGclKs/Ee0a+Ak6okAw2YkCwWQnCgSTnSgQTHaiQGS64KQ4Jyz8QLwZQ5tTHfF9o4r2/kK7rDXQeWDDRp5gxhrescta0+fMsw9q6F1hz8i6d8pjZuzQ/naZsrKH/eBWbijK6pEG79ljxbzxeR//OtCJve/ErEUlAXsGnvcctsZol9L5yk4UCCY7USCY7ESBYLITBYLJThQIJjtRIHLOeiuk3iI61og1O/1eK8Zg6FvEm9lmlai8fdkGOrFRTix5f7uIXUoFlhrt3hjbjPZmqG5OnLjGV3aiQDDZiQLBZCcKBJOdKBBMdqJA7DITYaqdfrwbTz5vzTjrGben0+dIJ5ZmG6dcMevuv1dlsNa0m2q085WdKBhMdqJAMNmJAsFkJwoEk50oEEx2okDkLL2JyAAAjyCqbyiAOlW9W0RuAHAhgE/jb71GVWd5x/oa0d7OScqdftaqX8u9k1FAvLKWtfaeV67zynLWpBXA366phxMzpof1dybdlBnbP/3tBbuLM4LttgC4UlUXiMi+AN4Vkdlx7C5VvT2PYxBRieWz11sLgJb46/Ui0gigX7EHRkSF1aH37CJSDWAYvtlY9VIRWSwiU0SkZ6EHR0SFk3eyi0gPANMBXKGq6wDcj+jt9FGIXvnvMPrViki9iNR/1fnxElFKeSW7iHRFlOiPq+oMAFDVNaq6VVW3AXgQwIikvqpap6o1qlrTrVCjJqIOy5nsIiIAJgNoVNU727VXtfu2MwAsKfzwiKhQ8rkbfxyAnwJoEJH34rZrAJwvIkchKsc1Abgo14G2AthgxLzVtg4y2ll6C4m9fRXQ24lZW30ZpSsA9nZMgF/ma3ViP7RDB01Ibp/olAAbjfaX9ja75HM3/nVEs1N35tbUiWjXwk/QEQWCyU4UCCY7USCY7ESBYLITBWKXWXDSKskB9lwi7wP6q/IaERWLtYTi1U6fF5z660ubvFKZN4PNWyDS4hWCrVIeAIx3DvkzO7bFKLE1OKdqNMp8G+3SIF/ZiQLBZCcKBJOdKBBMdqJAMNmJAsFkJwpEpqW3PeAXNSxWn2qnz1ontjHFGKhjzjfaq71O3nqN7lPVi1kH3c/p482ic8prfc+1Y6v/ZMeajLE0eWXDl60TmT34yk4UCCY7USCY7ESBYLITBYLJThQIJjtRIDItvXl7vXnL+Fm7ZHmDP9yJeeW/JifGmXQ7+pETqzDam50+c9yzrXFif3Fi1qKN3uw1pwbY/yd2rO0L55iPOTFr1t48p491PdrMHnxlJwoEk50oEEx2okAw2YkCwWQnCkTOu/Ei0h3AXES3NcsAPKOq14vIIABPIpo18C6An6qqu1Hrl7CX1drm9LOmJfR1+nhr2ll3igF7qynvfJ85fVY6sd3Bvzuxr52YVXXx5rp4FRmfN3HFuhvf5vQ5zw4NsrdXwrxfOMec7MQsRzox6zHbNaN8Xtk3A/iBqn4P0fbMY0TkGAC3AbhLVQ9CNMlsYh7HIqISyZnsGtn+Qtk1/qMAfgDgmbh9KoDTizFAIiqMfPdn7xLv4NoKYDaiDVTbVHX7b17N8Fd2JqISyyvZVXWrqh4FoD+AEQAOy/cEIlIrIvUiUp9uiERUCB26G6+qbYg+1TgSQLmIbL/B1x/GnQFVrVPVGlWt6cxAiahzcia7iFSKSHn89V4ATka0FfwcAGfH3zYBwPNFGiMRFUA+E2GqAEwVkS6I/nN4SlVfFJGlAJ4UkZsALESetQWvxGb53Ghf7/TxJrt4D7otxTHLnT5eOWlXmVjzXSf2iRNrc2JDjfZPnT5u3db9qVnPEK/fKLvLSOeX0PnenkxewfdsJ7bCaF/g9Om4nMmuqosBDEtoX4Ho/TsR7Qb4CTqiQDDZiQLBZCcKBJOdKBBMdqJAiKpmdzKRT/HNRLAK+BPGssJx7Ijj2NHuNo6BqlqZFMg02Xc4sUj9rvCpOo6D4whlHPw1nigQTHaiQJQy2etKeO72OI4dcRw7+taMo2Tv2YkoW/w1nigQJUl2ERkjIh+KyDIRmVSKMcTjaBKRBhF5L8vFNURkioi0isiSdm29RGS2iHwU/92zROO4QURWxdfkPREZl8E4BojIHBFZKiLvi8jlcXum18QZR6bXRES6i8g7IrIoHsev4/ZBIvJ2nDfTRKRbhw6sqpn+AdAF0bJWgwF0A7AIwJCsxxGPpQlARQnOewKA4QCWtGv7LYBJ8deTANxWonHcAOCqjK9HFYDh8df7Itq8bUjW18QZR6bXBIAA6BF/3RXA2wCOAfAUgPPi9v8G8POOHLcUr+wjACxT1RUaLT39JIDTSjCOklHVuQB23gXwNEQLdwIZLeBpjCNzqtqiqgvir9cjWhylHzK+Js44MqWRgi/yWopk74cd10Qo5WKVCuAVEXlXRGpLNIbt+qhqS/z1athbe2bhUhFZHP+aX/S3E+2JSDWi9RPeRgmvyU7jADK+JsVY5DX0G3THq+pwAGMBXCIiJ5R6QED0Pzui/4hK4X4AByLaI6AFwB1ZnVhEegCYDuAKVV3XPpblNUkYR+bXRDuxyKulFMm+CsCAdv82F6ssNlVdFf/dCuBZlHblnTUiUgUA8d+tpRiEqq6Jn2jbADyIjK6JiHRFlGCPq+qMuDnza5I0jlJdk/jcbejgIq+WUiT7fAAHx3cWuyHaa2dm1oMQkX1EZN/tXwM4BcASv1dRzUS0cCdQwgU8tydX7AxkcE1ERBCtYdioqne2C2V6TaxxZH1NirbIa1Z3GHe62zgO0Z3O5QCuLdEYBiOqBCwC8H6W4wDwBKJfB79G9N5rIqLNu14F8BGA/wXQq0TjeBTRlnyLESVbVQbjOB7Rr+iLAbwX/xmX9TVxxpHpNUG0ydvC+HxLAFzX7jn7DoBlAJ4GsGdHjstP0BEFIvQbdETBYLITBYLJThQIJjtRIJjsRIFgshMFgslOFAgmO1Eg/g8CTLnfY1K96gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 in cifar-10\n",
    "plt.imshow(testset[0][0].permute(2,1,0))\n",
    "print(testset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "83c4e66f-c91d-495c-ba1f-8d0fe9f2adb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb40e6ef60>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense10_cifar.cuda()\n",
    "result = LayerResult(dense10_cifar)\n",
    "\n",
    "dense10_cifar(testset[0][0].unsqueeze(0).cuda())\n",
    "activations = result.features\n",
    "plt.imshow(activations.squeeze().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d3e209f-2fe8-4452-b84d-650b0140af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(_test_ds[0][0]))\n",
    "print(_test_ds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2950a1a-7e61-4123-aafd-77a991b8df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb1133b748>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(activations.squeeze().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1bb57db-f931-4bc6-a695-95fba0d891a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(_test_ds[1][0]))\n",
    "print(_test_ds[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a14d1f58-3805-4870-ae9d-925cb2782ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb560447b8>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense10_svhn.cuda()\n",
    "result = LayerResult(dense10_svhn)\n",
    "\n",
    "dense10_svhn(test_ds[0][0].unsqueeze(0).cuda())\n",
    "activations = result.features\n",
    "plt.imshow(activations.squeeze().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "74bd15e5-2926-4f8c-9862-a031769c5a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb56089f28>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testsetout[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a1185c88-27e0-4b91-bc21-ca988e0a5815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb40e828d0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense10_svhn.cuda()\n",
    "result = LayerResult(dense10_svhn)\n",
    "\n",
    "dense10_svhn(testsetout[0][0].unsqueeze(0).cuda())\n",
    "activations = result.features\n",
    "plt.imshow(activations.squeeze().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dae236d8-e161-45c6-8530-997ffa04c948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb11988518>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense10_svhn(testsetout[1][0].unsqueeze(0).cuda())\n",
    "activations = result.features\n",
    "plt.imshow(activations.squeeze().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bc8d9-613a-4e29-8213-9a20f99465b4",
   "metadata": {},
   "source": [
    "`testlodaerIn == testlodaer10 == Cifar-10`\n",
    "\n",
    "`length == 10000 && batch_size == 1, image 한장과 정답레이블 한개가 같이 내재`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e996997-fa89-4f47-93ff-6605d50d9bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j, data in enumerate(testloaderIn):\n",
    "    display(j)\n",
    "    display(type(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4a454-ea48-4515-994c-b7d57b4f0080",
   "metadata": {},
   "source": [
    "# End of Little Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf0a38-6504-4322-ba1f-de0d7cfdb695",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 딥러닝 코딩 step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155922e3-fa85-4dd8-8f7c-742bebc5baec",
   "metadata": {},
   "source": [
    "## step1. 데이터 전처리 \n",
    "1. `sklearn.model_selection.train_test_split` 메소드를 이용하여 train, val, test 분리\n",
    "     - 필요에 따라 `torch.utils.data.Dataset`을 상속(필수 overriding: `__init__`, `__len__`, `__getitem__`)하여 custom dataset을 만들어야 한다. \n",
    "2. `torch.utils.data.DataLoader`를 이용하여 mini batch 호출을 정의한다.\n",
    "3. `model` 정의: 원하는 모델을 만들기(classifier든, detection이든, segmentation이든)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1f334c-f28c-44e3-ad3f-7e14d903545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class svhnDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        super(svhnDataset, self).__init__()\n",
    "        self.img_list = []\n",
    "        self.label_list = []\n",
    "        for data_pair in data:\n",
    "            self.img_list.append(data_pair[0])\n",
    "            self.label_list.append(data_pair[1])\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d38e27a9-6398-4769-9ad8-4c860b59ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /home/mydir/data/train_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f652874959d419e96e104465bf88f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182040794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/mydir/data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "path2data = '/home/mydir/data'\n",
    "\n",
    "train_transform =transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((125.3/255, 123.0/255, 113.9/255), (63.0/255, 62.1/255.0, 66.7/255.0)),\n",
    "    transforms.Resize(32)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((125.3/255, 123.0/255, 113.9/255), (63.0/255, 62.1/255.0, 66.7/255.0)),\n",
    "    transforms.Resize(32)\n",
    "])\n",
    "\n",
    "_train_ds = datasets.SVHN(root=path2data, split='train', download=True)\n",
    "_test_ds = datasets.SVHN(root=path2data, split='test', download=True)\n",
    "\n",
    "train_ds = svhnDataset(data=_train_ds, transform=train_transform)\n",
    "test_ds = svhnDataset(data=_test_ds, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1d111ba1-c7cc-41a6-877e-2926abada780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "trainloaderSVHN = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last = False)\n",
    "testloaderSVHN = DataLoader(test_ds, batch_size=1, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "15dd13c1-91ad-4810-b764-b2970465ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "path2model = './odin/models/'\n",
    "model_name = 'densenet10.pth'\n",
    "dense10_cifar = torch.load(path2model+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0668d690-1941-4559-8381-c1f6ee09831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([3, 3, 32, 32])\n",
      "Stem output size: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "# check whether the model do inference well or not\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn((3, 3, 32, 32)).to(device)\n",
    "# check MODEL\n",
    "model = dense10_cifar.to(device)\n",
    "output_Stem = model(x)\n",
    "print('Input size:', x.size())\n",
    "print('Stem output size:', output_Stem.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659799b-dc78-4cd8-88af-bd44aab57dfb",
   "metadata": {},
   "source": [
    "pretrained model `densenet10.pth`가 pytorch 버전 문제인지 일부 기능이 안된다. `print(densenet10)`을 실행하면 `KeyError: 'track_running_stats`라는 error를 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "04ee58c5-de63-412a-957e-6728a6c88bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 차이 때문인지, 아래와 같은 오류가 발생.\n",
    "# AttributeError: 'BatchNorm2d' object has no attribute 'track_running_stats'`\n",
    "# AttributeError: 'BatchNorm2d' object has no attribute 'num_batches_tracked'`\n",
    "# 주어진 model 내의 BatchNorm2d module의 위의 속성들을 True로 바꿈으로써 해결 가능\n",
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = True\n",
    "        module.num_batches_tracked = True\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "            \n",
    "recursion_change_bn(dense10_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4b57f-40f7-42f4-853e-231592fa2093",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `change_bn`의 작동 원리가 뭘까?\n",
    "`module._modules`는 무엇일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce939f4-8e19-448f-ac11-be38b6fa6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursion_change_bn(module):\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.track_running_stats = True\n",
    "#         module.num_batches_tracked = True\n",
    "    else:\n",
    "        for i, (name, module1) in enumerate(module._modules.items()):\n",
    "            module1 = recursion_change_bn(module1)\n",
    "            \n",
    "recursion_change_bn(dense10_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa00658a-d972-48c4-b590-2a2a04a80589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dense10_cifar._modules)#.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd211b1-4d7c-4d63-9d09-8e2e355894d9",
   "metadata": {},
   "source": [
    "### End of `change_bn`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a3ee4cb8-bd7e-46c9-b558-f11c53b22598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 200\n",
    "DEVICE = None\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"DEVICE : {DEVICE}\")\n",
    "\n",
    "model = dense10_cifar.to(DEVICE)\n",
    "optimizer = torch.optim.SGD(dense10_cifar.parameters(), lr=0.01, momentum=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "def train(model, train_loader, val_loader, topk=3):\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    start = int(time.time())\n",
    "    result_dict = {'EPOCH':[], 'Train Loss':[], 'Train Top 1 Acc':[], 'Train Top k Acc':[], 'Val Loss':[], 'Val Top 1 Acc':[], 'Val Top k Acc':[], 'Time':[]}\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        \n",
    "        train_loss, train_top1_acc, train_topk_acc = _train(model, train_loader, topk=topk)\n",
    "        scheduler.step()\n",
    "        val_loss, val_top1_acc, val_topk_acc = _evaluate(model, val_loader, topk=topk)\n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(model, '../models/densenet10_svhn_epoch'+str(epoch))\n",
    "        cur_time = int(time.time())\n",
    "        overtime = cur_time - start # the type of `time` is float\n",
    "#         print(f'Epoch: {epoch:>3}/{EPOCHS}  Train Loss: {train_loss:.3f}  Train Top 1 Acc: {train_top1_acc:.2f}%  Val Loss: {val_loss:.3f}  Val Top 1 Acc: {val_top1_acc:.2f}%')\n",
    "#         print(f'                                   Train Top 3 Acc: {train_topk_acc:.2f}%                   Val Top 3 Acc: {val_topk_acc:.2f}%   Overtime: {overtime//3600:>2}H {(overtime//60)%60:>2}M {overtime%60:>2}S')\n",
    "        result_dict['EPOCH'].append(epoch)\n",
    "        result_dict['Train Loss'].append(train_loss)\n",
    "        result_dict['Train Top 1 Acc'].append(train_top1_acc)\n",
    "        result_dict['Train Top k Acc'].append(train_topk_acc)\n",
    "        result_dict['Val Loss'].append(val_loss)\n",
    "        result_dict['Val Top 1 Acc'].append(val_top1_acc)\n",
    "        result_dict['Val Top k Acc'].append(val_topk_acc)\n",
    "        result_dict['Time'].append(overtime)\n",
    "    return result_dict\n",
    "\n",
    "def _train(model, train_loader, topk=3):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_top1 = 0\n",
    "    correct_topk = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()               # global `optimizer`(gredient descent method)\n",
    "        pred_proba = model(image)\n",
    "        loss = criterion(pred_proba, label) # global `criterion`(loss function)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # cummulative sum of loss\n",
    "        train_loss += loss.item()\n",
    "        # the number of correct top1 prediction\n",
    "        top1_pred = pred_proba.max(1, keepdim=True)[1]\n",
    "        correct_top1 += top1_pred.eq(label.view_as(top1_pred)).sum().item()\n",
    "        # the number of correct topk prediction\n",
    "        topk_pred = pred_proba.topk(k=topk, dim=1)[1] # len == 2인 tensor인데, index == 0에는 sorted topk proba가 있다.\n",
    "        correct_topk += topk_pred.eq(label.view(-1, 1).expand_as(topk_pred)).sum().item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    top1_accuracy = 100. * correct_top1 / len(train_loader.dataset)\n",
    "    topk_accuracy = 100. * correct_topk / len(train_loader.dataset)\n",
    "    return train_loss, top1_accuracy, topk_accuracy\n",
    "\n",
    "def _evaluate(model, val_loader, topk=3):\n",
    "    model.eval() # using this, the dropouts turn off\n",
    "    val_loss = 0\n",
    "    correct_top1 = 0\n",
    "    correct_topk = 0\n",
    "    \n",
    "    with torch.no_grad(): # turn of auto-tracking of gradient\n",
    "        for image, label in val_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            pred_proba = model(image)\n",
    "            # cummulative sum of loss\n",
    "            val_loss += criterion(pred_proba, label).item()\n",
    "            # the number of correct top1 prediction\n",
    "            top1_pred = pred_proba.max(1, keepdim=True)[1]\n",
    "            correct_top1 += top1_pred.eq(label.view_as(top1_pred)).sum().item()\n",
    "            # the number of correct topk prediction\n",
    "            topk_pred = pred_proba.topk(k=topk, dim=1)[1]\n",
    "            correct_topk += topk_pred.eq(label.view(-1, 1).expand_as(topk_pred)).sum().item()\n",
    "            \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    top1_accuracy = 100. * correct_top1 / len(val_loader.dataset)\n",
    "    topk_accuracy = 100. * correct_topk / len(val_loader.dataset)\n",
    "    return val_loss, top1_accuracy, topk_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52f19e-0e9f-4d78-ac3a-5ea227a3244e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Start of Experiments\n",
    "---\n",
    "#### 아래 셀들은 model의 `callable 함수의 output`과 `loss 함수의 output` 이 어떤 것인지 확인하는 실험과 top-k error에 대한 실험이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "466c9e99-5993-45a7-a6f8-e47715616f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "optimizer = torch.optim.SGD(dense10_cifar.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "dense10_cifar.train()\n",
    "train_loss = 0\n",
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "\n",
    "prediction = None\n",
    "loss_variable1 = None\n",
    "loss_varaibel2 = None\n",
    "label = None\n",
    "\n",
    "for batch_idx, (image, label) in enumerate(train_loader):\n",
    "    image = image.to(DEVICE)\n",
    "    label = label.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(image)\n",
    "    loss_variable1 = criterion1(prediction, label)\n",
    "    loss_variable2 = criterion2(prediction, label)\n",
    "    \n",
    "    loss_variable1.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b1553-ec8a-4e9a-9af7-0a6358d0ae06",
   "metadata": {},
   "source": [
    "##### 아래와 같은 방식으로 top 1 predictioin value에 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "81c36eea-d5ce-43c6-a76a-8656b6da0a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.8109, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = output.argmax(1, keepdim=True)\n",
    "# 또는\n",
    "pred = output.max(1, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba87c4-0275-4069-8505-08a2c0d8bdca",
   "metadata": {},
   "source": [
    "model의 callable method의 output은 `torch.Tensor`이다. `torch.Tensor.max()`, `torch.Tensor.argmas()` 모두 첫번째 parameter는 `dim`이다. ~~이것이 무엇을 의미하는지 정확히 모르겠다.~~ `dim`은 `max`(또는 `argmax`)가 적용될 tensor의 차원의 index를 의미한다. 즉, 해당 차원 방향으로 max value 또는 max index를 찾는 것이다.<br>\n",
    "두번째 parameter는 `keepdim`으로 `bool` type이다. default는 `False`이다. `True`이면 해당 input tensor를 그대로 유지한 채로 return한다.\n",
    "`max()` mothod는 tuple을 return하는데, 첫번째 값에는 `tensro of max value`가, 두번째 값에는 `tensor of index of max value`가 저장된다.\n",
    "<br><br>\n",
    "Appendix: input의 형태가 [A,B,C,D]라고 할 때\n",
    "dim=n 이라고 하면 n번째를 제외한 output이 나오게 되고\n",
    "ex) dim = 2, C가 빠져 [A,B,D]가 나오게 된다.\n",
    "이 C에 해당하는 데이터를 기준으로 최대값 및 인덱스가 튜플로 나오게 된다.\n",
    "```\n",
    "--------------------Example--------------------\n",
    "INPUT : \n",
    "tensor([[[3, 4, 2, 0, 3],\n",
    "         [0, 4, 0, 3, 0],\n",
    "         [2, 0, 4, 3, 3],\n",
    "         [1, 3, 3, 0, 4]],\n",
    "\n",
    "        [[0, 3, 4, 2, 0],\n",
    "         [0, 3, 4, 0, 2],\n",
    "         [4, 0, 3, 2, 2],\n",
    "         [3, 1, 1, 0, 1]],\n",
    "\n",
    "        [[3, 4, 3, 0, 2],\n",
    "         [2, 4, 1, 3, 1],\n",
    "         [4, 0, 1, 1, 4],\n",
    "         [4, 4, 1, 1, 0]]])\n",
    "dim=2\n",
    "torch.return_types.max(\n",
    "values=tensor([[4, 4, 4, 4],\n",
    "        [4, 4, 4, 3],\n",
    "        [4, 4, 4, 4]]),\n",
    "indices=tensor([[1, 1, 2, 4],\n",
    "        [2, 2, 0, 0],\n",
    "        [1, 1, 0, 0]]))\n",
    "dim=1\n",
    "torch.return_types.max(\n",
    "values=tensor([[3, 4, 4, 3, 4],\n",
    "        [4, 3, 4, 2, 2],\n",
    "        [4, 4, 3, 3, 4]]),\n",
    "indices=tensor([[0, 0, 2, 1, 3],\n",
    "        [2, 0, 0, 0, 1],\n",
    "        [2, 0, 0, 1, 2]]))\n",
    "dim=0\n",
    "torch.return_types.max(\n",
    "values=tensor([[3, 4, 4, 2, 3],\n",
    "        [2, 4, 4, 3, 2],\n",
    "        [4, 0, 4, 3, 4],\n",
    "        [4, 4, 3, 1, 4]]),\n",
    "indices=tensor([[0, 0, 1, 1, 0],\n",
    "        [2, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 0, 2],\n",
    "        [2, 2, 0, 2, 0]]))\n",
    "dim= -1\n",
    "torch.return_types.max(\n",
    "values=tensor([[4, 4, 4, 4],\n",
    "        [4, 4, 4, 3],\n",
    "        [4, 4, 4, 4]]),\n",
    "indices=tensor([[1, 1, 2, 4],\n",
    "        [2, 2, 0, 0],\n",
    "        [1, 1, 0, 0]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624bf67-25a8-451c-a825-6202282a4b3a",
   "metadata": {},
   "source": [
    "#### 다음으로 loss function `criterion`의 output에 대해 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c01120-24a1-4bee-80de-cda9a5e68b9b",
   "metadata": {},
   "source": [
    "여전히 `torch.Tensor`이다. 다만, `grad_fn`이라는 속성이 다르다. 해당 속성이 무엇을 의미하는지는 아직 모르겠지만, loss function의 output tensor는 이 속성덕분에 `backward()`가 가능한 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e78befff-37e1-471d-b0af-c03fb84b410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.324499130249023"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_variable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7cd9ea31-66c7-463c-abc7-088d34916c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.535888671875"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_variable1.item() * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "88881490-79de-40f3-93f0-66f083fb8585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.535888671875"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_variable2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c1e47-b448-4143-a4cb-80939b9b4a8b",
   "metadata": {},
   "source": [
    "loss function은 default로 입력으로 받은 batch의 평균 loss를 반환한다(파라미터 중 하나인 `reduction`이 `reduction='mean'`이기때문). 미니배치 평균 loss들의 평균은 전체 batch의 평균 loss와 다르다. 따라서 전체 배치의 loss합산에 batch size(위 코드에서는 `len(train_loader.dataset)`로 구할 수 있음)로 나눠주는 것이 진정 평균 loss이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df9d864-eaf8-4001-a2ce-5f23ed5da6d4",
   "metadata": {},
   "source": [
    "#### About top-5 error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75219aa1-6a07-4a3e-bf52-ccae88eafcd6",
   "metadata": {},
   "source": [
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKiVxY%2Fbtq4wvikM2O%2FwKfU8cCTahrZzQlsYuTk2k%2Fimg.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8a6113b0-0c02-4f02-b083-c6b49eb7dd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8047, -2.2865,  1.6786, -1.5653,  3.0456, -2.6758,  6.6618, -1.9233,\n",
       "         -5.7986,  3.6604],\n",
       "        [-3.0336,  1.3451,  0.8680, -0.2392,  2.8278, -2.3174,  1.4950, -3.9047,\n",
       "         -2.1566,  5.1090]], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9045e36e-8053-4615-bebb-97506ae58336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(values=tensor([[ 6.6618,  3.6604,  3.0456,  1.6786, -0.8047, -1.5653, -1.9233],\n",
       "        [ 5.1090,  2.8278,  1.4950,  1.3451,  0.8680, -0.2392, -2.1566]],\n",
       "       device='cuda:0', grad_fn=<TopkBackward>), indices=tensor([[6, 9, 4, 2, 0, 3, 7],\n",
       "        [9, 4, 6, 1, 2, 3, 8]], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topk_pred = prediction[0:2].topk(k=7, dim=1)\n",
    "display(topk_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "799ae079-cdbb-40e1-bf5d-3b998fb38ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False,  True, False],\n",
       "        [False, False, False, False, False, False,  True]], device='cuda:0')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_pred.eq(label[0:2].view(-1, 1).expand_as(topk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "926989df-b021-4f92-931a-138affe7f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_pred.eq(label[0:2].view(-1, 1).expand_as(topk_pred)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8a215e1c-d962-4157-8ad6-d074c5a9af25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_pred.eq(label[0:2].view(-1, 1).expand_as(topk_pred)).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9fe32-157a-489b-a9f0-95f0f2568e82",
   "metadata": {},
   "source": [
    "### End of Experiments\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6a0e3-a90b-4426-9072-67311053fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = train(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "25c0fe28-2160-4c0c-9b78-7a35fca63172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Top 1 Acc</th>\n",
       "      <th>Train Top k Acc</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Top 1 Acc</th>\n",
       "      <th>Val Top k Acc</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.273483</td>\n",
       "      <td>18.578429</td>\n",
       "      <td>44.375282</td>\n",
       "      <td>2.226622</td>\n",
       "      <td>19.587431</td>\n",
       "      <td>46.550400</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.128706</td>\n",
       "      <td>23.287877</td>\n",
       "      <td>50.123538</td>\n",
       "      <td>1.888511</td>\n",
       "      <td>26.720959</td>\n",
       "      <td>63.929010</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.095759</td>\n",
       "      <td>62.746222</td>\n",
       "      <td>86.348062</td>\n",
       "      <td>1.119816</td>\n",
       "      <td>69.149508</td>\n",
       "      <td>87.234942</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.539728</td>\n",
       "      <td>83.174304</td>\n",
       "      <td>95.013446</td>\n",
       "      <td>0.723782</td>\n",
       "      <td>76.329133</td>\n",
       "      <td>93.853719</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>86.014988</td>\n",
       "      <td>95.951240</td>\n",
       "      <td>0.532208</td>\n",
       "      <td>83.090043</td>\n",
       "      <td>95.440227</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>98.671799</td>\n",
       "      <td>99.931747</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>93.696220</td>\n",
       "      <td>98.413491</td>\n",
       "      <td>16184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>98.716846</td>\n",
       "      <td>99.930382</td>\n",
       "      <td>0.305350</td>\n",
       "      <td>93.980486</td>\n",
       "      <td>98.413491</td>\n",
       "      <td>16267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>0.037555</td>\n",
       "      <td>98.749608</td>\n",
       "      <td>99.916732</td>\n",
       "      <td>0.319139</td>\n",
       "      <td>93.607867</td>\n",
       "      <td>98.436540</td>\n",
       "      <td>16349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>0.036705</td>\n",
       "      <td>98.775544</td>\n",
       "      <td>99.923557</td>\n",
       "      <td>0.319001</td>\n",
       "      <td>93.788414</td>\n",
       "      <td>98.340504</td>\n",
       "      <td>16431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>98.738687</td>\n",
       "      <td>99.938572</td>\n",
       "      <td>0.311095</td>\n",
       "      <td>94.076521</td>\n",
       "      <td>98.505685</td>\n",
       "      <td>16514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EPOCH  Train Loss  Train Top 1 Acc  Train Top k Acc  Val Loss  \\\n",
       "0        1    2.273483        18.578429        44.375282  2.226622   \n",
       "1        2    2.128706        23.287877        50.123538  1.888511   \n",
       "2        3    1.095759        62.746222        86.348062  1.119816   \n",
       "3        4    0.539728        83.174304        95.013446  0.723782   \n",
       "4        5    0.446809        86.014988        95.951240  0.532208   \n",
       "..     ...         ...              ...              ...       ...   \n",
       "195    196    0.038833        98.671799        99.931747  0.316018   \n",
       "196    197    0.037876        98.716846        99.930382  0.305350   \n",
       "197    198    0.037555        98.749608        99.916732  0.319139   \n",
       "198    199    0.036705        98.775544        99.923557  0.319001   \n",
       "199    200    0.037490        98.738687        99.938572  0.311095   \n",
       "\n",
       "     Val Top 1 Acc  Val Top k Acc   Time  \n",
       "0        19.587431      46.550400     81  \n",
       "1        26.720959      63.929010    163  \n",
       "2        69.149508      87.234942    246  \n",
       "3        76.329133      93.853719    328  \n",
       "4        83.090043      95.440227    411  \n",
       "..             ...            ...    ...  \n",
       "195      93.696220      98.413491  16184  \n",
       "196      93.980486      98.413491  16267  \n",
       "197      93.607867      98.436540  16349  \n",
       "198      93.788414      98.340504  16431  \n",
       "199      94.076521      98.505685  16514  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result_dict).to_csv('dense10_svhn_training_history.csv', index=False)\n",
    "result_df = pd.read_csv('dense10_svhn_training_history.csv')\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1f6daa97-a4e3-42c2-ac80-1fe85b0814ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/200  Train Loss: 2.273  Train Top 1 Acc: 18.58%  Val Loss: 2.227  Val Top 1 Acc: 19.59%\n",
      "                                   Train Top 3 Acc: 44.38%                   Val Top 3 Acc: 46.55%   Overtime:  0H  1M 21S\n",
      "Epoch:   2/200  Train Loss: 2.129  Train Top 1 Acc: 23.29%  Val Loss: 1.889  Val Top 1 Acc: 26.72%\n",
      "                                   Train Top 3 Acc: 50.12%                   Val Top 3 Acc: 63.93%   Overtime:  0H  2M 43S\n",
      "Epoch:   3/200  Train Loss: 1.096  Train Top 1 Acc: 62.75%  Val Loss: 1.120  Val Top 1 Acc: 69.15%\n",
      "                                   Train Top 3 Acc: 86.35%                   Val Top 3 Acc: 87.23%   Overtime:  0H  4M  6S\n",
      "Epoch:   4/200  Train Loss: 0.540  Train Top 1 Acc: 83.17%  Val Loss: 0.724  Val Top 1 Acc: 76.33%\n",
      "                                   Train Top 3 Acc: 95.01%                   Val Top 3 Acc: 93.85%   Overtime:  0H  5M 28S\n",
      "Epoch:   5/200  Train Loss: 0.447  Train Top 1 Acc: 86.01%  Val Loss: 0.532  Val Top 1 Acc: 83.09%\n",
      "                                   Train Top 3 Acc: 95.95%                   Val Top 3 Acc: 95.44%   Overtime:  0H  6M 51S\n",
      "Epoch:   6/200  Train Loss: 0.392  Train Top 1 Acc: 88.02%  Val Loss: 0.407  Val Top 1 Acc: 87.58%\n",
      "                                   Train Top 3 Acc: 96.61%                   Val Top 3 Acc: 96.91%   Overtime:  0H  8M 13S\n",
      "Epoch:   7/200  Train Loss: 0.361  Train Top 1 Acc: 88.91%  Val Loss: 0.368  Val Top 1 Acc: 88.87%\n",
      "                                   Train Top 3 Acc: 96.88%                   Val Top 3 Acc: 97.40%   Overtime:  0H  9M 36S\n",
      "Epoch:   8/200  Train Loss: 0.342  Train Top 1 Acc: 89.55%  Val Loss: 0.371  Val Top 1 Acc: 88.49%\n",
      "                                   Train Top 3 Acc: 97.09%                   Val Top 3 Acc: 97.15%   Overtime:  0H 10M 58S\n",
      "Epoch:   9/200  Train Loss: 0.324  Train Top 1 Acc: 90.16%  Val Loss: 0.310  Val Top 1 Acc: 90.73%\n",
      "                                   Train Top 3 Acc: 97.19%                   Val Top 3 Acc: 97.81%   Overtime:  0H 12M 21S\n",
      "Epoch:  10/200  Train Loss: 0.312  Train Top 1 Acc: 90.57%  Val Loss: 0.348  Val Top 1 Acc: 89.51%\n",
      "                                   Train Top 3 Acc: 97.40%                   Val Top 3 Acc: 97.37%   Overtime:  0H 13M 44S\n",
      "Epoch:  11/200  Train Loss: 0.300  Train Top 1 Acc: 91.05%  Val Loss: 0.341  Val Top 1 Acc: 89.61%\n",
      "                                   Train Top 3 Acc: 97.59%                   Val Top 3 Acc: 97.64%   Overtime:  0H 15M  7S\n",
      "Epoch:  12/200  Train Loss: 0.289  Train Top 1 Acc: 91.37%  Val Loss: 0.274  Val Top 1 Acc: 92.08%\n",
      "                                   Train Top 3 Acc: 97.64%                   Val Top 3 Acc: 98.06%   Overtime:  0H 16M 29S\n",
      "Epoch:  13/200  Train Loss: 0.279  Train Top 1 Acc: 91.63%  Val Loss: 0.306  Val Top 1 Acc: 90.62%\n",
      "                                   Train Top 3 Acc: 97.77%                   Val Top 3 Acc: 97.94%   Overtime:  0H 17M 52S\n",
      "Epoch:  14/200  Train Loss: 0.273  Train Top 1 Acc: 91.83%  Val Loss: 0.301  Val Top 1 Acc: 91.00%\n",
      "                                   Train Top 3 Acc: 97.84%                   Val Top 3 Acc: 97.96%   Overtime:  0H 19M 14S\n",
      "Epoch:  15/200  Train Loss: 0.268  Train Top 1 Acc: 92.17%  Val Loss: 0.299  Val Top 1 Acc: 91.02%\n",
      "                                   Train Top 3 Acc: 97.95%                   Val Top 3 Acc: 97.72%   Overtime:  0H 20M 37S\n",
      "Epoch:  16/200  Train Loss: 0.261  Train Top 1 Acc: 92.16%  Val Loss: 0.267  Val Top 1 Acc: 92.19%\n",
      "                                   Train Top 3 Acc: 97.94%                   Val Top 3 Acc: 98.24%   Overtime:  0H 21M 59S\n",
      "Epoch:  17/200  Train Loss: 0.254  Train Top 1 Acc: 92.45%  Val Loss: 0.285  Val Top 1 Acc: 91.55%\n",
      "                                   Train Top 3 Acc: 98.02%                   Val Top 3 Acc: 97.99%   Overtime:  0H 23M 22S\n",
      "Epoch:  18/200  Train Loss: 0.250  Train Top 1 Acc: 92.61%  Val Loss: 0.304  Val Top 1 Acc: 90.91%\n",
      "                                   Train Top 3 Acc: 98.05%                   Val Top 3 Acc: 98.09%   Overtime:  0H 24M 44S\n",
      "Epoch:  19/200  Train Loss: 0.245  Train Top 1 Acc: 92.77%  Val Loss: 0.262  Val Top 1 Acc: 92.28%\n",
      "                                   Train Top 3 Acc: 98.14%                   Val Top 3 Acc: 98.24%   Overtime:  0H 26M  7S\n",
      "Epoch:  20/200  Train Loss: 0.242  Train Top 1 Acc: 92.84%  Val Loss: 0.234  Val Top 1 Acc: 93.26%\n",
      "                                   Train Top 3 Acc: 98.16%                   Val Top 3 Acc: 98.43%   Overtime:  0H 27M 29S\n",
      "Epoch:  21/200  Train Loss: 0.233  Train Top 1 Acc: 93.11%  Val Loss: 0.232  Val Top 1 Acc: 93.19%\n",
      "                                   Train Top 3 Acc: 98.29%                   Val Top 3 Acc: 98.38%   Overtime:  0H 28M 51S\n",
      "Epoch:  22/200  Train Loss: 0.233  Train Top 1 Acc: 93.12%  Val Loss: 0.238  Val Top 1 Acc: 93.18%\n",
      "                                   Train Top 3 Acc: 98.24%                   Val Top 3 Acc: 98.35%   Overtime:  0H 30M 14S\n",
      "Epoch:  23/200  Train Loss: 0.228  Train Top 1 Acc: 93.22%  Val Loss: 0.232  Val Top 1 Acc: 93.36%\n",
      "                                   Train Top 3 Acc: 98.30%                   Val Top 3 Acc: 98.44%   Overtime:  0H 31M 36S\n",
      "Epoch:  24/200  Train Loss: 0.223  Train Top 1 Acc: 93.45%  Val Loss: 0.264  Val Top 1 Acc: 92.29%\n",
      "                                   Train Top 3 Acc: 98.33%                   Val Top 3 Acc: 98.11%   Overtime:  0H 32M 59S\n",
      "Epoch:  25/200  Train Loss: 0.221  Train Top 1 Acc: 93.34%  Val Loss: 0.237  Val Top 1 Acc: 93.17%\n",
      "                                   Train Top 3 Acc: 98.36%                   Val Top 3 Acc: 98.51%   Overtime:  0H 34M 22S\n",
      "Epoch:  26/200  Train Loss: 0.218  Train Top 1 Acc: 93.49%  Val Loss: 0.243  Val Top 1 Acc: 93.10%\n",
      "                                   Train Top 3 Acc: 98.40%                   Val Top 3 Acc: 98.30%   Overtime:  0H 35M 45S\n",
      "Epoch:  27/200  Train Loss: 0.214  Train Top 1 Acc: 93.68%  Val Loss: 0.285  Val Top 1 Acc: 91.59%\n",
      "                                   Train Top 3 Acc: 98.44%                   Val Top 3 Acc: 98.04%   Overtime:  0H 37M  7S\n",
      "Epoch:  28/200  Train Loss: 0.211  Train Top 1 Acc: 93.87%  Val Loss: 0.249  Val Top 1 Acc: 92.65%\n",
      "                                   Train Top 3 Acc: 98.44%                   Val Top 3 Acc: 98.28%   Overtime:  0H 38M 29S\n",
      "Epoch:  29/200  Train Loss: 0.210  Train Top 1 Acc: 93.78%  Val Loss: 0.240  Val Top 1 Acc: 93.15%\n",
      "                                   Train Top 3 Acc: 98.50%                   Val Top 3 Acc: 98.37%   Overtime:  0H 39M 52S\n",
      "Epoch:  30/200  Train Loss: 0.207  Train Top 1 Acc: 93.95%  Val Loss: 0.247  Val Top 1 Acc: 92.94%\n",
      "                                   Train Top 3 Acc: 98.51%                   Val Top 3 Acc: 98.21%   Overtime:  0H 41M 15S\n",
      "Epoch:  31/200  Train Loss: 0.204  Train Top 1 Acc: 94.01%  Val Loss: 0.213  Val Top 1 Acc: 93.85%\n",
      "                                   Train Top 3 Acc: 98.53%                   Val Top 3 Acc: 98.59%   Overtime:  0H 42M 37S\n",
      "Epoch:  32/200  Train Loss: 0.201  Train Top 1 Acc: 94.03%  Val Loss: 0.227  Val Top 1 Acc: 93.36%\n",
      "                                   Train Top 3 Acc: 98.59%                   Val Top 3 Acc: 98.52%   Overtime:  0H 44M  0S\n",
      "Epoch:  33/200  Train Loss: 0.202  Train Top 1 Acc: 94.14%  Val Loss: 0.213  Val Top 1 Acc: 94.00%\n",
      "                                   Train Top 3 Acc: 98.61%                   Val Top 3 Acc: 98.59%   Overtime:  0H 45M 22S\n",
      "Epoch:  34/200  Train Loss: 0.197  Train Top 1 Acc: 94.21%  Val Loss: 0.248  Val Top 1 Acc: 92.84%\n",
      "                                   Train Top 3 Acc: 98.63%                   Val Top 3 Acc: 98.33%   Overtime:  0H 46M 44S\n",
      "Epoch:  35/200  Train Loss: 0.195  Train Top 1 Acc: 94.38%  Val Loss: 0.279  Val Top 1 Acc: 91.73%\n",
      "                                   Train Top 3 Acc: 98.71%                   Val Top 3 Acc: 98.33%   Overtime:  0H 48M  7S\n",
      "Epoch:  36/200  Train Loss: 0.193  Train Top 1 Acc: 94.35%  Val Loss: 0.243  Val Top 1 Acc: 93.11%\n",
      "                                   Train Top 3 Acc: 98.66%                   Val Top 3 Acc: 98.41%   Overtime:  0H 49M 30S\n",
      "Epoch:  37/200  Train Loss: 0.191  Train Top 1 Acc: 94.35%  Val Loss: 0.237  Val Top 1 Acc: 93.34%\n",
      "                                   Train Top 3 Acc: 98.70%                   Val Top 3 Acc: 98.53%   Overtime:  0H 50M 53S\n",
      "Epoch:  38/200  Train Loss: 0.189  Train Top 1 Acc: 94.38%  Val Loss: 0.219  Val Top 1 Acc: 93.87%\n",
      "                                   Train Top 3 Acc: 98.72%                   Val Top 3 Acc: 98.51%   Overtime:  0H 52M 17S\n",
      "Epoch:  39/200  Train Loss: 0.187  Train Top 1 Acc: 94.60%  Val Loss: 0.227  Val Top 1 Acc: 93.46%\n",
      "                                   Train Top 3 Acc: 98.71%                   Val Top 3 Acc: 98.39%   Overtime:  0H 53M 40S\n",
      "Epoch:  40/200  Train Loss: 0.185  Train Top 1 Acc: 94.55%  Val Loss: 0.226  Val Top 1 Acc: 93.51%\n",
      "                                   Train Top 3 Acc: 98.77%                   Val Top 3 Acc: 98.45%   Overtime:  0H 55M  3S\n",
      "Epoch:  41/200  Train Loss: 0.179  Train Top 1 Acc: 94.78%  Val Loss: 0.226  Val Top 1 Acc: 93.45%\n",
      "                                   Train Top 3 Acc: 98.77%                   Val Top 3 Acc: 98.49%   Overtime:  0H 56M 25S\n",
      "Epoch:  42/200  Train Loss: 0.184  Train Top 1 Acc: 94.68%  Val Loss: 0.213  Val Top 1 Acc: 93.80%\n",
      "                                   Train Top 3 Acc: 98.72%                   Val Top 3 Acc: 98.67%   Overtime:  0H 57M 48S\n",
      "Epoch:  43/200  Train Loss: 0.181  Train Top 1 Acc: 94.70%  Val Loss: 0.221  Val Top 1 Acc: 93.62%\n",
      "                                   Train Top 3 Acc: 98.79%                   Val Top 3 Acc: 98.46%   Overtime:  0H 59M 10S\n",
      "Epoch:  44/200  Train Loss: 0.177  Train Top 1 Acc: 94.80%  Val Loss: 0.244  Val Top 1 Acc: 92.97%\n",
      "                                   Train Top 3 Acc: 98.83%                   Val Top 3 Acc: 98.33%   Overtime:  1H  0M 33S\n",
      "Epoch:  45/200  Train Loss: 0.177  Train Top 1 Acc: 94.83%  Val Loss: 0.233  Val Top 1 Acc: 93.52%\n",
      "                                   Train Top 3 Acc: 98.81%                   Val Top 3 Acc: 98.52%   Overtime:  1H  1M 55S\n",
      "Epoch:  46/200  Train Loss: 0.176  Train Top 1 Acc: 94.83%  Val Loss: 0.224  Val Top 1 Acc: 93.60%\n",
      "                                   Train Top 3 Acc: 98.86%                   Val Top 3 Acc: 98.53%   Overtime:  1H  3M 18S\n",
      "Epoch:  47/200  Train Loss: 0.170  Train Top 1 Acc: 95.05%  Val Loss: 0.235  Val Top 1 Acc: 93.42%\n",
      "                                   Train Top 3 Acc: 98.85%                   Val Top 3 Acc: 98.50%   Overtime:  1H  4M 41S\n",
      "Epoch:  48/200  Train Loss: 0.172  Train Top 1 Acc: 94.95%  Val Loss: 0.223  Val Top 1 Acc: 93.67%\n",
      "                                   Train Top 3 Acc: 98.85%                   Val Top 3 Acc: 98.51%   Overtime:  1H  6M  4S\n",
      "Epoch:  49/200  Train Loss: 0.170  Train Top 1 Acc: 94.97%  Val Loss: 0.203  Val Top 1 Acc: 94.26%\n",
      "                                   Train Top 3 Acc: 98.89%                   Val Top 3 Acc: 98.64%   Overtime:  1H  7M 26S\n",
      "Epoch:  50/200  Train Loss: 0.167  Train Top 1 Acc: 95.13%  Val Loss: 0.229  Val Top 1 Acc: 93.45%\n",
      "                                   Train Top 3 Acc: 98.92%                   Val Top 3 Acc: 98.48%   Overtime:  1H  8M 49S\n",
      "Epoch:  51/200  Train Loss: 0.147  Train Top 1 Acc: 95.76%  Val Loss: 0.202  Val Top 1 Acc: 94.29%\n",
      "                                   Train Top 3 Acc: 99.10%                   Val Top 3 Acc: 98.66%   Overtime:  1H 10M 11S\n",
      "Epoch:  52/200  Train Loss: 0.141  Train Top 1 Acc: 95.94%  Val Loss: 0.219  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.15%                   Val Top 3 Acc: 98.58%   Overtime:  1H 11M 33S\n",
      "Epoch:  53/200  Train Loss: 0.138  Train Top 1 Acc: 95.97%  Val Loss: 0.201  Val Top 1 Acc: 94.65%\n",
      "                                   Train Top 3 Acc: 99.15%                   Val Top 3 Acc: 98.72%   Overtime:  1H 12M 55S\n",
      "Epoch:  54/200  Train Loss: 0.138  Train Top 1 Acc: 95.99%  Val Loss: 0.208  Val Top 1 Acc: 94.32%\n",
      "                                   Train Top 3 Acc: 99.15%                   Val Top 3 Acc: 98.56%   Overtime:  1H 14M 17S\n",
      "Epoch:  55/200  Train Loss: 0.133  Train Top 1 Acc: 96.13%  Val Loss: 0.210  Val Top 1 Acc: 94.10%\n",
      "                                   Train Top 3 Acc: 99.19%                   Val Top 3 Acc: 98.66%   Overtime:  1H 15M 39S\n",
      "Epoch:  56/200  Train Loss: 0.136  Train Top 1 Acc: 96.01%  Val Loss: 0.213  Val Top 1 Acc: 94.26%\n",
      "                                   Train Top 3 Acc: 99.22%                   Val Top 3 Acc: 98.56%   Overtime:  1H 17M  2S\n",
      "Epoch:  57/200  Train Loss: 0.133  Train Top 1 Acc: 96.21%  Val Loss: 0.233  Val Top 1 Acc: 93.70%\n",
      "                                   Train Top 3 Acc: 99.22%                   Val Top 3 Acc: 98.48%   Overtime:  1H 18M 24S\n",
      "Epoch:  58/200  Train Loss: 0.133  Train Top 1 Acc: 96.08%  Val Loss: 0.213  Val Top 1 Acc: 94.16%\n",
      "                                   Train Top 3 Acc: 99.21%                   Val Top 3 Acc: 98.55%   Overtime:  1H 19M 47S\n",
      "Epoch:  59/200  Train Loss: 0.131  Train Top 1 Acc: 96.20%  Val Loss: 0.213  Val Top 1 Acc: 94.26%\n",
      "                                   Train Top 3 Acc: 99.25%                   Val Top 3 Acc: 98.62%   Overtime:  1H 21M  9S\n",
      "Epoch:  60/200  Train Loss: 0.130  Train Top 1 Acc: 96.19%  Val Loss: 0.217  Val Top 1 Acc: 94.03%\n",
      "                                   Train Top 3 Acc: 99.24%                   Val Top 3 Acc: 98.60%   Overtime:  1H 22M 32S\n",
      "Epoch:  61/200  Train Loss: 0.129  Train Top 1 Acc: 96.23%  Val Loss: 0.209  Val Top 1 Acc: 94.46%\n",
      "                                   Train Top 3 Acc: 99.26%                   Val Top 3 Acc: 98.64%   Overtime:  1H 23M 54S\n",
      "Epoch:  62/200  Train Loss: 0.128  Train Top 1 Acc: 96.24%  Val Loss: 0.209  Val Top 1 Acc: 94.26%\n",
      "                                   Train Top 3 Acc: 99.27%                   Val Top 3 Acc: 98.66%   Overtime:  1H 25M 17S\n",
      "Epoch:  63/200  Train Loss: 0.129  Train Top 1 Acc: 96.23%  Val Loss: 0.211  Val Top 1 Acc: 94.37%\n",
      "                                   Train Top 3 Acc: 99.25%                   Val Top 3 Acc: 98.64%   Overtime:  1H 26M 39S\n",
      "Epoch:  64/200  Train Loss: 0.128  Train Top 1 Acc: 96.23%  Val Loss: 0.208  Val Top 1 Acc: 94.37%\n",
      "                                   Train Top 3 Acc: 99.29%                   Val Top 3 Acc: 98.69%   Overtime:  1H 28M  1S\n",
      "Epoch:  65/200  Train Loss: 0.126  Train Top 1 Acc: 96.31%  Val Loss: 0.216  Val Top 1 Acc: 94.16%\n",
      "                                   Train Top 3 Acc: 99.30%                   Val Top 3 Acc: 98.59%   Overtime:  1H 29M 24S\n",
      "Epoch:  66/200  Train Loss: 0.126  Train Top 1 Acc: 96.26%  Val Loss: 0.216  Val Top 1 Acc: 94.20%\n",
      "                                   Train Top 3 Acc: 99.30%                   Val Top 3 Acc: 98.46%   Overtime:  1H 30M 47S\n",
      "Epoch:  67/200  Train Loss: 0.124  Train Top 1 Acc: 96.35%  Val Loss: 0.220  Val Top 1 Acc: 93.94%\n",
      "                                   Train Top 3 Acc: 99.32%                   Val Top 3 Acc: 98.52%   Overtime:  1H 32M 10S\n",
      "Epoch:  68/200  Train Loss: 0.123  Train Top 1 Acc: 96.38%  Val Loss: 0.223  Val Top 1 Acc: 93.88%\n",
      "                                   Train Top 3 Acc: 99.35%                   Val Top 3 Acc: 98.51%   Overtime:  1H 33M 34S\n",
      "Epoch:  69/200  Train Loss: 0.123  Train Top 1 Acc: 96.36%  Val Loss: 0.214  Val Top 1 Acc: 94.30%\n",
      "                                   Train Top 3 Acc: 99.31%                   Val Top 3 Acc: 98.63%   Overtime:  1H 34M 57S\n",
      "Epoch:  70/200  Train Loss: 0.122  Train Top 1 Acc: 96.39%  Val Loss: 0.233  Val Top 1 Acc: 93.82%\n",
      "                                   Train Top 3 Acc: 99.31%                   Val Top 3 Acc: 98.42%   Overtime:  1H 36M 20S\n",
      "Epoch:  71/200  Train Loss: 0.120  Train Top 1 Acc: 96.40%  Val Loss: 0.218  Val Top 1 Acc: 94.33%\n",
      "                                   Train Top 3 Acc: 99.34%                   Val Top 3 Acc: 98.52%   Overtime:  1H 37M 43S\n",
      "Epoch:  72/200  Train Loss: 0.121  Train Top 1 Acc: 96.40%  Val Loss: 0.218  Val Top 1 Acc: 94.15%\n",
      "                                   Train Top 3 Acc: 99.34%                   Val Top 3 Acc: 98.49%   Overtime:  1H 39M  5S\n",
      "Epoch:  73/200  Train Loss: 0.120  Train Top 1 Acc: 96.41%  Val Loss: 0.222  Val Top 1 Acc: 93.82%\n",
      "                                   Train Top 3 Acc: 99.36%                   Val Top 3 Acc: 98.64%   Overtime:  1H 40M 29S\n",
      "Epoch:  74/200  Train Loss: 0.119  Train Top 1 Acc: 96.58%  Val Loss: 0.213  Val Top 1 Acc: 94.25%\n",
      "                                   Train Top 3 Acc: 99.35%                   Val Top 3 Acc: 98.59%   Overtime:  1H 41M 52S\n",
      "Epoch:  75/200  Train Loss: 0.118  Train Top 1 Acc: 96.46%  Val Loss: 0.210  Val Top 1 Acc: 94.22%\n",
      "                                   Train Top 3 Acc: 99.38%                   Val Top 3 Acc: 98.69%   Overtime:  1H 43M 16S\n",
      "Epoch:  76/200  Train Loss: 0.117  Train Top 1 Acc: 96.51%  Val Loss: 0.238  Val Top 1 Acc: 93.50%\n",
      "                                   Train Top 3 Acc: 99.38%                   Val Top 3 Acc: 98.43%   Overtime:  1H 44M 38S\n",
      "Epoch:  77/200  Train Loss: 0.117  Train Top 1 Acc: 96.54%  Val Loss: 0.221  Val Top 1 Acc: 94.17%\n",
      "                                   Train Top 3 Acc: 99.40%                   Val Top 3 Acc: 98.59%   Overtime:  1H 46M  1S\n",
      "Epoch:  78/200  Train Loss: 0.116  Train Top 1 Acc: 96.56%  Val Loss: 0.220  Val Top 1 Acc: 94.10%\n",
      "                                   Train Top 3 Acc: 99.42%                   Val Top 3 Acc: 98.64%   Overtime:  1H 47M 23S\n",
      "Epoch:  79/200  Train Loss: 0.116  Train Top 1 Acc: 96.56%  Val Loss: 0.211  Val Top 1 Acc: 94.54%\n",
      "                                   Train Top 3 Acc: 99.40%                   Val Top 3 Acc: 98.67%   Overtime:  1H 48M 47S\n",
      "Epoch:  80/200  Train Loss: 0.115  Train Top 1 Acc: 96.59%  Val Loss: 0.220  Val Top 1 Acc: 94.20%\n",
      "                                   Train Top 3 Acc: 99.42%                   Val Top 3 Acc: 98.62%   Overtime:  1H 50M  9S\n",
      "Epoch:  81/200  Train Loss: 0.114  Train Top 1 Acc: 96.60%  Val Loss: 0.232  Val Top 1 Acc: 93.92%\n",
      "                                   Train Top 3 Acc: 99.41%                   Val Top 3 Acc: 98.52%   Overtime:  1H 51M 32S\n",
      "Epoch:  82/200  Train Loss: 0.113  Train Top 1 Acc: 96.67%  Val Loss: 0.228  Val Top 1 Acc: 93.96%\n",
      "                                   Train Top 3 Acc: 99.40%                   Val Top 3 Acc: 98.58%   Overtime:  1H 52M 55S\n",
      "Epoch:  83/200  Train Loss: 0.112  Train Top 1 Acc: 96.68%  Val Loss: 0.224  Val Top 1 Acc: 94.08%\n",
      "                                   Train Top 3 Acc: 99.38%                   Val Top 3 Acc: 98.53%   Overtime:  1H 54M 17S\n",
      "Epoch:  84/200  Train Loss: 0.111  Train Top 1 Acc: 96.64%  Val Loss: 0.241  Val Top 1 Acc: 93.75%\n",
      "                                   Train Top 3 Acc: 99.44%                   Val Top 3 Acc: 98.48%   Overtime:  1H 55M 39S\n",
      "Epoch:  85/200  Train Loss: 0.111  Train Top 1 Acc: 96.68%  Val Loss: 0.239  Val Top 1 Acc: 93.61%\n",
      "                                   Train Top 3 Acc: 99.43%                   Val Top 3 Acc: 98.53%   Overtime:  1H 57M  2S\n",
      "Epoch:  86/200  Train Loss: 0.111  Train Top 1 Acc: 96.65%  Val Loss: 0.236  Val Top 1 Acc: 93.92%\n",
      "                                   Train Top 3 Acc: 99.42%                   Val Top 3 Acc: 98.54%   Overtime:  1H 58M 24S\n",
      "Epoch:  87/200  Train Loss: 0.111  Train Top 1 Acc: 96.56%  Val Loss: 0.219  Val Top 1 Acc: 94.23%\n",
      "                                   Train Top 3 Acc: 99.45%                   Val Top 3 Acc: 98.69%   Overtime:  1H 59M 47S\n",
      "Epoch:  88/200  Train Loss: 0.109  Train Top 1 Acc: 96.75%  Val Loss: 0.241  Val Top 1 Acc: 93.63%\n",
      "                                   Train Top 3 Acc: 99.47%                   Val Top 3 Acc: 98.50%   Overtime:  2H  1M 10S\n",
      "Epoch:  89/200  Train Loss: 0.110  Train Top 1 Acc: 96.69%  Val Loss: 0.244  Val Top 1 Acc: 93.67%\n",
      "                                   Train Top 3 Acc: 99.46%                   Val Top 3 Acc: 98.46%   Overtime:  2H  2M 33S\n",
      "Epoch:  90/200  Train Loss: 0.108  Train Top 1 Acc: 96.71%  Val Loss: 0.220  Val Top 1 Acc: 94.16%\n",
      "                                   Train Top 3 Acc: 99.46%                   Val Top 3 Acc: 98.56%   Overtime:  2H  3M 56S\n",
      "Epoch:  91/200  Train Loss: 0.107  Train Top 1 Acc: 96.79%  Val Loss: 0.225  Val Top 1 Acc: 93.97%\n",
      "                                   Train Top 3 Acc: 99.51%                   Val Top 3 Acc: 98.44%   Overtime:  2H  5M 19S\n",
      "Epoch:  92/200  Train Loss: 0.108  Train Top 1 Acc: 96.72%  Val Loss: 0.230  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.49%                   Val Top 3 Acc: 98.51%   Overtime:  2H  6M 41S\n",
      "Epoch:  93/200  Train Loss: 0.108  Train Top 1 Acc: 96.70%  Val Loss: 0.234  Val Top 1 Acc: 93.82%\n",
      "                                   Train Top 3 Acc: 99.48%                   Val Top 3 Acc: 98.48%   Overtime:  2H  8M  5S\n",
      "Epoch:  94/200  Train Loss: 0.106  Train Top 1 Acc: 96.71%  Val Loss: 0.222  Val Top 1 Acc: 94.12%\n",
      "                                   Train Top 3 Acc: 99.53%                   Val Top 3 Acc: 98.59%   Overtime:  2H  9M 27S\n",
      "Epoch:  95/200  Train Loss: 0.104  Train Top 1 Acc: 96.87%  Val Loss: 0.249  Val Top 1 Acc: 93.56%\n",
      "                                   Train Top 3 Acc: 99.49%                   Val Top 3 Acc: 98.50%   Overtime:  2H 10M 49S\n",
      "Epoch:  96/200  Train Loss: 0.104  Train Top 1 Acc: 96.87%  Val Loss: 0.250  Val Top 1 Acc: 93.45%\n",
      "                                   Train Top 3 Acc: 99.51%                   Val Top 3 Acc: 98.40%   Overtime:  2H 12M 12S\n",
      "Epoch:  97/200  Train Loss: 0.103  Train Top 1 Acc: 96.91%  Val Loss: 0.223  Val Top 1 Acc: 94.25%\n",
      "                                   Train Top 3 Acc: 99.52%                   Val Top 3 Acc: 98.62%   Overtime:  2H 13M 34S\n",
      "Epoch:  98/200  Train Loss: 0.103  Train Top 1 Acc: 96.82%  Val Loss: 0.231  Val Top 1 Acc: 93.93%\n",
      "                                   Train Top 3 Acc: 99.52%                   Val Top 3 Acc: 98.47%   Overtime:  2H 14M 56S\n",
      "Epoch:  99/200  Train Loss: 0.102  Train Top 1 Acc: 96.89%  Val Loss: 0.233  Val Top 1 Acc: 94.09%\n",
      "                                   Train Top 3 Acc: 99.51%                   Val Top 3 Acc: 98.40%   Overtime:  2H 16M 19S\n",
      "Epoch: 100/200  Train Loss: 0.101  Train Top 1 Acc: 96.94%  Val Loss: 0.236  Val Top 1 Acc: 93.92%\n",
      "                                   Train Top 3 Acc: 99.55%                   Val Top 3 Acc: 98.51%   Overtime:  2H 17M 41S\n",
      "Epoch: 101/200  Train Loss: 0.088  Train Top 1 Acc: 97.26%  Val Loss: 0.223  Val Top 1 Acc: 94.46%\n",
      "                                   Train Top 3 Acc: 99.61%                   Val Top 3 Acc: 98.57%   Overtime:  2H 19M  3S\n",
      "Epoch: 102/200  Train Loss: 0.083  Train Top 1 Acc: 97.45%  Val Loss: 0.238  Val Top 1 Acc: 94.08%\n",
      "                                   Train Top 3 Acc: 99.65%                   Val Top 3 Acc: 98.49%   Overtime:  2H 20M 26S\n",
      "Epoch: 103/200  Train Loss: 0.081  Train Top 1 Acc: 97.51%  Val Loss: 0.240  Val Top 1 Acc: 94.27%\n",
      "                                   Train Top 3 Acc: 99.67%                   Val Top 3 Acc: 98.47%   Overtime:  2H 21M 50S\n",
      "Epoch: 104/200  Train Loss: 0.078  Train Top 1 Acc: 97.60%  Val Loss: 0.239  Val Top 1 Acc: 94.11%\n",
      "                                   Train Top 3 Acc: 99.63%                   Val Top 3 Acc: 98.49%   Overtime:  2H 23M 13S\n",
      "Epoch: 105/200  Train Loss: 0.080  Train Top 1 Acc: 97.55%  Val Loss: 0.241  Val Top 1 Acc: 93.83%\n",
      "                                   Train Top 3 Acc: 99.69%                   Val Top 3 Acc: 98.51%   Overtime:  2H 24M 36S\n",
      "Epoch: 106/200  Train Loss: 0.078  Train Top 1 Acc: 97.64%  Val Loss: 0.236  Val Top 1 Acc: 94.33%\n",
      "                                   Train Top 3 Acc: 99.68%                   Val Top 3 Acc: 98.54%   Overtime:  2H 26M  0S\n",
      "Epoch: 107/200  Train Loss: 0.078  Train Top 1 Acc: 97.61%  Val Loss: 0.241  Val Top 1 Acc: 94.11%\n",
      "                                   Train Top 3 Acc: 99.70%                   Val Top 3 Acc: 98.42%   Overtime:  2H 27M 24S\n",
      "Epoch: 108/200  Train Loss: 0.076  Train Top 1 Acc: 97.63%  Val Loss: 0.242  Val Top 1 Acc: 94.22%\n",
      "                                   Train Top 3 Acc: 99.70%                   Val Top 3 Acc: 98.52%   Overtime:  2H 28M 46S\n",
      "Epoch: 109/200  Train Loss: 0.075  Train Top 1 Acc: 97.66%  Val Loss: 0.244  Val Top 1 Acc: 94.02%\n",
      "                                   Train Top 3 Acc: 99.74%                   Val Top 3 Acc: 98.46%   Overtime:  2H 30M  9S\n",
      "Epoch: 110/200  Train Loss: 0.076  Train Top 1 Acc: 97.59%  Val Loss: 0.236  Val Top 1 Acc: 94.41%\n",
      "                                   Train Top 3 Acc: 99.69%                   Val Top 3 Acc: 98.48%   Overtime:  2H 31M 31S\n",
      "Epoch: 111/200  Train Loss: 0.074  Train Top 1 Acc: 97.69%  Val Loss: 0.237  Val Top 1 Acc: 94.45%\n",
      "                                   Train Top 3 Acc: 99.69%                   Val Top 3 Acc: 98.51%   Overtime:  2H 32M 54S\n",
      "Epoch: 112/200  Train Loss: 0.075  Train Top 1 Acc: 97.61%  Val Loss: 0.239  Val Top 1 Acc: 94.10%\n",
      "                                   Train Top 3 Acc: 99.72%                   Val Top 3 Acc: 98.49%   Overtime:  2H 34M 16S\n",
      "Epoch: 113/200  Train Loss: 0.074  Train Top 1 Acc: 97.68%  Val Loss: 0.256  Val Top 1 Acc: 93.98%\n",
      "                                   Train Top 3 Acc: 99.71%                   Val Top 3 Acc: 98.47%   Overtime:  2H 35M 39S\n",
      "Epoch: 114/200  Train Loss: 0.073  Train Top 1 Acc: 97.73%  Val Loss: 0.250  Val Top 1 Acc: 94.09%\n",
      "                                   Train Top 3 Acc: 99.74%                   Val Top 3 Acc: 98.44%   Overtime:  2H 37M  1S\n",
      "Epoch: 115/200  Train Loss: 0.074  Train Top 1 Acc: 97.66%  Val Loss: 0.245  Val Top 1 Acc: 94.21%\n",
      "                                   Train Top 3 Acc: 99.72%                   Val Top 3 Acc: 98.56%   Overtime:  2H 38M 23S\n",
      "Epoch: 116/200  Train Loss: 0.072  Train Top 1 Acc: 97.77%  Val Loss: 0.248  Val Top 1 Acc: 94.20%\n",
      "                                   Train Top 3 Acc: 99.72%                   Val Top 3 Acc: 98.52%   Overtime:  2H 39M 46S\n",
      "Epoch: 117/200  Train Loss: 0.071  Train Top 1 Acc: 97.70%  Val Loss: 0.247  Val Top 1 Acc: 93.91%\n",
      "                                   Train Top 3 Acc: 99.78%                   Val Top 3 Acc: 98.52%   Overtime:  2H 41M  8S\n",
      "Epoch: 118/200  Train Loss: 0.072  Train Top 1 Acc: 97.77%  Val Loss: 0.255  Val Top 1 Acc: 93.96%\n",
      "                                   Train Top 3 Acc: 99.74%                   Val Top 3 Acc: 98.59%   Overtime:  2H 42M 31S\n",
      "Epoch: 119/200  Train Loss: 0.070  Train Top 1 Acc: 97.78%  Val Loss: 0.259  Val Top 1 Acc: 94.00%\n",
      "                                   Train Top 3 Acc: 99.76%                   Val Top 3 Acc: 98.49%   Overtime:  2H 43M 53S\n",
      "Epoch: 120/200  Train Loss: 0.071  Train Top 1 Acc: 97.77%  Val Loss: 0.270  Val Top 1 Acc: 93.69%\n",
      "                                   Train Top 3 Acc: 99.75%                   Val Top 3 Acc: 98.47%   Overtime:  2H 45M 16S\n",
      "Epoch: 121/200  Train Loss: 0.070  Train Top 1 Acc: 97.79%  Val Loss: 0.267  Val Top 1 Acc: 93.95%\n",
      "                                   Train Top 3 Acc: 99.76%                   Val Top 3 Acc: 98.43%   Overtime:  2H 46M 38S\n",
      "Epoch: 122/200  Train Loss: 0.072  Train Top 1 Acc: 97.71%  Val Loss: 0.253  Val Top 1 Acc: 93.91%\n",
      "                                   Train Top 3 Acc: 99.74%                   Val Top 3 Acc: 98.55%   Overtime:  2H 48M  0S\n",
      "Epoch: 123/200  Train Loss: 0.071  Train Top 1 Acc: 97.76%  Val Loss: 0.257  Val Top 1 Acc: 93.99%\n",
      "                                   Train Top 3 Acc: 99.75%                   Val Top 3 Acc: 98.48%   Overtime:  2H 49M 23S\n",
      "Epoch: 124/200  Train Loss: 0.070  Train Top 1 Acc: 97.78%  Val Loss: 0.259  Val Top 1 Acc: 93.50%\n",
      "                                   Train Top 3 Acc: 99.76%                   Val Top 3 Acc: 98.34%   Overtime:  2H 50M 45S\n",
      "Epoch: 125/200  Train Loss: 0.068  Train Top 1 Acc: 97.82%  Val Loss: 0.249  Val Top 1 Acc: 94.09%\n",
      "                                   Train Top 3 Acc: 99.77%                   Val Top 3 Acc: 98.48%   Overtime:  2H 52M  7S\n",
      "Epoch: 126/200  Train Loss: 0.068  Train Top 1 Acc: 97.85%  Val Loss: 0.250  Val Top 1 Acc: 94.18%\n",
      "                                   Train Top 3 Acc: 99.76%                   Val Top 3 Acc: 98.51%   Overtime:  2H 53M 30S\n",
      "Epoch: 127/200  Train Loss: 0.067  Train Top 1 Acc: 97.92%  Val Loss: 0.249  Val Top 1 Acc: 94.04%\n",
      "                                   Train Top 3 Acc: 99.75%                   Val Top 3 Acc: 98.48%   Overtime:  2H 54M 52S\n",
      "Epoch: 128/200  Train Loss: 0.069  Train Top 1 Acc: 97.82%  Val Loss: 0.272  Val Top 1 Acc: 93.67%\n",
      "                                   Train Top 3 Acc: 99.78%                   Val Top 3 Acc: 98.43%   Overtime:  2H 56M 15S\n",
      "Epoch: 129/200  Train Loss: 0.068  Train Top 1 Acc: 97.86%  Val Loss: 0.269  Val Top 1 Acc: 93.78%\n",
      "                                   Train Top 3 Acc: 99.77%                   Val Top 3 Acc: 98.35%   Overtime:  2H 57M 38S\n",
      "Epoch: 130/200  Train Loss: 0.068  Train Top 1 Acc: 97.84%  Val Loss: 0.260  Val Top 1 Acc: 93.91%\n",
      "                                   Train Top 3 Acc: 99.77%                   Val Top 3 Acc: 98.47%   Overtime:  2H 59M  0S\n",
      "Epoch: 131/200  Train Loss: 0.066  Train Top 1 Acc: 97.88%  Val Loss: 0.268  Val Top 1 Acc: 93.85%\n",
      "                                   Train Top 3 Acc: 99.77%                   Val Top 3 Acc: 98.43%   Overtime:  3H  0M 23S\n",
      "Epoch: 132/200  Train Loss: 0.066  Train Top 1 Acc: 97.90%  Val Loss: 0.266  Val Top 1 Acc: 94.02%\n",
      "                                   Train Top 3 Acc: 99.78%                   Val Top 3 Acc: 98.34%   Overtime:  3H  1M 45S\n",
      "Epoch: 133/200  Train Loss: 0.067  Train Top 1 Acc: 97.83%  Val Loss: 0.264  Val Top 1 Acc: 93.98%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.43%   Overtime:  3H  3M  7S\n",
      "Epoch: 134/200  Train Loss: 0.065  Train Top 1 Acc: 97.91%  Val Loss: 0.279  Val Top 1 Acc: 93.60%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.38%   Overtime:  3H  4M 29S\n",
      "Epoch: 135/200  Train Loss: 0.068  Train Top 1 Acc: 97.82%  Val Loss: 0.256  Val Top 1 Acc: 93.97%\n",
      "                                   Train Top 3 Acc: 99.80%                   Val Top 3 Acc: 98.56%   Overtime:  3H  5M 52S\n",
      "Epoch: 136/200  Train Loss: 0.066  Train Top 1 Acc: 97.88%  Val Loss: 0.266  Val Top 1 Acc: 93.97%\n",
      "                                   Train Top 3 Acc: 99.79%                   Val Top 3 Acc: 98.51%   Overtime:  3H  7M 14S\n",
      "Epoch: 137/200  Train Loss: 0.064  Train Top 1 Acc: 97.92%  Val Loss: 0.280  Val Top 1 Acc: 93.79%\n",
      "                                   Train Top 3 Acc: 99.79%                   Val Top 3 Acc: 98.43%   Overtime:  3H  8M 37S\n",
      "Epoch: 138/200  Train Loss: 0.066  Train Top 1 Acc: 97.84%  Val Loss: 0.271  Val Top 1 Acc: 93.74%\n",
      "                                   Train Top 3 Acc: 99.81%                   Val Top 3 Acc: 98.48%   Overtime:  3H  9M 59S\n",
      "Epoch: 139/200  Train Loss: 0.066  Train Top 1 Acc: 97.87%  Val Loss: 0.273  Val Top 1 Acc: 93.71%\n",
      "                                   Train Top 3 Acc: 99.78%                   Val Top 3 Acc: 98.40%   Overtime:  3H 11M 21S\n",
      "Epoch: 140/200  Train Loss: 0.066  Train Top 1 Acc: 97.84%  Val Loss: 0.271  Val Top 1 Acc: 93.67%\n",
      "                                   Train Top 3 Acc: 99.80%                   Val Top 3 Acc: 98.40%   Overtime:  3H 12M 44S\n",
      "Epoch: 141/200  Train Loss: 0.065  Train Top 1 Acc: 97.89%  Val Loss: 0.263  Val Top 1 Acc: 94.05%\n",
      "                                   Train Top 3 Acc: 99.80%                   Val Top 3 Acc: 98.53%   Overtime:  3H 14M  7S\n",
      "Epoch: 142/200  Train Loss: 0.062  Train Top 1 Acc: 97.99%  Val Loss: 0.271  Val Top 1 Acc: 93.90%\n",
      "                                   Train Top 3 Acc: 99.80%                   Val Top 3 Acc: 98.53%   Overtime:  3H 15M 30S\n",
      "Epoch: 143/200  Train Loss: 0.063  Train Top 1 Acc: 97.91%  Val Loss: 0.269  Val Top 1 Acc: 93.78%\n",
      "                                   Train Top 3 Acc: 99.81%                   Val Top 3 Acc: 98.44%   Overtime:  3H 16M 53S\n",
      "Epoch: 144/200  Train Loss: 0.063  Train Top 1 Acc: 97.94%  Val Loss: 0.290  Val Top 1 Acc: 93.42%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.38%   Overtime:  3H 18M 15S\n",
      "Epoch: 145/200  Train Loss: 0.063  Train Top 1 Acc: 98.00%  Val Loss: 0.266  Val Top 1 Acc: 93.81%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.47%   Overtime:  3H 19M 38S\n",
      "Epoch: 146/200  Train Loss: 0.063  Train Top 1 Acc: 97.92%  Val Loss: 0.269  Val Top 1 Acc: 93.90%\n",
      "                                   Train Top 3 Acc: 99.80%                   Val Top 3 Acc: 98.48%   Overtime:  3H 21M  1S\n",
      "Epoch: 147/200  Train Loss: 0.061  Train Top 1 Acc: 98.00%  Val Loss: 0.285  Val Top 1 Acc: 93.77%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.53%   Overtime:  3H 22M 24S\n",
      "Epoch: 148/200  Train Loss: 0.061  Train Top 1 Acc: 98.05%  Val Loss: 0.276  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.81%                   Val Top 3 Acc: 98.42%   Overtime:  3H 23M 46S\n",
      "Epoch: 149/200  Train Loss: 0.062  Train Top 1 Acc: 97.95%  Val Loss: 0.274  Val Top 1 Acc: 93.65%\n",
      "                                   Train Top 3 Acc: 99.84%                   Val Top 3 Acc: 98.33%   Overtime:  3H 25M  9S\n",
      "Epoch: 150/200  Train Loss: 0.062  Train Top 1 Acc: 97.94%  Val Loss: 0.272  Val Top 1 Acc: 94.19%\n",
      "                                   Train Top 3 Acc: 99.82%                   Val Top 3 Acc: 98.55%   Overtime:  3H 26M 31S\n",
      "Epoch: 151/200  Train Loss: 0.053  Train Top 1 Acc: 98.27%  Val Loss: 0.272  Val Top 1 Acc: 93.81%\n",
      "                                   Train Top 3 Acc: 99.85%                   Val Top 3 Acc: 98.49%   Overtime:  3H 27M 54S\n",
      "Epoch: 152/200  Train Loss: 0.049  Train Top 1 Acc: 98.41%  Val Loss: 0.275  Val Top 1 Acc: 93.89%\n",
      "                                   Train Top 3 Acc: 99.86%                   Val Top 3 Acc: 98.52%   Overtime:  3H 29M 16S\n",
      "Epoch: 153/200  Train Loss: 0.047  Train Top 1 Acc: 98.47%  Val Loss: 0.286  Val Top 1 Acc: 93.75%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.53%   Overtime:  3H 30M 38S\n",
      "Epoch: 154/200  Train Loss: 0.048  Train Top 1 Acc: 98.47%  Val Loss: 0.286  Val Top 1 Acc: 93.75%\n",
      "                                   Train Top 3 Acc: 99.88%                   Val Top 3 Acc: 98.47%   Overtime:  3H 32M  1S\n",
      "Epoch: 155/200  Train Loss: 0.047  Train Top 1 Acc: 98.35%  Val Loss: 0.270  Val Top 1 Acc: 94.20%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.56%   Overtime:  3H 33M 23S\n",
      "Epoch: 156/200  Train Loss: 0.048  Train Top 1 Acc: 98.42%  Val Loss: 0.280  Val Top 1 Acc: 93.98%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.53%   Overtime:  3H 34M 45S\n",
      "Epoch: 157/200  Train Loss: 0.046  Train Top 1 Acc: 98.49%  Val Loss: 0.288  Val Top 1 Acc: 93.74%\n",
      "                                   Train Top 3 Acc: 99.87%                   Val Top 3 Acc: 98.42%   Overtime:  3H 36M  8S\n",
      "Epoch: 158/200  Train Loss: 0.046  Train Top 1 Acc: 98.49%  Val Loss: 0.279  Val Top 1 Acc: 94.17%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.53%   Overtime:  3H 37M 30S\n",
      "Epoch: 159/200  Train Loss: 0.043  Train Top 1 Acc: 98.54%  Val Loss: 0.290  Val Top 1 Acc: 93.97%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.51%   Overtime:  3H 38M 53S\n",
      "Epoch: 160/200  Train Loss: 0.046  Train Top 1 Acc: 98.51%  Val Loss: 0.291  Val Top 1 Acc: 93.90%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.48%   Overtime:  3H 40M 15S\n",
      "Epoch: 161/200  Train Loss: 0.044  Train Top 1 Acc: 98.53%  Val Loss: 0.287  Val Top 1 Acc: 93.99%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.50%   Overtime:  3H 41M 37S\n",
      "Epoch: 162/200  Train Loss: 0.043  Train Top 1 Acc: 98.56%  Val Loss: 0.281  Val Top 1 Acc: 93.94%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.53%   Overtime:  3H 43M  0S\n",
      "Epoch: 163/200  Train Loss: 0.045  Train Top 1 Acc: 98.54%  Val Loss: 0.285  Val Top 1 Acc: 93.89%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.48%   Overtime:  3H 44M 22S\n",
      "Epoch: 164/200  Train Loss: 0.045  Train Top 1 Acc: 98.50%  Val Loss: 0.292  Val Top 1 Acc: 93.96%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.45%   Overtime:  3H 45M 45S\n",
      "Epoch: 165/200  Train Loss: 0.046  Train Top 1 Acc: 98.45%  Val Loss: 0.291  Val Top 1 Acc: 94.15%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.55%   Overtime:  3H 47M  7S\n",
      "Epoch: 166/200  Train Loss: 0.042  Train Top 1 Acc: 98.56%  Val Loss: 0.300  Val Top 1 Acc: 93.82%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.43%   Overtime:  3H 48M 29S\n",
      "Epoch: 167/200  Train Loss: 0.044  Train Top 1 Acc: 98.54%  Val Loss: 0.297  Val Top 1 Acc: 93.85%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.52%   Overtime:  3H 49M 52S\n",
      "Epoch: 168/200  Train Loss: 0.043  Train Top 1 Acc: 98.58%  Val Loss: 0.294  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.43%   Overtime:  3H 51M 15S\n",
      "Epoch: 169/200  Train Loss: 0.042  Train Top 1 Acc: 98.58%  Val Loss: 0.290  Val Top 1 Acc: 93.98%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.47%   Overtime:  3H 52M 38S\n",
      "Epoch: 170/200  Train Loss: 0.044  Train Top 1 Acc: 98.55%  Val Loss: 0.299  Val Top 1 Acc: 93.89%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.40%   Overtime:  3H 54M  0S\n",
      "Epoch: 171/200  Train Loss: 0.042  Train Top 1 Acc: 98.57%  Val Loss: 0.294  Val Top 1 Acc: 94.02%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.47%   Overtime:  3H 55M 22S\n",
      "Epoch: 172/200  Train Loss: 0.041  Train Top 1 Acc: 98.60%  Val Loss: 0.300  Val Top 1 Acc: 93.88%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.47%   Overtime:  3H 56M 45S\n",
      "Epoch: 173/200  Train Loss: 0.042  Train Top 1 Acc: 98.59%  Val Loss: 0.299  Val Top 1 Acc: 93.82%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.41%   Overtime:  3H 58M  7S\n",
      "Epoch: 174/200  Train Loss: 0.042  Train Top 1 Acc: 98.58%  Val Loss: 0.292  Val Top 1 Acc: 94.02%\n",
      "                                   Train Top 3 Acc: 99.89%                   Val Top 3 Acc: 98.49%   Overtime:  3H 59M 30S\n",
      "Epoch: 175/200  Train Loss: 0.041  Train Top 1 Acc: 98.65%  Val Loss: 0.313  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.42%   Overtime:  4H  0M 53S\n",
      "Epoch: 176/200  Train Loss: 0.041  Train Top 1 Acc: 98.65%  Val Loss: 0.298  Val Top 1 Acc: 94.00%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.38%   Overtime:  4H  2M 16S\n",
      "Epoch: 177/200  Train Loss: 0.040  Train Top 1 Acc: 98.63%  Val Loss: 0.300  Val Top 1 Acc: 94.06%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.46%   Overtime:  4H  3M 39S\n",
      "Epoch: 178/200  Train Loss: 0.040  Train Top 1 Acc: 98.61%  Val Loss: 0.310  Val Top 1 Acc: 93.73%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.44%   Overtime:  4H  5M  1S\n",
      "Epoch: 179/200  Train Loss: 0.041  Train Top 1 Acc: 98.59%  Val Loss: 0.310  Val Top 1 Acc: 93.81%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.47%   Overtime:  4H  6M 24S\n",
      "Epoch: 180/200  Train Loss: 0.040  Train Top 1 Acc: 98.67%  Val Loss: 0.326  Val Top 1 Acc: 93.72%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.35%   Overtime:  4H  7M 46S\n",
      "Epoch: 181/200  Train Loss: 0.039  Train Top 1 Acc: 98.66%  Val Loss: 0.310  Val Top 1 Acc: 93.77%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.39%   Overtime:  4H  9M  8S\n",
      "Epoch: 182/200  Train Loss: 0.041  Train Top 1 Acc: 98.59%  Val Loss: 0.314  Val Top 1 Acc: 93.95%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.41%   Overtime:  4H 10M 31S\n",
      "Epoch: 183/200  Train Loss: 0.039  Train Top 1 Acc: 98.70%  Val Loss: 0.310  Val Top 1 Acc: 94.01%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.43%   Overtime:  4H 11M 54S\n",
      "Epoch: 184/200  Train Loss: 0.039  Train Top 1 Acc: 98.72%  Val Loss: 0.305  Val Top 1 Acc: 94.01%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.52%   Overtime:  4H 13M 16S\n",
      "Epoch: 185/200  Train Loss: 0.039  Train Top 1 Acc: 98.72%  Val Loss: 0.306  Val Top 1 Acc: 94.01%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.51%   Overtime:  4H 14M 39S\n",
      "Epoch: 186/200  Train Loss: 0.038  Train Top 1 Acc: 98.70%  Val Loss: 0.320  Val Top 1 Acc: 93.75%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.45%   Overtime:  4H 16M  1S\n",
      "Epoch: 187/200  Train Loss: 0.041  Train Top 1 Acc: 98.61%  Val Loss: 0.304  Val Top 1 Acc: 94.08%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.42%   Overtime:  4H 17M 24S\n",
      "Epoch: 188/200  Train Loss: 0.038  Train Top 1 Acc: 98.72%  Val Loss: 0.313  Val Top 1 Acc: 93.84%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.40%   Overtime:  4H 18M 46S\n",
      "Epoch: 189/200  Train Loss: 0.039  Train Top 1 Acc: 98.67%  Val Loss: 0.314  Val Top 1 Acc: 93.66%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.46%   Overtime:  4H 20M  8S\n",
      "Epoch: 190/200  Train Loss: 0.038  Train Top 1 Acc: 98.72%  Val Loss: 0.308  Val Top 1 Acc: 93.92%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.45%   Overtime:  4H 21M 30S\n",
      "Epoch: 191/200  Train Loss: 0.040  Train Top 1 Acc: 98.67%  Val Loss: 0.317  Val Top 1 Acc: 93.73%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.42%   Overtime:  4H 22M 52S\n",
      "Epoch: 192/200  Train Loss: 0.041  Train Top 1 Acc: 98.58%  Val Loss: 0.315  Val Top 1 Acc: 93.78%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.38%   Overtime:  4H 24M 15S\n",
      "Epoch: 193/200  Train Loss: 0.040  Train Top 1 Acc: 98.69%  Val Loss: 0.305  Val Top 1 Acc: 94.00%\n",
      "                                   Train Top 3 Acc: 99.90%                   Val Top 3 Acc: 98.46%   Overtime:  4H 25M 37S\n",
      "Epoch: 194/200  Train Loss: 0.036  Train Top 1 Acc: 98.77%  Val Loss: 0.305  Val Top 1 Acc: 93.97%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.46%   Overtime:  4H 26M 59S\n",
      "Epoch: 195/200  Train Loss: 0.037  Train Top 1 Acc: 98.75%  Val Loss: 0.316  Val Top 1 Acc: 93.94%\n",
      "                                   Train Top 3 Acc: 99.91%                   Val Top 3 Acc: 98.45%   Overtime:  4H 28M 22S\n",
      "Epoch: 196/200  Train Loss: 0.039  Train Top 1 Acc: 98.67%  Val Loss: 0.316  Val Top 1 Acc: 93.70%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.41%   Overtime:  4H 29M 44S\n",
      "Epoch: 197/200  Train Loss: 0.038  Train Top 1 Acc: 98.72%  Val Loss: 0.305  Val Top 1 Acc: 93.98%\n",
      "                                   Train Top 3 Acc: 99.93%                   Val Top 3 Acc: 98.41%   Overtime:  4H 31M  7S\n",
      "Epoch: 198/200  Train Loss: 0.038  Train Top 1 Acc: 98.75%  Val Loss: 0.319  Val Top 1 Acc: 93.61%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.44%   Overtime:  4H 32M 29S\n",
      "Epoch: 199/200  Train Loss: 0.037  Train Top 1 Acc: 98.78%  Val Loss: 0.319  Val Top 1 Acc: 93.79%\n",
      "                                   Train Top 3 Acc: 99.92%                   Val Top 3 Acc: 98.34%   Overtime:  4H 33M 51S\n",
      "Epoch: 200/200  Train Loss: 0.037  Train Top 1 Acc: 98.74%  Val Loss: 0.311  Val Top 1 Acc: 94.08%\n",
      "                                   Train Top 3 Acc: 99.94%                   Val Top 3 Acc: 98.51%   Overtime:  4H 35M 14S\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    result_sr = result_df.iloc[i]\n",
    "    epoch = int(result_sr['EPOCH'])\n",
    "    train_loss = result_sr['Train Loss']\n",
    "    train_top1_acc = result_sr['Train Top 1 Acc']\n",
    "    train_topk_acc = result_sr['Train Top k Acc']\n",
    "    val_loss = result_sr['Val Loss']\n",
    "    val_top1_acc = result_sr['Val Top 1 Acc']\n",
    "    val_topk_acc = result_sr['Val Top k Acc']\n",
    "    overtime = int(result_sr['Time'])\n",
    "    print(f'Epoch: {epoch:>3}/{EPOCHS}  Train Loss: {train_loss:.3f}  Train Top 1 Acc: {train_top1_acc:.2f}%  Val Loss: {val_loss:.3f}  Val Top 1 Acc: {val_top1_acc:.2f}%')\n",
    "    print(f'                                   Train Top 3 Acc: {train_topk_acc:.2f}%                   Val Top 3 Acc: {val_topk_acc:.2f}%   Overtime: {overtime//3600:>2}H {(overtime//60)%60:>2}M {overtime%60:>2}S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "308b7876-9831-4fcf-a302-58709c743100",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense10_svhn = torch.load('./odin/models/densenet10_svhn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b8e5319c-75ea-4585-b1d7-6933b8177fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31109534664687455, 94.07652120467118, 98.50568531038722)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_evaluate(model=dense10_svhn,topk=3, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "37ee7798-2f5f-40d5-8d0d-409d2c037c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cal.py copied'''\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import misc\n",
    "import calMetric as m\n",
    "import calData as d\n",
    "#CUDA_DEVICE = 0\n",
    "\n",
    "start = time.time()\n",
    "#loading data sets\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # `Normalize` is the class which normalize data channelwise by the given mean and std.\n",
    "    # In this case, the number of input channels is 3 because the lenght of the iterable object is 3.\n",
    "    # Ref: https://pytorch.org/vision/stable/transforms.html\n",
    "    # Ref of various image normalizing: https://stackoverflow.com/questions/33610825/normalization-in-image-processing\n",
    "    transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614)),\n",
    "    transforms.Resize(32)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loading neural network\n",
    "\n",
    "# Name of neural networks\n",
    "# Densenet trained on CIFAR-10:         densenet10\n",
    "# Densenet trained on CIFAR-100:        densenet100\n",
    "# Densenet trained on WideResNet-10:    wideresnet10\n",
    "# Densenet trained on WideResNet-100:   wideresnet100\n",
    "#nnName = \"densenet10\"\n",
    "\n",
    "#imName = \"Imagenet\"\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def test(nnName, dataName, CUDA_DEVICE, epsilon, temperature):\n",
    "    \n",
    "    net1 = torch.load(\"../models/{}.pth\".format(nnName))\n",
    "    optimizer1 = optim.SGD(net1.parameters(), lr = 0, momentum = 0)\n",
    "    net1.cuda(CUDA_DEVICE)\n",
    "    \n",
    "    # We suppose the out-of distribution data is `Uniform` or `Gaussian`. \n",
    "    # If you do not, we call the data as `testsetout`.\n",
    "    if dataName != \"Uniform\" and dataName != \"Gaussian\":\n",
    "        testsetout = torchvision.datasets.ImageFolder(\"../data/{}\".format(dataName), transform=transform)\n",
    "        testloaderOut = torch.utils.data.DataLoader(testsetout, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "        \n",
    "    # OOD 성능을 평가할 때는 고정되어야 하는 것들이 있다.\n",
    "    # 적어도 같은 모델이어야 하고 같은 데이터이어야 한다(in dist & out-of dist 모두). (이것도 하이퍼 파라미터라고 볼 수 있을까?)\n",
    "    # 그래야 OOD 방법론에 대한 정량적인 평가가 가능하기때문.\n",
    "    if nnName == \"densenet10\" or nnName == \"wideresnet10\": \n",
    "        testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "        testloaderIn = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "        \n",
    "    if nnName == \"densenet100\" or nnName == \"wideresnet100\": \n",
    "        testset = torchvision.datasets.CIFAR100(root='../data', train=False, download=True, transform=transform)\n",
    "        testloaderIn = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    if nnName == \"densenet10_svhn\":\n",
    "        testset = torchvision.datasets.SVHN(root='../data', split='test', download=True, transform=transform)\n",
    "        testloaderIn = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    \n",
    "    if dataName == \"Gaussian\":\n",
    "        d.testGaussian(net1, criterion, CUDA_DEVICE, testloaderIn, testloaderIn, nnName, dataName, epsilon, temperature)\n",
    "        m.metric(nnName, dataName)\n",
    "\n",
    "    elif dataName == \"Uniform\":\n",
    "        d.testUni(net1, criterion, CUDA_DEVICE, testloaderIn, testloaderIn, nnName, dataName, epsilon, temperature)\n",
    "        m.metric(nnName, dataName)\n",
    "        \n",
    "    else:\n",
    "        d.testData(net1, criterion, CUDA_DEVICE, testloaderIn, testloaderOut, nnName, dataName, epsilon, temperature) \n",
    "        m.metric(nnName, dataName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153f61f3-05c5-4b34-86f8-083becd11f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mydir/dn2ood/odin/code/calData.py:72: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Tensor input, Number alpha, Tensor other, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor input, Tensor other, *, Number alpha, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100/9000 images processed, 4.8 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.0 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 4.0 seconds used.\n",
      "3400/9000 images processed, 4.0 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.0 seconds used.\n",
      "3700/9000 images processed, 4.0 seconds used.\n",
      "3800/9000 images processed, 4.0 seconds used.\n",
      "3900/9000 images processed, 4.0 seconds used.\n",
      "4000/9000 images processed, 4.0 seconds used.\n",
      "4100/9000 images processed, 4.0 seconds used.\n",
      "4200/9000 images processed, 4.0 seconds used.\n",
      "4300/9000 images processed, 4.0 seconds used.\n",
      "4400/9000 images processed, 4.0 seconds used.\n",
      "4500/9000 images processed, 4.0 seconds used.\n",
      "4600/9000 images processed, 4.0 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.0 seconds used.\n",
      "5600/9000 images processed, 4.0 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.0 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.1 seconds used.\n",
      "7500/9000 images processed, 4.3 seconds used.\n",
      "7600/9000 images processed, 4.3 seconds used.\n",
      "7700/9000 images processed, 4.3 seconds used.\n",
      "7800/9000 images processed, 4.2 seconds used.\n",
      "7900/9000 images processed, 4.3 seconds used.\n",
      "8000/9000 images processed, 4.4 seconds used.\n",
      "8100/9000 images processed, 4.4 seconds used.\n",
      "8200/9000 images processed, 4.2 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 4.4 seconds used.\n",
      " 200/9000 images processed, 3.6 seconds used.\n",
      " 300/9000 images processed, 3.6 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 3.9 seconds used.\n",
      " 900/9000 images processed, 4.1 seconds used.\n",
      "1000/9000 images processed, 4.4 seconds used.\n",
      "1100/9000 images processed, 4.4 seconds used.\n",
      "1200/9000 images processed, 4.4 seconds used.\n",
      "1300/9000 images processed, 4.3 seconds used.\n",
      "1400/9000 images processed, 4.4 seconds used.\n",
      "1500/9000 images processed, 4.3 seconds used.\n",
      "1600/9000 images processed, 4.4 seconds used.\n",
      "1700/9000 images processed, 4.4 seconds used.\n",
      "1800/9000 images processed, 4.4 seconds used.\n",
      "1900/9000 images processed, 4.3 seconds used.\n",
      "2000/9000 images processed, 4.4 seconds used.\n",
      "2100/9000 images processed, 4.4 seconds used.\n",
      "2200/9000 images processed, 4.3 seconds used.\n",
      "2300/9000 images processed, 4.4 seconds used.\n",
      "2400/9000 images processed, 4.4 seconds used.\n",
      "2500/9000 images processed, 4.4 seconds used.\n",
      "2600/9000 images processed, 4.4 seconds used.\n",
      "2700/9000 images processed, 4.4 seconds used.\n",
      "2800/9000 images processed, 4.4 seconds used.\n",
      "2900/9000 images processed, 4.3 seconds used.\n",
      "3000/9000 images processed, 4.3 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 3.9 seconds used.\n",
      "3400/9000 images processed, 4.0 seconds used.\n",
      "3500/9000 images processed, 3.9 seconds used.\n",
      "3600/9000 images processed, 4.0 seconds used.\n",
      "3700/9000 images processed, 4.3 seconds used.\n",
      "3800/9000 images processed, 4.4 seconds used.\n",
      "3900/9000 images processed, 4.3 seconds used.\n",
      "4000/9000 images processed, 4.4 seconds used.\n",
      "4100/9000 images processed, 4.4 seconds used.\n",
      "4200/9000 images processed, 4.4 seconds used.\n",
      "4300/9000 images processed, 4.2 seconds used.\n",
      "4400/9000 images processed, 4.3 seconds used.\n",
      "4500/9000 images processed, 4.3 seconds used.\n",
      "4600/9000 images processed, 4.4 seconds used.\n",
      "4700/9000 images processed, 4.4 seconds used.\n",
      "4800/9000 images processed, 4.3 seconds used.\n",
      "4900/9000 images processed, 3.9 seconds used.\n",
      "5000/9000 images processed, 3.9 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 3.6 seconds used.\n",
      "5400/9000 images processed, 3.6 seconds used.\n",
      "5500/9000 images processed, 3.7 seconds used.\n",
      "5600/9000 images processed, 4.3 seconds used.\n",
      "5700/9000 images processed, 4.4 seconds used.\n",
      "5800/9000 images processed, 4.4 seconds used.\n",
      "5900/9000 images processed, 4.4 seconds used.\n",
      "6000/9000 images processed, 4.2 seconds used.\n",
      "6100/9000 images processed, 4.4 seconds used.\n",
      "6200/9000 images processed, 4.3 seconds used.\n",
      "6300/9000 images processed, 4.3 seconds used.\n",
      "6400/9000 images processed, 4.4 seconds used.\n",
      "6500/9000 images processed, 4.4 seconds used.\n",
      "6600/9000 images processed, 4.4 seconds used.\n",
      "6700/9000 images processed, 4.3 seconds used.\n",
      "6800/9000 images processed, 4.3 seconds used.\n",
      "6900/9000 images processed, 4.4 seconds used.\n",
      "7000/9000 images processed, 4.2 seconds used.\n",
      "7100/9000 images processed, 4.3 seconds used.\n",
      "7200/9000 images processed, 4.4 seconds used.\n",
      "7300/9000 images processed, 4.3 seconds used.\n",
      "7400/9000 images processed, 4.3 seconds used.\n",
      "7500/9000 images processed, 4.3 seconds used.\n",
      "7600/9000 images processed, 4.3 seconds used.\n",
      "7700/9000 images processed, 4.4 seconds used.\n",
      "7800/9000 images processed, 4.4 seconds used.\n",
      "7900/9000 images processed, 4.3 seconds used.\n",
      "8000/9000 images processed, 4.4 seconds used.\n",
      "8100/9000 images processed, 4.3 seconds used.\n",
      "8200/9000 images processed, 4.3 seconds used.\n",
      "8300/9000 images processed, 4.3 seconds used.\n",
      "8400/9000 images processed, 4.4 seconds used.\n",
      "8500/9000 images processed, 4.3 seconds used.\n",
      "8600/9000 images processed, 4.3 seconds used.\n",
      "8700/9000 images processed, 4.4 seconds used.\n",
      "8800/9000 images processed, 4.5 seconds used.\n",
      "8900/9000 images processed, 4.4 seconds used.\n",
      "9000/9000 images processed, 4.3 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:     Tiny-ImageNet (crop)\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              44.2%              26.0% \n",
      "Detection error:             12.8%              11.8%\n",
      "AUROC:                       93.3%              94.7%\n",
      "AUPR In:                     94.0%              94.1%\n",
      "AUPR Out:                    91.5%              94.7%\n"
     ]
    }
   ],
   "source": [
    "import  cal as c\n",
    "c.test('densenet10_svhn', 'Imagenet', 0, 0.0014, 1000) # 첫번째 인자는 모델명, 두번째 인자는 ood dataset의 이름, 세번째는 # gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43c2124-1d58-4730-9324-19ff717c46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Processing in-distribution images\n",
      " 100/9000 images processed, 4.7 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.1 seconds used.\n",
      " 600/9000 images processed, 4.2 seconds used.\n",
      " 700/9000 images processed, 4.2 seconds used.\n",
      " 800/9000 images processed, 4.2 seconds used.\n",
      " 900/9000 images processed, 4.1 seconds used.\n",
      "1000/9000 images processed, 4.1 seconds used.\n",
      "1100/9000 images processed, 4.1 seconds used.\n",
      "1200/9000 images processed, 4.1 seconds used.\n",
      "1300/9000 images processed, 4.2 seconds used.\n",
      "1400/9000 images processed, 4.2 seconds used.\n",
      "1500/9000 images processed, 4.2 seconds used.\n",
      "1600/9000 images processed, 4.2 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.1 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.1 seconds used.\n",
      "2600/9000 images processed, 4.2 seconds used.\n",
      "2700/9000 images processed, 4.2 seconds used.\n",
      "2800/9000 images processed, 4.2 seconds used.\n",
      "2900/9000 images processed, 4.2 seconds used.\n",
      "3000/9000 images processed, 4.2 seconds used.\n",
      "3100/9000 images processed, 4.2 seconds used.\n",
      "3200/9000 images processed, 4.3 seconds used.\n",
      "3300/9000 images processed, 4.3 seconds used.\n",
      "3400/9000 images processed, 4.3 seconds used.\n",
      "3500/9000 images processed, 4.3 seconds used.\n",
      "3600/9000 images processed, 4.3 seconds used.\n",
      "3700/9000 images processed, 4.4 seconds used.\n",
      "3800/9000 images processed, 4.4 seconds used.\n",
      "3900/9000 images processed, 4.3 seconds used.\n",
      "4000/9000 images processed, 4.4 seconds used.\n",
      "4100/9000 images processed, 4.4 seconds used.\n",
      "4200/9000 images processed, 4.2 seconds used.\n",
      "4300/9000 images processed, 4.2 seconds used.\n",
      "4400/9000 images processed, 4.0 seconds used.\n",
      "4500/9000 images processed, 4.0 seconds used.\n",
      "4600/9000 images processed, 4.0 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.0 seconds used.\n",
      "5600/9000 images processed, 4.0 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.0 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 3.9 seconds used.\n",
      "7500/9000 images processed, 4.0 seconds used.\n",
      "7600/9000 images processed, 4.0 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 4.9 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 3.9 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.1 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.1 seconds used.\n",
      "3300/9000 images processed, 4.2 seconds used.\n",
      "3400/9000 images processed, 4.2 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.0 seconds used.\n",
      "3700/9000 images processed, 4.0 seconds used.\n",
      "3800/9000 images processed, 4.0 seconds used.\n",
      "3900/9000 images processed, 4.0 seconds used.\n",
      "4000/9000 images processed, 4.1 seconds used.\n",
      "4100/9000 images processed, 4.1 seconds used.\n",
      "4200/9000 images processed, 4.1 seconds used.\n",
      "4300/9000 images processed, 4.1 seconds used.\n",
      "4400/9000 images processed, 4.1 seconds used.\n",
      "4500/9000 images processed, 4.1 seconds used.\n",
      "4600/9000 images processed, 4.1 seconds used.\n",
      "4700/9000 images processed, 4.1 seconds used.\n",
      "4800/9000 images processed, 4.1 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.3 seconds used.\n",
      "5600/9000 images processed, 4.3 seconds used.\n",
      "5700/9000 images processed, 4.3 seconds used.\n",
      "5800/9000 images processed, 4.3 seconds used.\n",
      "5900/9000 images processed, 4.3 seconds used.\n",
      "6000/9000 images processed, 4.3 seconds used.\n",
      "6100/9000 images processed, 4.3 seconds used.\n",
      "6200/9000 images processed, 4.3 seconds used.\n",
      "6300/9000 images processed, 4.3 seconds used.\n",
      "6400/9000 images processed, 4.3 seconds used.\n",
      "6500/9000 images processed, 4.1 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.1 seconds used.\n",
      "6800/9000 images processed, 4.1 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.0 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.0 seconds used.\n",
      "7500/9000 images processed, 4.0 seconds used.\n",
      "7600/9000 images processed, 4.1 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                     CIFAR-10\n",
      "Out-of-distribution dataset:     Tiny-ImageNet (crop)\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              34.8%               4.3% \n",
      "Detection error:             10.0%               4.6%\n",
      "AUROC:                       95.3%              99.1%\n",
      "AUPR In:                     96.4%              99.2%\n",
      "AUPR Out:                    93.8%              99.1%\n"
     ]
    }
   ],
   "source": [
    "c.test('densenet10', 'Imagenet_crop', 0, 0.0014, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71211e18-60f3-42e6-b58a-7bc82fffdac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n",
      " 100/9000 images processed, 4.8 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.0 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.2 seconds used.\n",
      "3100/9000 images processed, 4.3 seconds used.\n",
      "3200/9000 images processed, 4.2 seconds used.\n",
      "3300/9000 images processed, 3.9 seconds used.\n",
      "3400/9000 images processed, 4.1 seconds used.\n",
      "3500/9000 images processed, 4.1 seconds used.\n",
      "3600/9000 images processed, 4.0 seconds used.\n",
      "3700/9000 images processed, 4.0 seconds used.\n",
      "3800/9000 images processed, 4.0 seconds used.\n",
      "3900/9000 images processed, 4.0 seconds used.\n",
      "4000/9000 images processed, 4.0 seconds used.\n",
      "4100/9000 images processed, 4.0 seconds used.\n",
      "4200/9000 images processed, 3.9 seconds used.\n",
      "4300/9000 images processed, 4.0 seconds used.\n",
      "4400/9000 images processed, 4.0 seconds used.\n",
      "4500/9000 images processed, 3.9 seconds used.\n",
      "4600/9000 images processed, 3.9 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.2 seconds used.\n",
      "4900/9000 images processed, 4.2 seconds used.\n",
      "5000/9000 images processed, 4.3 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.1 seconds used.\n",
      "5300/9000 images processed, 4.4 seconds used.\n",
      "5400/9000 images processed, 4.3 seconds used.\n",
      "5500/9000 images processed, 4.3 seconds used.\n",
      "5600/9000 images processed, 4.2 seconds used.\n",
      "5700/9000 images processed, 4.3 seconds used.\n",
      "5800/9000 images processed, 4.3 seconds used.\n",
      "5900/9000 images processed, 4.3 seconds used.\n",
      "6000/9000 images processed, 4.3 seconds used.\n",
      "6100/9000 images processed, 4.3 seconds used.\n",
      "6200/9000 images processed, 4.3 seconds used.\n",
      "6300/9000 images processed, 4.1 seconds used.\n",
      "6400/9000 images processed, 3.9 seconds used.\n",
      "6500/9000 images processed, 4.4 seconds used.\n",
      "6600/9000 images processed, 4.2 seconds used.\n",
      "6700/9000 images processed, 4.1 seconds used.\n",
      "6800/9000 images processed, 4.1 seconds used.\n",
      "6900/9000 images processed, 4.3 seconds used.\n",
      "7000/9000 images processed, 4.4 seconds used.\n",
      "7100/9000 images processed, 4.3 seconds used.\n",
      "7200/9000 images processed, 4.3 seconds used.\n",
      "7300/9000 images processed, 4.4 seconds used.\n",
      "7400/9000 images processed, 4.2 seconds used.\n",
      "7500/9000 images processed, 4.1 seconds used.\n",
      "7600/9000 images processed, 4.3 seconds used.\n",
      "7700/9000 images processed, 4.2 seconds used.\n",
      "7800/9000 images processed, 4.4 seconds used.\n",
      "7900/9000 images processed, 4.4 seconds used.\n",
      "8000/9000 images processed, 4.3 seconds used.\n",
      "8100/9000 images processed, 4.3 seconds used.\n",
      "8200/9000 images processed, 4.4 seconds used.\n",
      "8300/9000 images processed, 4.4 seconds used.\n",
      "8400/9000 images processed, 4.4 seconds used.\n",
      "8500/9000 images processed, 4.3 seconds used.\n",
      "8600/9000 images processed, 4.3 seconds used.\n",
      "8700/9000 images processed, 4.3 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.1 seconds used.\n",
      "9000/9000 images processed, 4.2 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 4.9 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.1 seconds used.\n",
      "1900/9000 images processed, 4.3 seconds used.\n",
      "2000/9000 images processed, 4.2 seconds used.\n",
      "2100/9000 images processed, 4.4 seconds used.\n",
      "2200/9000 images processed, 4.2 seconds used.\n",
      "2300/9000 images processed, 4.3 seconds used.\n",
      "2400/9000 images processed, 4.4 seconds used.\n",
      "2500/9000 images processed, 4.3 seconds used.\n",
      "2600/9000 images processed, 4.3 seconds used.\n",
      "2700/9000 images processed, 4.3 seconds used.\n",
      "2800/9000 images processed, 4.3 seconds used.\n",
      "2900/9000 images processed, 4.3 seconds used.\n",
      "3000/9000 images processed, 4.3 seconds used.\n",
      "3100/9000 images processed, 4.3 seconds used.\n",
      "3200/9000 images processed, 4.4 seconds used.\n",
      "3300/9000 images processed, 4.3 seconds used.\n",
      "3400/9000 images processed, 4.0 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 3.9 seconds used.\n",
      "3700/9000 images processed, 4.0 seconds used.\n",
      "3800/9000 images processed, 4.4 seconds used.\n",
      "3900/9000 images processed, 4.4 seconds used.\n",
      "4000/9000 images processed, 4.4 seconds used.\n",
      "4100/9000 images processed, 4.4 seconds used.\n",
      "4200/9000 images processed, 4.3 seconds used.\n",
      "4300/9000 images processed, 4.3 seconds used.\n",
      "4400/9000 images processed, 4.3 seconds used.\n",
      "4500/9000 images processed, 4.0 seconds used.\n",
      "4600/9000 images processed, 4.3 seconds used.\n",
      "4700/9000 images processed, 4.3 seconds used.\n",
      "4800/9000 images processed, 4.4 seconds used.\n",
      "4900/9000 images processed, 4.4 seconds used.\n",
      "5000/9000 images processed, 4.4 seconds used.\n",
      "5100/9000 images processed, 4.3 seconds used.\n",
      "5200/9000 images processed, 4.3 seconds used.\n",
      "5300/9000 images processed, 4.1 seconds used.\n",
      "5400/9000 images processed, 4.3 seconds used.\n",
      "5500/9000 images processed, 4.3 seconds used.\n",
      "5600/9000 images processed, 4.1 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.2 seconds used.\n",
      "5900/9000 images processed, 4.4 seconds used.\n",
      "6000/9000 images processed, 4.3 seconds used.\n",
      "6100/9000 images processed, 4.4 seconds used.\n",
      "6200/9000 images processed, 4.4 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.3 seconds used.\n",
      "6500/9000 images processed, 4.4 seconds used.\n",
      "6600/9000 images processed, 4.3 seconds used.\n",
      "6700/9000 images processed, 4.4 seconds used.\n",
      "6800/9000 images processed, 4.3 seconds used.\n",
      "6900/9000 images processed, 4.3 seconds used.\n",
      "7000/9000 images processed, 4.4 seconds used.\n",
      "7100/9000 images processed, 4.2 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.0 seconds used.\n",
      "7500/9000 images processed, 4.0 seconds used.\n",
      "7600/9000 images processed, 4.0 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.1 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:   Tiny-ImageNet (resize)\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              42.9%              22.8% \n",
      "Detection error:             12.7%              11.2%\n",
      "AUROC:                       93.3%              95.0%\n",
      "AUPR In:                     93.9%              94.4%\n",
      "AUPR Out:                    91.5%              95.2%\n"
     ]
    }
   ],
   "source": [
    "c.test('densenet10_svhn', 'Imagenet_resize', 0, 0.0014, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3a42e6-9cb8-4866-b0ff-836bd95a2213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n",
      " 100/9000 images processed, 4.8 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.0 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 4.0 seconds used.\n",
      "3400/9000 images processed, 4.0 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.2 seconds used.\n",
      "3700/9000 images processed, 4.1 seconds used.\n",
      "3800/9000 images processed, 4.2 seconds used.\n",
      "3900/9000 images processed, 4.2 seconds used.\n",
      "4000/9000 images processed, 4.2 seconds used.\n",
      "4100/9000 images processed, 4.2 seconds used.\n",
      "4200/9000 images processed, 4.1 seconds used.\n",
      "4300/9000 images processed, 4.3 seconds used.\n",
      "4400/9000 images processed, 4.3 seconds used.\n",
      "4500/9000 images processed, 4.3 seconds used.\n",
      "4600/9000 images processed, 4.2 seconds used.\n",
      "4700/9000 images processed, 3.7 seconds used.\n",
      "4800/9000 images processed, 4.1 seconds used.\n",
      "4900/9000 images processed, 4.3 seconds used.\n",
      "5000/9000 images processed, 4.2 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 3.9 seconds used.\n",
      "5500/9000 images processed, 3.8 seconds used.\n",
      "5600/9000 images processed, 4.2 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.1 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.1 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.1 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.1 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.0 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.2 seconds used.\n",
      "7500/9000 images processed, 4.4 seconds used.\n",
      "7600/9000 images processed, 4.2 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 4.9 seconds used.\n",
      " 200/9000 images processed, 4.1 seconds used.\n",
      " 300/9000 images processed, 4.1 seconds used.\n",
      " 400/9000 images processed, 4.1 seconds used.\n",
      " 500/9000 images processed, 4.1 seconds used.\n",
      " 600/9000 images processed, 4.1 seconds used.\n",
      " 700/9000 images processed, 4.1 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.1 seconds used.\n",
      "1200/9000 images processed, 4.1 seconds used.\n",
      "1300/9000 images processed, 4.1 seconds used.\n",
      "1400/9000 images processed, 4.1 seconds used.\n",
      "1500/9000 images processed, 4.1 seconds used.\n",
      "1600/9000 images processed, 4.1 seconds used.\n",
      "1700/9000 images processed, 4.2 seconds used.\n",
      "1800/9000 images processed, 4.2 seconds used.\n",
      "1900/9000 images processed, 4.2 seconds used.\n",
      "2000/9000 images processed, 4.1 seconds used.\n",
      "2100/9000 images processed, 4.2 seconds used.\n",
      "2200/9000 images processed, 4.3 seconds used.\n",
      "2300/9000 images processed, 4.3 seconds used.\n",
      "2400/9000 images processed, 4.3 seconds used.\n",
      "2500/9000 images processed, 4.3 seconds used.\n",
      "2600/9000 images processed, 4.3 seconds used.\n",
      "2700/9000 images processed, 4.4 seconds used.\n",
      "2800/9000 images processed, 4.3 seconds used.\n",
      "2900/9000 images processed, 4.3 seconds used.\n",
      "3000/9000 images processed, 4.1 seconds used.\n",
      "3100/9000 images processed, 4.3 seconds used.\n",
      "3200/9000 images processed, 4.1 seconds used.\n",
      "3300/9000 images processed, 4.1 seconds used.\n",
      "3400/9000 images processed, 4.1 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.1 seconds used.\n",
      "3700/9000 images processed, 4.1 seconds used.\n",
      "3800/9000 images processed, 4.1 seconds used.\n",
      "3900/9000 images processed, 4.1 seconds used.\n",
      "4000/9000 images processed, 4.0 seconds used.\n",
      "4100/9000 images processed, 4.0 seconds used.\n",
      "4200/9000 images processed, 4.1 seconds used.\n",
      "4300/9000 images processed, 4.1 seconds used.\n",
      "4400/9000 images processed, 4.1 seconds used.\n",
      "4500/9000 images processed, 4.1 seconds used.\n",
      "4600/9000 images processed, 4.1 seconds used.\n",
      "4700/9000 images processed, 4.1 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.1 seconds used.\n",
      "5100/9000 images processed, 4.1 seconds used.\n",
      "5200/9000 images processed, 4.1 seconds used.\n",
      "5300/9000 images processed, 4.1 seconds used.\n",
      "5400/9000 images processed, 4.1 seconds used.\n",
      "5500/9000 images processed, 4.1 seconds used.\n",
      "5600/9000 images processed, 4.1 seconds used.\n",
      "5700/9000 images processed, 4.1 seconds used.\n",
      "5800/9000 images processed, 4.1 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.1 seconds used.\n",
      "6600/9000 images processed, 4.2 seconds used.\n",
      "6700/9000 images processed, 4.1 seconds used.\n",
      "6800/9000 images processed, 4.2 seconds used.\n",
      "6900/9000 images processed, 4.2 seconds used.\n",
      "7000/9000 images processed, 4.2 seconds used.\n",
      "7100/9000 images processed, 4.3 seconds used.\n",
      "7200/9000 images processed, 4.3 seconds used.\n",
      "7300/9000 images processed, 4.3 seconds used.\n",
      "7400/9000 images processed, 4.2 seconds used.\n",
      "7500/9000 images processed, 4.1 seconds used.\n",
      "7600/9000 images processed, 4.1 seconds used.\n",
      "7700/9000 images processed, 4.1 seconds used.\n",
      "7800/9000 images processed, 4.1 seconds used.\n",
      "7900/9000 images processed, 4.1 seconds used.\n",
      "8000/9000 images processed, 4.3 seconds used.\n",
      "8100/9000 images processed, 4.2 seconds used.\n",
      "8200/9000 images processed, 4.4 seconds used.\n",
      "8300/9000 images processed, 4.5 seconds used.\n",
      "8400/9000 images processed, 4.5 seconds used.\n",
      "8500/9000 images processed, 3.7 seconds used.\n",
      "8600/9000 images processed, 4.3 seconds used.\n",
      "8700/9000 images processed, 4.4 seconds used.\n",
      "8800/9000 images processed, 4.4 seconds used.\n",
      "8900/9000 images processed, 4.4 seconds used.\n",
      "9000/9000 images processed, 4.4 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataName' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c6c84abb2dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'densenet10_svhn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LSUN_crop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mydir/dn2ood/odin/code/cal.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(nnName, dataName, CUDA_DEVICE, epsilon, temperature)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA_DEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloaderIn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloaderOut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mydir/dn2ood/odin/code/calMetric.py\u001b[0m in \u001b[0;36mmetric\u001b[0;34m(nn, data)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:31}{:>22}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neural network architecture:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnStructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:31}{:>22}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In-distribution dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:31}{:>22}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Out-of-distribution dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:>34}{:>19}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Our Method\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'dataName' referenced before assignment"
     ]
    }
   ],
   "source": [
    "c.test('densenet10_svhn', 'LSUN_crop', 0, 0.0014, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05994afe-99ec-41dc-9754-d2bc918b787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:              LSUN (crop)\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              41.2%              31.1% \n",
      "Detection error:             13.2%              14.0%\n",
      "AUROC:                       93.2%              92.9%\n",
      "AUPR In:                     93.4%              92.1%\n",
      "AUPR Out:                    91.8%              93.2%\n"
     ]
    }
   ],
   "source": [
    "import calMetric as m\n",
    "m.metric('densenet10_svhn', 'LSUN_crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca97b4c6-8691-44a9-bf12-af6b010559de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mydir/dn2ood/odin/code/calData.py:72: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Tensor input, Number alpha, Tensor other, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor input, Tensor other, *, Number alpha, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  tempInputs = torch.add(inputs.data,  -noiseMagnitude1, gradient)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100/9000 images processed, 4.9 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 3.9 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 3.9 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 3.9 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.2 seconds used.\n",
      "2800/9000 images processed, 4.4 seconds used.\n",
      "2900/9000 images processed, 4.4 seconds used.\n",
      "3000/9000 images processed, 4.2 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.3 seconds used.\n",
      "3300/9000 images processed, 4.4 seconds used.\n",
      "3400/9000 images processed, 4.3 seconds used.\n",
      "3500/9000 images processed, 4.3 seconds used.\n",
      "3600/9000 images processed, 4.3 seconds used.\n",
      "3700/9000 images processed, 4.4 seconds used.\n",
      "3800/9000 images processed, 4.2 seconds used.\n",
      "3900/9000 images processed, 4.0 seconds used.\n",
      "4000/9000 images processed, 4.0 seconds used.\n",
      "4100/9000 images processed, 3.7 seconds used.\n",
      "4200/9000 images processed, 3.8 seconds used.\n",
      "4300/9000 images processed, 4.0 seconds used.\n",
      "4400/9000 images processed, 4.0 seconds used.\n",
      "4500/9000 images processed, 4.0 seconds used.\n",
      "4600/9000 images processed, 4.0 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.0 seconds used.\n",
      "5600/9000 images processed, 4.0 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.0 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.0 seconds used.\n",
      "7500/9000 images processed, 4.0 seconds used.\n",
      "7600/9000 images processed, 4.0 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 4.8 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.0 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 4.0 seconds used.\n",
      "3400/9000 images processed, 4.3 seconds used.\n",
      "3500/9000 images processed, 4.4 seconds used.\n",
      "3600/9000 images processed, 4.3 seconds used.\n",
      "3700/9000 images processed, 4.3 seconds used.\n",
      "3800/9000 images processed, 4.4 seconds used.\n",
      "3900/9000 images processed, 4.4 seconds used.\n",
      "4000/9000 images processed, 4.4 seconds used.\n",
      "4100/9000 images processed, 4.4 seconds used.\n",
      "4200/9000 images processed, 4.4 seconds used.\n",
      "4300/9000 images processed, 4.4 seconds used.\n",
      "4400/9000 images processed, 4.3 seconds used.\n",
      "4500/9000 images processed, 4.1 seconds used.\n",
      "4600/9000 images processed, 3.9 seconds used.\n",
      "4700/9000 images processed, 4.1 seconds used.\n",
      "4800/9000 images processed, 4.1 seconds used.\n",
      "4900/9000 images processed, 4.1 seconds used.\n",
      "5000/9000 images processed, 3.7 seconds used.\n",
      "5100/9000 images processed, 3.5 seconds used.\n",
      "5200/9000 images processed, 3.8 seconds used.\n",
      "5300/9000 images processed, 4.4 seconds used.\n",
      "5400/9000 images processed, 4.4 seconds used.\n",
      "5500/9000 images processed, 4.4 seconds used.\n",
      "5600/9000 images processed, 4.2 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.3 seconds used.\n",
      "6100/9000 images processed, 4.3 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.3 seconds used.\n",
      "6500/9000 images processed, 4.4 seconds used.\n",
      "6600/9000 images processed, 4.1 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.2 seconds used.\n",
      "7100/9000 images processed, 4.4 seconds used.\n",
      "7200/9000 images processed, 4.3 seconds used.\n",
      "7300/9000 images processed, 4.3 seconds used.\n",
      "7400/9000 images processed, 4.3 seconds used.\n",
      "7500/9000 images processed, 4.4 seconds used.\n",
      "7600/9000 images processed, 4.2 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.1 seconds used.\n",
      "7900/9000 images processed, 4.2 seconds used.\n",
      "8000/9000 images processed, 4.2 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.1 seconds used.\n",
      "8300/9000 images processed, 4.3 seconds used.\n",
      "8400/9000 images processed, 4.4 seconds used.\n",
      "8500/9000 images processed, 4.3 seconds used.\n",
      "8600/9000 images processed, 4.3 seconds used.\n",
      "8700/9000 images processed, 4.3 seconds used.\n",
      "8800/9000 images processed, 3.9 seconds used.\n",
      "8900/9000 images processed, 4.0 seconds used.\n",
      "9000/9000 images processed, 4.0 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:            LSUN (resize)\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              44.3%              22.7% \n",
      "Detection error:             13.4%              11.3%\n",
      "AUROC:                       92.8%              95.0%\n",
      "AUPR In:                     93.2%              94.7%\n",
      "AUPR Out:                    91.2%              95.2%\n"
     ]
    }
   ],
   "source": [
    "import  cal as c\n",
    "c.test('densenet10_svhn', 'LSUN_resize', 0, 0.0014, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b49877-cf29-482a-a147-ec9a6899fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n",
      " 100/7925 images processed, 4.8 seconds used.\n",
      " 200/7925 images processed, 4.0 seconds used.\n",
      " 300/7925 images processed, 4.0 seconds used.\n",
      " 400/7925 images processed, 4.0 seconds used.\n",
      " 500/7925 images processed, 4.0 seconds used.\n",
      " 600/7925 images processed, 4.0 seconds used.\n",
      " 700/7925 images processed, 4.0 seconds used.\n",
      " 800/7925 images processed, 4.0 seconds used.\n",
      " 900/7925 images processed, 4.0 seconds used.\n",
      "1000/7925 images processed, 4.0 seconds used.\n",
      "1100/7925 images processed, 4.0 seconds used.\n",
      "1200/7925 images processed, 4.0 seconds used.\n",
      "1300/7925 images processed, 4.0 seconds used.\n",
      "1400/7925 images processed, 4.0 seconds used.\n",
      "1500/7925 images processed, 4.0 seconds used.\n",
      "1600/7925 images processed, 4.0 seconds used.\n",
      "1700/7925 images processed, 4.0 seconds used.\n",
      "1800/7925 images processed, 4.0 seconds used.\n",
      "1900/7925 images processed, 4.0 seconds used.\n",
      "2000/7925 images processed, 4.0 seconds used.\n",
      "2100/7925 images processed, 4.0 seconds used.\n",
      "2200/7925 images processed, 4.0 seconds used.\n",
      "2300/7925 images processed, 4.0 seconds used.\n",
      "2400/7925 images processed, 4.0 seconds used.\n",
      "2500/7925 images processed, 4.0 seconds used.\n",
      "2600/7925 images processed, 4.0 seconds used.\n",
      "2700/7925 images processed, 4.0 seconds used.\n",
      "2800/7925 images processed, 4.0 seconds used.\n",
      "2900/7925 images processed, 4.0 seconds used.\n",
      "3000/7925 images processed, 4.0 seconds used.\n",
      "3100/7925 images processed, 4.0 seconds used.\n",
      "3200/7925 images processed, 4.0 seconds used.\n",
      "3300/7925 images processed, 4.0 seconds used.\n",
      "3400/7925 images processed, 4.0 seconds used.\n",
      "3500/7925 images processed, 4.0 seconds used.\n",
      "3600/7925 images processed, 4.0 seconds used.\n",
      "3700/7925 images processed, 4.0 seconds used.\n",
      "3800/7925 images processed, 4.0 seconds used.\n",
      "3900/7925 images processed, 4.0 seconds used.\n",
      "4000/7925 images processed, 4.0 seconds used.\n",
      "4100/7925 images processed, 4.0 seconds used.\n",
      "4200/7925 images processed, 4.0 seconds used.\n",
      "4300/7925 images processed, 4.0 seconds used.\n",
      "4400/7925 images processed, 4.0 seconds used.\n",
      "4500/7925 images processed, 4.0 seconds used.\n",
      "4600/7925 images processed, 4.0 seconds used.\n",
      "4700/7925 images processed, 4.0 seconds used.\n",
      "4800/7925 images processed, 4.0 seconds used.\n",
      "4900/7925 images processed, 4.0 seconds used.\n",
      "5000/7925 images processed, 4.0 seconds used.\n",
      "5100/7925 images processed, 4.0 seconds used.\n",
      "5200/7925 images processed, 4.0 seconds used.\n",
      "5300/7925 images processed, 4.0 seconds used.\n",
      "5400/7925 images processed, 4.0 seconds used.\n",
      "5500/7925 images processed, 4.0 seconds used.\n",
      "5600/7925 images processed, 4.0 seconds used.\n",
      "5700/7925 images processed, 4.0 seconds used.\n",
      "5800/7925 images processed, 4.0 seconds used.\n",
      "5900/7925 images processed, 4.0 seconds used.\n",
      "6000/7925 images processed, 4.0 seconds used.\n",
      "6100/7925 images processed, 4.0 seconds used.\n",
      "6200/7925 images processed, 4.1 seconds used.\n",
      "6300/7925 images processed, 4.2 seconds used.\n",
      "6400/7925 images processed, 4.3 seconds used.\n",
      "6500/7925 images processed, 4.0 seconds used.\n",
      "6600/7925 images processed, 3.6 seconds used.\n",
      "6700/7925 images processed, 3.6 seconds used.\n",
      "6800/7925 images processed, 4.2 seconds used.\n",
      "6900/7925 images processed, 4.3 seconds used.\n",
      "7000/7925 images processed, 4.3 seconds used.\n",
      "7100/7925 images processed, 4.4 seconds used.\n",
      "7200/7925 images processed, 4.3 seconds used.\n",
      "7300/7925 images processed, 4.2 seconds used.\n",
      "7400/7925 images processed, 4.0 seconds used.\n",
      "7500/7925 images processed, 4.0 seconds used.\n",
      "7600/7925 images processed, 4.2 seconds used.\n",
      "7700/7925 images processed, 4.3 seconds used.\n",
      "7800/7925 images processed, 4.4 seconds used.\n",
      "7900/7925 images processed, 4.2 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/7925 images processed, 4.8 seconds used.\n",
      " 200/7925 images processed, 4.0 seconds used.\n",
      " 300/7925 images processed, 4.0 seconds used.\n",
      " 400/7925 images processed, 4.0 seconds used.\n",
      " 500/7925 images processed, 4.0 seconds used.\n",
      " 600/7925 images processed, 4.0 seconds used.\n",
      " 700/7925 images processed, 4.0 seconds used.\n",
      " 800/7925 images processed, 4.0 seconds used.\n",
      " 900/7925 images processed, 4.0 seconds used.\n",
      "1000/7925 images processed, 4.0 seconds used.\n",
      "1100/7925 images processed, 4.0 seconds used.\n",
      "1200/7925 images processed, 4.0 seconds used.\n",
      "1300/7925 images processed, 4.0 seconds used.\n",
      "1400/7925 images processed, 4.0 seconds used.\n",
      "1500/7925 images processed, 4.0 seconds used.\n",
      "1600/7925 images processed, 4.0 seconds used.\n",
      "1700/7925 images processed, 4.0 seconds used.\n",
      "1800/7925 images processed, 4.0 seconds used.\n",
      "1900/7925 images processed, 4.0 seconds used.\n",
      "2000/7925 images processed, 4.0 seconds used.\n",
      "2100/7925 images processed, 4.0 seconds used.\n",
      "2200/7925 images processed, 4.0 seconds used.\n",
      "2300/7925 images processed, 4.0 seconds used.\n",
      "2400/7925 images processed, 4.1 seconds used.\n",
      "2500/7925 images processed, 4.3 seconds used.\n",
      "2600/7925 images processed, 4.2 seconds used.\n",
      "2700/7925 images processed, 4.4 seconds used.\n",
      "2800/7925 images processed, 4.3 seconds used.\n",
      "2900/7925 images processed, 4.0 seconds used.\n",
      "3000/7925 images processed, 4.0 seconds used.\n",
      "3100/7925 images processed, 3.9 seconds used.\n",
      "3200/7925 images processed, 4.0 seconds used.\n",
      "3300/7925 images processed, 4.0 seconds used.\n",
      "3400/7925 images processed, 4.0 seconds used.\n",
      "3500/7925 images processed, 4.1 seconds used.\n",
      "3600/7925 images processed, 4.4 seconds used.\n",
      "3700/7925 images processed, 4.4 seconds used.\n",
      "3800/7925 images processed, 4.1 seconds used.\n",
      "3900/7925 images processed, 4.2 seconds used.\n",
      "4000/7925 images processed, 4.3 seconds used.\n",
      "4100/7925 images processed, 4.3 seconds used.\n",
      "4200/7925 images processed, 4.4 seconds used.\n",
      "4300/7925 images processed, 4.3 seconds used.\n",
      "4400/7925 images processed, 4.3 seconds used.\n",
      "4500/7925 images processed, 4.4 seconds used.\n",
      "4600/7925 images processed, 4.3 seconds used.\n",
      "4700/7925 images processed, 4.4 seconds used.\n",
      "4800/7925 images processed, 4.3 seconds used.\n",
      "4900/7925 images processed, 4.2 seconds used.\n",
      "5000/7925 images processed, 4.0 seconds used.\n",
      "5100/7925 images processed, 4.0 seconds used.\n",
      "5200/7925 images processed, 4.0 seconds used.\n",
      "5300/7925 images processed, 3.9 seconds used.\n",
      "5400/7925 images processed, 4.0 seconds used.\n",
      "5500/7925 images processed, 4.1 seconds used.\n",
      "5600/7925 images processed, 4.4 seconds used.\n",
      "5700/7925 images processed, 4.3 seconds used.\n",
      "5800/7925 images processed, 4.3 seconds used.\n",
      "5900/7925 images processed, 4.0 seconds used.\n",
      "6000/7925 images processed, 3.8 seconds used.\n",
      "6100/7925 images processed, 3.5 seconds used.\n",
      "6200/7925 images processed, 3.9 seconds used.\n",
      "6300/7925 images processed, 4.1 seconds used.\n",
      "6400/7925 images processed, 4.4 seconds used.\n",
      "6500/7925 images processed, 4.3 seconds used.\n",
      "6600/7925 images processed, 4.4 seconds used.\n",
      "6700/7925 images processed, 4.4 seconds used.\n",
      "6800/7925 images processed, 4.3 seconds used.\n",
      "6900/7925 images processed, 3.9 seconds used.\n",
      "7000/7925 images processed, 4.0 seconds used.\n",
      "7100/7925 images processed, 4.0 seconds used.\n",
      "7200/7925 images processed, 4.0 seconds used.\n",
      "7300/7925 images processed, 4.0 seconds used.\n",
      "7400/7925 images processed, 4.0 seconds used.\n",
      "7500/7925 images processed, 4.0 seconds used.\n",
      "7600/7925 images processed, 4.1 seconds used.\n",
      "7700/7925 images processed, 3.9 seconds used.\n",
      "7800/7925 images processed, 3.9 seconds used.\n",
      "7900/7925 images processed, 4.1 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:                     iSUN\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              43.6%              21.5% \n",
      "Detection error:             12.7%              10.8%\n",
      "AUROC:                       93.3%              95.5%\n",
      "AUPR In:                     93.9%              95.4%\n",
      "AUPR Out:                    91.6%              95.6%\n"
     ]
    }
   ],
   "source": [
    "c.test('densenet10_svhn', 'iSUN', 0, 0.0014, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f35c54a-237b-488c-ba95-645cd63baed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n",
      " 100/9000 images processed, 4.7 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.1 seconds used.\n",
      "1900/9000 images processed, 4.2 seconds used.\n",
      "2000/9000 images processed, 4.2 seconds used.\n",
      "2100/9000 images processed, 4.2 seconds used.\n",
      "2200/9000 images processed, 4.2 seconds used.\n",
      "2300/9000 images processed, 4.2 seconds used.\n",
      "2400/9000 images processed, 4.2 seconds used.\n",
      "2500/9000 images processed, 4.2 seconds used.\n",
      "2600/9000 images processed, 4.3 seconds used.\n",
      "2700/9000 images processed, 4.3 seconds used.\n",
      "2800/9000 images processed, 4.2 seconds used.\n",
      "2900/9000 images processed, 4.4 seconds used.\n",
      "3000/9000 images processed, 4.4 seconds used.\n",
      "3100/9000 images processed, 4.4 seconds used.\n",
      "3200/9000 images processed, 4.3 seconds used.\n",
      "3300/9000 images processed, 4.0 seconds used.\n",
      "3400/9000 images processed, 4.1 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.1 seconds used.\n",
      "3700/9000 images processed, 4.1 seconds used.\n",
      "3800/9000 images processed, 4.2 seconds used.\n",
      "3900/9000 images processed, 4.2 seconds used.\n",
      "4000/9000 images processed, 4.0 seconds used.\n",
      "4100/9000 images processed, 4.0 seconds used.\n",
      "4200/9000 images processed, 4.0 seconds used.\n",
      "4300/9000 images processed, 4.1 seconds used.\n",
      "4400/9000 images processed, 4.2 seconds used.\n",
      "4500/9000 images processed, 4.2 seconds used.\n",
      "4600/9000 images processed, 4.2 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.3 seconds used.\n",
      "4900/9000 images processed, 4.4 seconds used.\n",
      "5000/9000 images processed, 4.2 seconds used.\n",
      "5100/9000 images processed, 4.4 seconds used.\n",
      "5200/9000 images processed, 4.3 seconds used.\n",
      "5300/9000 images processed, 3.9 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.3 seconds used.\n",
      "5600/9000 images processed, 4.2 seconds used.\n",
      "5700/9000 images processed, 4.4 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 3.9 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.2 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.1 seconds used.\n",
      "7100/9000 images processed, 4.2 seconds used.\n",
      "7200/9000 images processed, 4.1 seconds used.\n",
      "7300/9000 images processed, 4.3 seconds used.\n",
      "7400/9000 images processed, 4.0 seconds used.\n",
      "7500/9000 images processed, 4.1 seconds used.\n",
      "7600/9000 images processed, 3.9 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.0 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.2 seconds used.\n",
      "8600/9000 images processed, 4.1 seconds used.\n",
      "8700/9000 images processed, 4.1 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.1 seconds used.\n",
      "9000/9000 images processed, 4.1 seconds used.\n",
      "9100/9000 images processed, 4.1 seconds used.\n",
      "9200/9000 images processed, 4.1 seconds used.\n",
      "9300/9000 images processed, 4.1 seconds used.\n",
      "9400/9000 images processed, 4.1 seconds used.\n",
      "9500/9000 images processed, 4.1 seconds used.\n",
      "9600/9000 images processed, 4.1 seconds used.\n",
      "9700/9000 images processed, 4.1 seconds used.\n",
      "9800/9000 images processed, 4.1 seconds used.\n",
      "9900/9000 images processed, 4.1 seconds used.\n",
      "10000/9000 images processed, 4.1 seconds used.\n",
      "10100/9000 images processed, 4.1 seconds used.\n",
      "10200/9000 images processed, 4.1 seconds used.\n",
      "10300/9000 images processed, 4.1 seconds used.\n",
      "10400/9000 images processed, 4.1 seconds used.\n",
      "10500/9000 images processed, 4.1 seconds used.\n",
      "10600/9000 images processed, 4.1 seconds used.\n",
      "10700/9000 images processed, 4.1 seconds used.\n",
      "10800/9000 images processed, 4.1 seconds used.\n",
      "10900/9000 images processed, 4.1 seconds used.\n",
      "11000/9000 images processed, 4.1 seconds used.\n",
      "11100/9000 images processed, 4.1 seconds used.\n",
      "11200/9000 images processed, 4.1 seconds used.\n",
      "11300/9000 images processed, 4.1 seconds used.\n",
      "11400/9000 images processed, 4.1 seconds used.\n",
      "11500/9000 images processed, 4.0 seconds used.\n",
      "11600/9000 images processed, 4.0 seconds used.\n",
      "11700/9000 images processed, 4.0 seconds used.\n",
      "11800/9000 images processed, 4.0 seconds used.\n",
      "11900/9000 images processed, 4.0 seconds used.\n",
      "12000/9000 images processed, 4.0 seconds used.\n",
      "12100/9000 images processed, 4.0 seconds used.\n",
      "12200/9000 images processed, 4.0 seconds used.\n",
      "12300/9000 images processed, 4.0 seconds used.\n",
      "12400/9000 images processed, 4.1 seconds used.\n",
      "12500/9000 images processed, 4.1 seconds used.\n",
      "12600/9000 images processed, 4.1 seconds used.\n",
      "12700/9000 images processed, 4.1 seconds used.\n",
      "12800/9000 images processed, 4.1 seconds used.\n",
      "12900/9000 images processed, 4.1 seconds used.\n",
      "13000/9000 images processed, 4.1 seconds used.\n",
      "13100/9000 images processed, 4.0 seconds used.\n",
      "13200/9000 images processed, 4.1 seconds used.\n",
      "13300/9000 images processed, 4.1 seconds used.\n",
      "13400/9000 images processed, 4.1 seconds used.\n",
      "13500/9000 images processed, 4.1 seconds used.\n",
      "13600/9000 images processed, 4.1 seconds used.\n",
      "13700/9000 images processed, 4.0 seconds used.\n",
      "13800/9000 images processed, 4.0 seconds used.\n",
      "13900/9000 images processed, 4.1 seconds used.\n",
      "14000/9000 images processed, 4.1 seconds used.\n",
      "14100/9000 images processed, 4.0 seconds used.\n",
      "14200/9000 images processed, 4.0 seconds used.\n",
      "14300/9000 images processed, 4.0 seconds used.\n",
      "14400/9000 images processed, 4.0 seconds used.\n",
      "14500/9000 images processed, 4.1 seconds used.\n",
      "14600/9000 images processed, 4.1 seconds used.\n",
      "14700/9000 images processed, 4.1 seconds used.\n",
      "14800/9000 images processed, 4.1 seconds used.\n",
      "14900/9000 images processed, 4.0 seconds used.\n",
      "15000/9000 images processed, 4.0 seconds used.\n",
      "15100/9000 images processed, 4.0 seconds used.\n",
      "15200/9000 images processed, 4.0 seconds used.\n",
      "15300/9000 images processed, 4.1 seconds used.\n",
      "15400/9000 images processed, 4.0 seconds used.\n",
      "15500/9000 images processed, 4.1 seconds used.\n",
      "15600/9000 images processed, 4.0 seconds used.\n",
      "15700/9000 images processed, 4.0 seconds used.\n",
      "15800/9000 images processed, 4.0 seconds used.\n",
      "15900/9000 images processed, 4.0 seconds used.\n",
      "16000/9000 images processed, 4.0 seconds used.\n",
      "16100/9000 images processed, 4.0 seconds used.\n",
      "16200/9000 images processed, 4.0 seconds used.\n",
      "16300/9000 images processed, 4.0 seconds used.\n",
      "16400/9000 images processed, 4.0 seconds used.\n",
      "16500/9000 images processed, 4.0 seconds used.\n",
      "16600/9000 images processed, 4.0 seconds used.\n",
      "16700/9000 images processed, 4.0 seconds used.\n",
      "16800/9000 images processed, 4.0 seconds used.\n",
      "16900/9000 images processed, 4.0 seconds used.\n",
      "17000/9000 images processed, 4.2 seconds used.\n",
      "17100/9000 images processed, 4.1 seconds used.\n",
      "17200/9000 images processed, 4.0 seconds used.\n",
      "17300/9000 images processed, 4.1 seconds used.\n",
      "17400/9000 images processed, 4.0 seconds used.\n",
      "17500/9000 images processed, 4.0 seconds used.\n",
      "17600/9000 images processed, 4.3 seconds used.\n",
      "17700/9000 images processed, 4.0 seconds used.\n",
      "17800/9000 images processed, 4.2 seconds used.\n",
      "17900/9000 images processed, 4.2 seconds used.\n",
      "18000/9000 images processed, 4.1 seconds used.\n",
      "18100/9000 images processed, 4.0 seconds used.\n",
      "18200/9000 images processed, 4.3 seconds used.\n",
      "18300/9000 images processed, 4.3 seconds used.\n",
      "18400/9000 images processed, 4.3 seconds used.\n",
      "18500/9000 images processed, 4.2 seconds used.\n",
      "18600/9000 images processed, 4.3 seconds used.\n",
      "18700/9000 images processed, 4.3 seconds used.\n",
      "18800/9000 images processed, 4.2 seconds used.\n",
      "18900/9000 images processed, 4.1 seconds used.\n",
      "19000/9000 images processed, 4.2 seconds used.\n",
      "19100/9000 images processed, 4.3 seconds used.\n",
      "19200/9000 images processed, 4.4 seconds used.\n",
      "19300/9000 images processed, 4.0 seconds used.\n",
      "19400/9000 images processed, 4.0 seconds used.\n",
      "19500/9000 images processed, 4.0 seconds used.\n",
      "19600/9000 images processed, 4.0 seconds used.\n",
      "19700/9000 images processed, 3.9 seconds used.\n",
      "19800/9000 images processed, 4.0 seconds used.\n",
      "19900/9000 images processed, 4.0 seconds used.\n",
      "20000/9000 images processed, 4.1 seconds used.\n",
      "20100/9000 images processed, 4.3 seconds used.\n",
      "20200/9000 images processed, 4.3 seconds used.\n",
      "20300/9000 images processed, 4.2 seconds used.\n",
      "20400/9000 images processed, 4.2 seconds used.\n",
      "20500/9000 images processed, 4.2 seconds used.\n",
      "20600/9000 images processed, 4.0 seconds used.\n",
      "20700/9000 images processed, 4.1 seconds used.\n",
      "20800/9000 images processed, 4.2 seconds used.\n",
      "20900/9000 images processed, 4.3 seconds used.\n",
      "21000/9000 images processed, 4.0 seconds used.\n",
      "21100/9000 images processed, 4.0 seconds used.\n",
      "21200/9000 images processed, 4.0 seconds used.\n",
      "21300/9000 images processed, 4.0 seconds used.\n",
      "21400/9000 images processed, 4.0 seconds used.\n",
      "21500/9000 images processed, 4.1 seconds used.\n",
      "21600/9000 images processed, 4.3 seconds used.\n",
      "21700/9000 images processed, 4.4 seconds used.\n",
      "21800/9000 images processed, 4.3 seconds used.\n",
      "21900/9000 images processed, 4.3 seconds used.\n",
      "22000/9000 images processed, 4.4 seconds used.\n",
      "22100/9000 images processed, 4.3 seconds used.\n",
      "22200/9000 images processed, 4.2 seconds used.\n",
      "22300/9000 images processed, 4.2 seconds used.\n",
      "22400/9000 images processed, 4.2 seconds used.\n",
      "22500/9000 images processed, 4.2 seconds used.\n",
      "22600/9000 images processed, 4.2 seconds used.\n",
      "22700/9000 images processed, 4.1 seconds used.\n",
      "22800/9000 images processed, 4.0 seconds used.\n",
      "22900/9000 images processed, 4.1 seconds used.\n",
      "23000/9000 images processed, 4.2 seconds used.\n",
      "23100/9000 images processed, 3.9 seconds used.\n",
      "23200/9000 images processed, 3.9 seconds used.\n",
      "23300/9000 images processed, 4.4 seconds used.\n",
      "23400/9000 images processed, 4.0 seconds used.\n",
      "23500/9000 images processed, 4.0 seconds used.\n",
      "23600/9000 images processed, 4.0 seconds used.\n",
      "23700/9000 images processed, 4.0 seconds used.\n",
      "23800/9000 images processed, 4.2 seconds used.\n",
      "23900/9000 images processed, 4.2 seconds used.\n",
      "24000/9000 images processed, 4.0 seconds used.\n",
      "24100/9000 images processed, 4.0 seconds used.\n",
      "24200/9000 images processed, 4.0 seconds used.\n",
      "24300/9000 images processed, 4.0 seconds used.\n",
      "24400/9000 images processed, 4.0 seconds used.\n",
      "24500/9000 images processed, 4.0 seconds used.\n",
      "24600/9000 images processed, 4.3 seconds used.\n",
      "24700/9000 images processed, 4.3 seconds used.\n",
      "24800/9000 images processed, 4.2 seconds used.\n",
      "24900/9000 images processed, 4.4 seconds used.\n",
      "25000/9000 images processed, 4.4 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 6.2 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.2 seconds used.\n",
      " 900/9000 images processed, 3.9 seconds used.\n",
      "1000/9000 images processed, 3.6 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.1 seconds used.\n",
      "1300/9000 images processed, 4.1 seconds used.\n",
      "1400/9000 images processed, 4.1 seconds used.\n",
      "1500/9000 images processed, 4.1 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.1 seconds used.\n",
      "1800/9000 images processed, 4.1 seconds used.\n",
      "1900/9000 images processed, 4.1 seconds used.\n",
      "2000/9000 images processed, 4.1 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.1 seconds used.\n",
      "2800/9000 images processed, 4.2 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.0 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 4.2 seconds used.\n",
      "3400/9000 images processed, 4.2 seconds used.\n",
      "3500/9000 images processed, 4.1 seconds used.\n",
      "3600/9000 images processed, 4.2 seconds used.\n",
      "3700/9000 images processed, 4.1 seconds used.\n",
      "3800/9000 images processed, 4.1 seconds used.\n",
      "3900/9000 images processed, 4.2 seconds used.\n",
      "4000/9000 images processed, 4.1 seconds used.\n",
      "4100/9000 images processed, 4.1 seconds used.\n",
      "4200/9000 images processed, 4.2 seconds used.\n",
      "4300/9000 images processed, 4.2 seconds used.\n",
      "4400/9000 images processed, 4.1 seconds used.\n",
      "4500/9000 images processed, 4.0 seconds used.\n",
      "4600/9000 images processed, 4.0 seconds used.\n",
      "4700/9000 images processed, 4.0 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.0 seconds used.\n",
      "5600/9000 images processed, 4.0 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.3 seconds used.\n",
      "6700/9000 images processed, 4.3 seconds used.\n",
      "6800/9000 images processed, 4.3 seconds used.\n",
      "6900/9000 images processed, 4.4 seconds used.\n",
      "7000/9000 images processed, 4.2 seconds used.\n",
      "7100/9000 images processed, 4.3 seconds used.\n",
      "7200/9000 images processed, 4.2 seconds used.\n",
      "7300/9000 images processed, 4.2 seconds used.\n",
      "7400/9000 images processed, 4.2 seconds used.\n",
      "7500/9000 images processed, 4.3 seconds used.\n",
      "7600/9000 images processed, 4.3 seconds used.\n",
      "7700/9000 images processed, 4.3 seconds used.\n",
      "7800/9000 images processed, 4.2 seconds used.\n",
      "7900/9000 images processed, 4.2 seconds used.\n",
      "8000/9000 images processed, 4.2 seconds used.\n",
      "8100/9000 images processed, 4.3 seconds used.\n",
      "8200/9000 images processed, 4.3 seconds used.\n",
      "8300/9000 images processed, 4.3 seconds used.\n",
      "8400/9000 images processed, 4.2 seconds used.\n",
      "8500/9000 images processed, 4.3 seconds used.\n",
      "8600/9000 images processed, 4.4 seconds used.\n",
      "8700/9000 images processed, 4.2 seconds used.\n",
      "8800/9000 images processed, 4.1 seconds used.\n",
      "8900/9000 images processed, 4.2 seconds used.\n",
      "9000/9000 images processed, 3.9 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:           Gaussian noise\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              29.9%               5.3% \n",
      "Detection error:              8.6%               4.8%\n",
      "AUROC:                       95.9%              98.8%\n",
      "AUPR In:                     97.0%              99.0%\n",
      "AUPR Out:                    94.1%              98.5%\n"
     ]
    }
   ],
   "source": [
    "c.test('densenet10_svhn', 'Gaussian', 0, 0.0014, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe0242e-2386-40ff-8a44-236d170bbb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "Processing in-distribution images\n",
      " 100/9000  images processed, 4.8 seconds used.\n",
      " 200/9000  images processed, 4.0 seconds used.\n",
      " 300/9000  images processed, 4.0 seconds used.\n",
      " 400/9000  images processed, 4.0 seconds used.\n",
      " 500/9000  images processed, 4.1 seconds used.\n",
      " 600/9000  images processed, 4.1 seconds used.\n",
      " 700/9000  images processed, 4.2 seconds used.\n",
      " 800/9000  images processed, 4.1 seconds used.\n",
      " 900/9000  images processed, 4.0 seconds used.\n",
      "1000/9000  images processed, 4.0 seconds used.\n",
      "1100/9000  images processed, 4.0 seconds used.\n",
      "1200/9000  images processed, 4.0 seconds used.\n",
      "1300/9000  images processed, 4.0 seconds used.\n",
      "1400/9000  images processed, 4.0 seconds used.\n",
      "1500/9000  images processed, 4.2 seconds used.\n",
      "1600/9000  images processed, 4.3 seconds used.\n",
      "1700/9000  images processed, 4.2 seconds used.\n",
      "1800/9000  images processed, 4.1 seconds used.\n",
      "1900/9000  images processed, 4.3 seconds used.\n",
      "2000/9000  images processed, 4.3 seconds used.\n",
      "2100/9000  images processed, 4.2 seconds used.\n",
      "2200/9000  images processed, 4.0 seconds used.\n",
      "2300/9000  images processed, 4.1 seconds used.\n",
      "2400/9000  images processed, 4.1 seconds used.\n",
      "2500/9000  images processed, 3.8 seconds used.\n",
      "2600/9000  images processed, 4.1 seconds used.\n",
      "2700/9000  images processed, 4.0 seconds used.\n",
      "2800/9000  images processed, 4.0 seconds used.\n",
      "2900/9000  images processed, 4.0 seconds used.\n",
      "3000/9000  images processed, 4.0 seconds used.\n",
      "3100/9000  images processed, 4.1 seconds used.\n",
      "3200/9000  images processed, 4.3 seconds used.\n",
      "3300/9000  images processed, 4.4 seconds used.\n",
      "3400/9000  images processed, 4.3 seconds used.\n",
      "3500/9000  images processed, 4.4 seconds used.\n",
      "3600/9000  images processed, 4.2 seconds used.\n",
      "3700/9000  images processed, 4.0 seconds used.\n",
      "3800/9000  images processed, 4.0 seconds used.\n",
      "3900/9000  images processed, 4.2 seconds used.\n",
      "4000/9000  images processed, 4.1 seconds used.\n",
      "4100/9000  images processed, 4.2 seconds used.\n",
      "4200/9000  images processed, 4.3 seconds used.\n",
      "4300/9000  images processed, 4.3 seconds used.\n",
      "4400/9000  images processed, 4.2 seconds used.\n",
      "4500/9000  images processed, 4.2 seconds used.\n",
      "4600/9000  images processed, 4.2 seconds used.\n",
      "4700/9000  images processed, 4.3 seconds used.\n",
      "4800/9000  images processed, 4.4 seconds used.\n",
      "4900/9000  images processed, 4.4 seconds used.\n",
      "5000/9000  images processed, 4.2 seconds used.\n",
      "5100/9000  images processed, 4.1 seconds used.\n",
      "5200/9000  images processed, 4.1 seconds used.\n",
      "5300/9000  images processed, 4.3 seconds used.\n",
      "5400/9000  images processed, 4.2 seconds used.\n",
      "5500/9000  images processed, 4.3 seconds used.\n",
      "5600/9000  images processed, 4.4 seconds used.\n",
      "5700/9000  images processed, 4.3 seconds used.\n",
      "5800/9000  images processed, 4.0 seconds used.\n",
      "5900/9000  images processed, 4.2 seconds used.\n",
      "6000/9000  images processed, 4.3 seconds used.\n",
      "6100/9000  images processed, 4.3 seconds used.\n",
      "6200/9000  images processed, 4.3 seconds used.\n",
      "6300/9000  images processed, 4.3 seconds used.\n",
      "6400/9000  images processed, 4.3 seconds used.\n",
      "6500/9000  images processed, 4.3 seconds used.\n",
      "6600/9000  images processed, 4.2 seconds used.\n",
      "6700/9000  images processed, 4.1 seconds used.\n",
      "6800/9000  images processed, 4.1 seconds used.\n",
      "6900/9000  images processed, 4.2 seconds used.\n",
      "7000/9000  images processed, 4.0 seconds used.\n",
      "7100/9000  images processed, 4.2 seconds used.\n",
      "7200/9000  images processed, 4.4 seconds used.\n",
      "7300/9000  images processed, 4.3 seconds used.\n",
      "7400/9000  images processed, 4.1 seconds used.\n",
      "7500/9000  images processed, 4.0 seconds used.\n",
      "7600/9000  images processed, 4.0 seconds used.\n",
      "7700/9000  images processed, 4.0 seconds used.\n",
      "7800/9000  images processed, 4.0 seconds used.\n",
      "7900/9000  images processed, 4.2 seconds used.\n",
      "8000/9000  images processed, 4.0 seconds used.\n",
      "8100/9000  images processed, 4.0 seconds used.\n",
      "8200/9000  images processed, 4.1 seconds used.\n",
      "8300/9000  images processed, 4.4 seconds used.\n",
      "8400/9000  images processed, 4.0 seconds used.\n",
      "8500/9000  images processed, 4.3 seconds used.\n",
      "8600/9000  images processed, 4.1 seconds used.\n",
      "8700/9000  images processed, 4.1 seconds used.\n",
      "8800/9000  images processed, 4.3 seconds used.\n",
      "8900/9000  images processed, 4.0 seconds used.\n",
      "9000/9000  images processed, 3.8 seconds used.\n",
      "9100/9000  images processed, 3.6 seconds used.\n",
      "9200/9000  images processed, 4.0 seconds used.\n",
      "9300/9000  images processed, 4.0 seconds used.\n",
      "9400/9000  images processed, 4.0 seconds used.\n",
      "9500/9000  images processed, 4.0 seconds used.\n",
      "9600/9000  images processed, 4.0 seconds used.\n",
      "9700/9000  images processed, 4.0 seconds used.\n",
      "9800/9000  images processed, 4.0 seconds used.\n",
      "9900/9000  images processed, 4.0 seconds used.\n",
      "10000/9000  images processed, 4.0 seconds used.\n",
      "10100/9000  images processed, 4.0 seconds used.\n",
      "10200/9000  images processed, 4.0 seconds used.\n",
      "10300/9000  images processed, 4.0 seconds used.\n",
      "10400/9000  images processed, 4.0 seconds used.\n",
      "10500/9000  images processed, 4.0 seconds used.\n",
      "10600/9000  images processed, 4.0 seconds used.\n",
      "10700/9000  images processed, 4.0 seconds used.\n",
      "10800/9000  images processed, 4.0 seconds used.\n",
      "10900/9000  images processed, 4.0 seconds used.\n",
      "11000/9000  images processed, 4.0 seconds used.\n",
      "11100/9000  images processed, 4.0 seconds used.\n",
      "11200/9000  images processed, 4.0 seconds used.\n",
      "11300/9000  images processed, 4.0 seconds used.\n",
      "11400/9000  images processed, 4.0 seconds used.\n",
      "11500/9000  images processed, 4.0 seconds used.\n",
      "11600/9000  images processed, 4.0 seconds used.\n",
      "11700/9000  images processed, 4.0 seconds used.\n",
      "11800/9000  images processed, 4.0 seconds used.\n",
      "11900/9000  images processed, 4.0 seconds used.\n",
      "12000/9000  images processed, 4.0 seconds used.\n",
      "12100/9000  images processed, 4.0 seconds used.\n",
      "12200/9000  images processed, 4.0 seconds used.\n",
      "12300/9000  images processed, 4.0 seconds used.\n",
      "12400/9000  images processed, 4.0 seconds used.\n",
      "12500/9000  images processed, 4.0 seconds used.\n",
      "12600/9000  images processed, 4.0 seconds used.\n",
      "12700/9000  images processed, 4.0 seconds used.\n",
      "12800/9000  images processed, 4.0 seconds used.\n",
      "12900/9000  images processed, 4.0 seconds used.\n",
      "13000/9000  images processed, 4.0 seconds used.\n",
      "13100/9000  images processed, 4.0 seconds used.\n",
      "13200/9000  images processed, 3.9 seconds used.\n",
      "13300/9000  images processed, 4.0 seconds used.\n",
      "13400/9000  images processed, 4.0 seconds used.\n",
      "13500/9000  images processed, 4.0 seconds used.\n",
      "13600/9000  images processed, 4.0 seconds used.\n",
      "13700/9000  images processed, 4.0 seconds used.\n",
      "13800/9000  images processed, 4.0 seconds used.\n",
      "13900/9000  images processed, 4.0 seconds used.\n",
      "14000/9000  images processed, 4.0 seconds used.\n",
      "14100/9000  images processed, 4.0 seconds used.\n",
      "14200/9000  images processed, 4.0 seconds used.\n",
      "14300/9000  images processed, 4.1 seconds used.\n",
      "14400/9000  images processed, 4.0 seconds used.\n",
      "14500/9000  images processed, 4.0 seconds used.\n",
      "14600/9000  images processed, 4.1 seconds used.\n",
      "14700/9000  images processed, 4.0 seconds used.\n",
      "14800/9000  images processed, 4.0 seconds used.\n",
      "14900/9000  images processed, 4.1 seconds used.\n",
      "15000/9000  images processed, 4.0 seconds used.\n",
      "15100/9000  images processed, 4.0 seconds used.\n",
      "15200/9000  images processed, 4.1 seconds used.\n",
      "15300/9000  images processed, 4.0 seconds used.\n",
      "15400/9000  images processed, 4.0 seconds used.\n",
      "15500/9000  images processed, 4.0 seconds used.\n",
      "15600/9000  images processed, 4.0 seconds used.\n",
      "15700/9000  images processed, 4.1 seconds used.\n",
      "15800/9000  images processed, 4.0 seconds used.\n",
      "15900/9000  images processed, 4.0 seconds used.\n",
      "16000/9000  images processed, 3.9 seconds used.\n",
      "16100/9000  images processed, 4.0 seconds used.\n",
      "16200/9000  images processed, 4.0 seconds used.\n",
      "16300/9000  images processed, 4.0 seconds used.\n",
      "16400/9000  images processed, 4.0 seconds used.\n",
      "16500/9000  images processed, 4.0 seconds used.\n",
      "16600/9000  images processed, 4.0 seconds used.\n",
      "16700/9000  images processed, 4.0 seconds used.\n",
      "16800/9000  images processed, 4.0 seconds used.\n",
      "16900/9000  images processed, 4.0 seconds used.\n",
      "17000/9000  images processed, 4.0 seconds used.\n",
      "17100/9000  images processed, 4.0 seconds used.\n",
      "17200/9000  images processed, 4.0 seconds used.\n",
      "17300/9000  images processed, 4.1 seconds used.\n",
      "17400/9000  images processed, 4.0 seconds used.\n",
      "17500/9000  images processed, 4.0 seconds used.\n",
      "17600/9000  images processed, 4.0 seconds used.\n",
      "17700/9000  images processed, 4.0 seconds used.\n",
      "17800/9000  images processed, 4.2 seconds used.\n",
      "17900/9000  images processed, 4.0 seconds used.\n",
      "18000/9000  images processed, 4.0 seconds used.\n",
      "18100/9000  images processed, 4.0 seconds used.\n",
      "18200/9000  images processed, 4.0 seconds used.\n",
      "18300/9000  images processed, 4.0 seconds used.\n",
      "18400/9000  images processed, 4.0 seconds used.\n",
      "18500/9000  images processed, 4.1 seconds used.\n",
      "18600/9000  images processed, 4.1 seconds used.\n",
      "18700/9000  images processed, 4.1 seconds used.\n",
      "18800/9000  images processed, 4.1 seconds used.\n",
      "18900/9000  images processed, 4.1 seconds used.\n",
      "19000/9000  images processed, 4.0 seconds used.\n",
      "19100/9000  images processed, 4.0 seconds used.\n",
      "19200/9000  images processed, 4.1 seconds used.\n",
      "19300/9000  images processed, 4.1 seconds used.\n",
      "19400/9000  images processed, 4.0 seconds used.\n",
      "19500/9000  images processed, 4.0 seconds used.\n",
      "19600/9000  images processed, 4.0 seconds used.\n",
      "19700/9000  images processed, 4.0 seconds used.\n",
      "19800/9000  images processed, 4.0 seconds used.\n",
      "19900/9000  images processed, 4.0 seconds used.\n",
      "20000/9000  images processed, 4.0 seconds used.\n",
      "20100/9000  images processed, 4.0 seconds used.\n",
      "20200/9000  images processed, 4.0 seconds used.\n",
      "20300/9000  images processed, 4.0 seconds used.\n",
      "20400/9000  images processed, 4.0 seconds used.\n",
      "20500/9000  images processed, 4.1 seconds used.\n",
      "20600/9000  images processed, 4.0 seconds used.\n",
      "20700/9000  images processed, 4.1 seconds used.\n",
      "20800/9000  images processed, 4.0 seconds used.\n",
      "20900/9000  images processed, 4.0 seconds used.\n",
      "21000/9000  images processed, 3.9 seconds used.\n",
      "21100/9000  images processed, 4.0 seconds used.\n",
      "21200/9000  images processed, 4.1 seconds used.\n",
      "21300/9000  images processed, 4.2 seconds used.\n",
      "21400/9000  images processed, 4.2 seconds used.\n",
      "21500/9000  images processed, 4.3 seconds used.\n",
      "21600/9000  images processed, 4.3 seconds used.\n",
      "21700/9000  images processed, 4.2 seconds used.\n",
      "21800/9000  images processed, 4.2 seconds used.\n",
      "21900/9000  images processed, 4.2 seconds used.\n",
      "22000/9000  images processed, 4.1 seconds used.\n",
      "22100/9000  images processed, 4.1 seconds used.\n",
      "22200/9000  images processed, 4.2 seconds used.\n",
      "22300/9000  images processed, 4.1 seconds used.\n",
      "22400/9000  images processed, 4.3 seconds used.\n",
      "22500/9000  images processed, 4.3 seconds used.\n",
      "22600/9000  images processed, 4.3 seconds used.\n",
      "22700/9000  images processed, 4.3 seconds used.\n",
      "22800/9000  images processed, 4.3 seconds used.\n",
      "22900/9000  images processed, 4.2 seconds used.\n",
      "23000/9000  images processed, 4.4 seconds used.\n",
      "23100/9000  images processed, 4.2 seconds used.\n",
      "23200/9000  images processed, 4.2 seconds used.\n",
      "23300/9000  images processed, 4.3 seconds used.\n",
      "23400/9000  images processed, 4.3 seconds used.\n",
      "23500/9000  images processed, 4.2 seconds used.\n",
      "23600/9000  images processed, 4.1 seconds used.\n",
      "23700/9000  images processed, 4.3 seconds used.\n",
      "23800/9000  images processed, 4.1 seconds used.\n",
      "23900/9000  images processed, 4.2 seconds used.\n",
      "24000/9000  images processed, 4.2 seconds used.\n",
      "24100/9000  images processed, 4.0 seconds used.\n",
      "24200/9000  images processed, 3.9 seconds used.\n",
      "24300/9000  images processed, 4.0 seconds used.\n",
      "24400/9000  images processed, 4.1 seconds used.\n",
      "24500/9000  images processed, 4.0 seconds used.\n",
      "24600/9000  images processed, 4.0 seconds used.\n",
      "24700/9000  images processed, 4.0 seconds used.\n",
      "24800/9000  images processed, 3.9 seconds used.\n",
      "24900/9000  images processed, 4.0 seconds used.\n",
      "25000/9000  images processed, 4.0 seconds used.\n",
      "Processing out-of-distribution images\n",
      " 100/9000 images processed, 6.1 seconds used.\n",
      " 200/9000 images processed, 4.0 seconds used.\n",
      " 300/9000 images processed, 4.0 seconds used.\n",
      " 400/9000 images processed, 4.0 seconds used.\n",
      " 500/9000 images processed, 4.0 seconds used.\n",
      " 600/9000 images processed, 4.0 seconds used.\n",
      " 700/9000 images processed, 4.0 seconds used.\n",
      " 800/9000 images processed, 4.0 seconds used.\n",
      " 900/9000 images processed, 4.0 seconds used.\n",
      "1000/9000 images processed, 4.0 seconds used.\n",
      "1100/9000 images processed, 4.0 seconds used.\n",
      "1200/9000 images processed, 4.0 seconds used.\n",
      "1300/9000 images processed, 4.0 seconds used.\n",
      "1400/9000 images processed, 4.0 seconds used.\n",
      "1500/9000 images processed, 4.0 seconds used.\n",
      "1600/9000 images processed, 4.0 seconds used.\n",
      "1700/9000 images processed, 4.0 seconds used.\n",
      "1800/9000 images processed, 4.0 seconds used.\n",
      "1900/9000 images processed, 4.0 seconds used.\n",
      "2000/9000 images processed, 4.0 seconds used.\n",
      "2100/9000 images processed, 4.0 seconds used.\n",
      "2200/9000 images processed, 4.0 seconds used.\n",
      "2300/9000 images processed, 4.0 seconds used.\n",
      "2400/9000 images processed, 4.0 seconds used.\n",
      "2500/9000 images processed, 4.0 seconds used.\n",
      "2600/9000 images processed, 4.0 seconds used.\n",
      "2700/9000 images processed, 4.1 seconds used.\n",
      "2800/9000 images processed, 4.0 seconds used.\n",
      "2900/9000 images processed, 4.0 seconds used.\n",
      "3000/9000 images processed, 4.0 seconds used.\n",
      "3100/9000 images processed, 4.1 seconds used.\n",
      "3200/9000 images processed, 4.0 seconds used.\n",
      "3300/9000 images processed, 4.0 seconds used.\n",
      "3400/9000 images processed, 4.0 seconds used.\n",
      "3500/9000 images processed, 4.0 seconds used.\n",
      "3600/9000 images processed, 4.1 seconds used.\n",
      "3700/9000 images processed, 4.1 seconds used.\n",
      "3800/9000 images processed, 4.1 seconds used.\n",
      "3900/9000 images processed, 4.1 seconds used.\n",
      "4000/9000 images processed, 4.1 seconds used.\n",
      "4100/9000 images processed, 4.0 seconds used.\n",
      "4200/9000 images processed, 4.1 seconds used.\n",
      "4300/9000 images processed, 4.1 seconds used.\n",
      "4400/9000 images processed, 4.1 seconds used.\n",
      "4500/9000 images processed, 4.1 seconds used.\n",
      "4600/9000 images processed, 4.1 seconds used.\n",
      "4700/9000 images processed, 4.1 seconds used.\n",
      "4800/9000 images processed, 4.0 seconds used.\n",
      "4900/9000 images processed, 4.0 seconds used.\n",
      "5000/9000 images processed, 4.0 seconds used.\n",
      "5100/9000 images processed, 4.0 seconds used.\n",
      "5200/9000 images processed, 4.0 seconds used.\n",
      "5300/9000 images processed, 4.0 seconds used.\n",
      "5400/9000 images processed, 4.0 seconds used.\n",
      "5500/9000 images processed, 4.0 seconds used.\n",
      "5600/9000 images processed, 4.0 seconds used.\n",
      "5700/9000 images processed, 4.0 seconds used.\n",
      "5800/9000 images processed, 4.0 seconds used.\n",
      "5900/9000 images processed, 4.0 seconds used.\n",
      "6000/9000 images processed, 4.0 seconds used.\n",
      "6100/9000 images processed, 4.0 seconds used.\n",
      "6200/9000 images processed, 4.0 seconds used.\n",
      "6300/9000 images processed, 4.0 seconds used.\n",
      "6400/9000 images processed, 4.0 seconds used.\n",
      "6500/9000 images processed, 4.0 seconds used.\n",
      "6600/9000 images processed, 4.0 seconds used.\n",
      "6700/9000 images processed, 4.0 seconds used.\n",
      "6800/9000 images processed, 4.0 seconds used.\n",
      "6900/9000 images processed, 4.0 seconds used.\n",
      "7000/9000 images processed, 4.1 seconds used.\n",
      "7100/9000 images processed, 4.0 seconds used.\n",
      "7200/9000 images processed, 4.0 seconds used.\n",
      "7300/9000 images processed, 4.0 seconds used.\n",
      "7400/9000 images processed, 4.0 seconds used.\n",
      "7500/9000 images processed, 4.0 seconds used.\n",
      "7600/9000 images processed, 4.0 seconds used.\n",
      "7700/9000 images processed, 4.0 seconds used.\n",
      "7800/9000 images processed, 4.0 seconds used.\n",
      "7900/9000 images processed, 4.0 seconds used.\n",
      "8000/9000 images processed, 4.0 seconds used.\n",
      "8100/9000 images processed, 4.0 seconds used.\n",
      "8200/9000 images processed, 4.0 seconds used.\n",
      "8300/9000 images processed, 4.1 seconds used.\n",
      "8400/9000 images processed, 4.0 seconds used.\n",
      "8500/9000 images processed, 4.0 seconds used.\n",
      "8600/9000 images processed, 4.0 seconds used.\n",
      "8700/9000 images processed, 4.0 seconds used.\n",
      "8800/9000 images processed, 4.0 seconds used.\n",
      "8900/9000 images processed, 4.3 seconds used.\n",
      "9000/9000 images processed, 4.2 seconds used.\n",
      "Neural network architecture:          DenseNet-BC-100\n",
      "In-distribution dataset:                         SVHN\n",
      "Out-of-distribution dataset:            Uniform Noise\n",
      "\n",
      "                          Baseline         Our Method\n",
      "FPR at TPR 95%:              39.1%              15.5% \n",
      "Detection error:              9.9%               7.6%\n",
      "AUROC:                       94.9%              97.3%\n",
      "AUPR In:                     96.2%              97.9%\n",
      "AUPR Out:                    92.4%              96.5%\n"
     ]
    }
   ],
   "source": [
    "c.test('densenet10_svhn', 'Uniform', 0, 0.0014, 1000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
